{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZp6LkQL1o4k",
        "outputId": "5c3bc354-e018-4328-d9aa-0e3272b6947a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SGIy8RG2WEu",
        "outputId": "ff16d84f-d8ae-41c1-ef01-d8430341d7ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textatistic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "GptKkOMq4f4b",
        "outputId": "62f2b362-04ad-4214-f42f-38f280479b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textatistic\n",
            "  Downloading textatistic-0.0.1.tar.gz (29 kB)\n",
            "Collecting pyhyphen>=2.0.5\n",
            "  Downloading PyHyphen-4.0.3.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.36.0 in /usr/local/lib/python3.7/dist-packages (from pyhyphen>=2.0.5->textatistic) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=52.0 in /usr/local/lib/python3.7/dist-packages (from pyhyphen>=2.0.5->textatistic) (57.4.0)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyhyphen>=2.0.5->textatistic) (1.4.4)\n",
            "Collecting requests>=2.25\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 573 kB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25->pyhyphen>=2.0.5->textatistic) (2021.10.8)\n",
            "Building wheels for collected packages: textatistic, pyhyphen\n",
            "  Building wheel for textatistic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textatistic: filename=textatistic-0.0.1-py3-none-any.whl size=29068 sha256=88dced17f0f8faa470d77a60d1af9e9ba7c1e0122ee30b543bd25b2bd4a48d88\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/4a/1a/5ed2a089cbd2f98693b07221c4ab499c8c446e15b6123ba4a4\n",
            "  Building wheel for pyhyphen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyhyphen: filename=PyHyphen-4.0.3-cp37-abi3-linux_x86_64.whl size=60307 sha256=0015de9a86d88c9ecfc2cb979f93be4187bd60ebd5fe9650f9887c549f7d26e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/21/3e/e883a6e9969fdd074763213ddaeee0e781c359bbfda3fa435f\n",
            "Successfully built textatistic pyhyphen\n",
            "Installing collected packages: requests, pyhyphen, textatistic\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pyhyphen-4.0.3 requests-2.27.1 textatistic-0.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeQSttMz3JL6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "#from textatistic import Textatistic\n",
        "from spacy.matcher import Matcher\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOfehfR72nvU",
        "outputId": "f9b0ba44-4c4f-4c1f-bfb4-d709f5d4cac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATj27jXl2tHf"
      },
      "outputs": [],
      "source": [
        "imdb_dir = '/content/gdrive/MyDrive'\n",
        "dataset_dir = os.path.join(imdb_dir, 'Textify.ai/Textify AI Text Corpus Center (Responses).xlsx')\n",
        "#dataset_dir = os.path.join(imdb_dir, 'Textify.ai/training_set_rel3.xls')\n",
        "#print(dataset_dir)\n",
        "#bad_essays = os.path.join(imdb_dir,'Textify.ai/First Draft Essays.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcdJGhut3HGI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(dataset_dir)\n",
        "#df_bad = pd.read_excel(bad_essays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_XKtKqqUXXZ"
      },
      "outputs": [],
      "source": [
        "#df.shape,df_bad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Tytoiv3Vc8p1",
        "outputId": "a69d73c1-f180-4976-dff8-9be5fdd706a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Timestamp Contributor                        Topic  \\\n",
              "0 2021-06-20 05:36:05.410         Tin                        Bacon   \n",
              "1 2021-06-20 05:47:07.236         Tin  “Beyond Plug-and-Chug Math”   \n",
              "2 2021-06-20 06:00:53.430         Tin   “A Different Kind of love”   \n",
              "3 2021-06-20 06:12:52.684         Tin   “From Flaubert to Frisbee”   \n",
              "4 2021-06-20 06:20:05.473         Tin              Raising the Bar   \n",
              "\n",
              "         Writing Style                                         Essay Text  \\\n",
              "0            Narrative  THE ALARM CLOCK IS, TO MANY high school studen...   \n",
              "1           Persuasive  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   \n",
              "2  Narrative, Personal  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...   \n",
              "3           Persuasive  THIS SUMMER, I WENT TO THE governor’s Honors P...   \n",
              "4            Narrative  THIS PAST SUMMER I HAD THE opportunity to part...   \n",
              "\n",
              "    Essay Grading                              University Name  \\\n",
              "0   Average (B-C)                              Duke University   \n",
              "1   Average (B-C)  MIT - Massachusetts Institute of Technology   \n",
              "2  Excellent (A+)                          Stanford University   \n",
              "3   Average (B-C)                             Brown University   \n",
              "4   Average (B-C)                                          NaN   \n",
              "\n",
              "  Education Program Relevant Field (Major/ Subject of study etc)  \\\n",
              "0         Bachelors                                          NaN   \n",
              "1         Bachelors                                  Mathematics   \n",
              "2         Bachelors                             Spanish Language   \n",
              "3           Masters                                   Literature   \n",
              "4           Masters                     Engineering and Sciences   \n",
              "\n",
              "                                      Reference Link  \\\n",
              "0  http://www.qianmu.org/u/lystu/school/file/0hme...   \n",
              "1  http://www.qianmu.org/u/lystu/school/file/0hme...   \n",
              "2  http://www.qianmu.org/u/lystu/school/file/0hme...   \n",
              "3  http://www.qianmu.org/u/lystu/school/file/0hme...   \n",
              "4  http://www.qianmu.org/u/lystu/school/file/0hme...   \n",
              "\n",
              "  Comments (is something unusual about the essay?)  \n",
              "0                                              NaN  \n",
              "1                                              NaN  \n",
              "2                                              NaN  \n",
              "3                                              NaN  \n",
              "4                                              NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28223355-1720-4d07-8b87-4ee97968606d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Contributor</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Writing Style</th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>University Name</th>\n",
              "      <th>Education Program</th>\n",
              "      <th>Relevant Field (Major/ Subject of study etc)</th>\n",
              "      <th>Reference Link</th>\n",
              "      <th>Comments (is something unusual about the essay?)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-20 05:36:05.410</td>\n",
              "      <td>Tin</td>\n",
              "      <td>Bacon</td>\n",
              "      <td>Narrative</td>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>Duke University</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www.qianmu.org/u/lystu/school/file/0hme...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-20 05:47:07.236</td>\n",
              "      <td>Tin</td>\n",
              "      <td>“Beyond Plug-and-Chug Math”</td>\n",
              "      <td>Persuasive</td>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>MIT - Massachusetts Institute of Technology</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Mathematics</td>\n",
              "      <td>http://www.qianmu.org/u/lystu/school/file/0hme...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-20 06:00:53.430</td>\n",
              "      <td>Tin</td>\n",
              "      <td>“A Different Kind of love”</td>\n",
              "      <td>Narrative, Personal</td>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Spanish Language</td>\n",
              "      <td>http://www.qianmu.org/u/lystu/school/file/0hme...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-20 06:12:52.684</td>\n",
              "      <td>Tin</td>\n",
              "      <td>“From Flaubert to Frisbee”</td>\n",
              "      <td>Persuasive</td>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>Brown University</td>\n",
              "      <td>Masters</td>\n",
              "      <td>Literature</td>\n",
              "      <td>http://www.qianmu.org/u/lystu/school/file/0hme...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-20 06:20:05.473</td>\n",
              "      <td>Tin</td>\n",
              "      <td>Raising the Bar</td>\n",
              "      <td>Narrative</td>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Masters</td>\n",
              "      <td>Engineering and Sciences</td>\n",
              "      <td>http://www.qianmu.org/u/lystu/school/file/0hme...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28223355-1720-4d07-8b87-4ee97968606d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28223355-1720-4d07-8b87-4ee97968606d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28223355-1720-4d07-8b87-4ee97968606d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTroWxu4w7mG"
      },
      "outputs": [],
      "source": [
        "#df_bad.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7UiCVjwUd6z"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2vy50-9V4JT",
        "outputId": "a8512c8b-690e-4adf-9928-0d9cb2259561"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Average (B-C)     401\n",
              "Excellent (A+)    288\n",
              "Bad (D-F)          45\n",
              "Name: Essay Grading, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#df_essays_recovery = df_essays.copy()\n",
        "df_essays = df[['Essay Text','Essay Grading']]\n",
        "df_essays['Essay Grading'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvw4jtnoyyaL"
      },
      "outputs": [],
      "source": [
        "#df_bad.rename(columns={'Essay_Text':'Essay Text','Grade':'Essay Grading'},inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twrevbUJWPZc"
      },
      "outputs": [],
      "source": [
        "#df_essays = pd.concat([df_initial,df_bad])\n",
        "#df_essays = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DehIzrY0yUUr",
        "outputId": "72ae450b-b862-46c7-d27a-047f029449b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)\n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)\n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)\n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)\n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad989cef-70d9-4ab8-a889-fffdb4e3d52d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad989cef-70d9-4ab8-a889-fffdb4e3d52d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad989cef-70d9-4ab8-a889-fffdb4e3d52d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad989cef-70d9-4ab8-a889-fffdb4e3d52d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_essays.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMiVrckTy0mC",
        "outputId": "ca0dd120-72f7-4cf4-d6bd-e16139722890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Essay Text       object\n",
              "Essay Grading    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ5vybzyzEBe",
        "outputId": "90582729-8c9f-413e-99b8-4758e56c13e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Average (B-C)     401\n",
              "Excellent (A+)    288\n",
              "Bad (D-F)          45\n",
              "Name: Essay Grading, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_essays['Essay Grading'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whKJ5ctrffwa"
      },
      "source": [
        "# **FEATURE EXTRACTION FROM ESSAY'S ASCII TEST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Zv7fITm-Ko"
      },
      "source": [
        "## **COUNTING SENTENCES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgiBkzMggmCf"
      },
      "outputs": [],
      "source": [
        "def count_sentences(essay):\n",
        "  doc = nlp(essay)\n",
        "  doc_sents = [sent for sent in doc.sents]\n",
        "  return len(doc_sents)\n",
        "  \n",
        "  # return len(list(doc.sents))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prm-9nSyeOzx",
        "outputId": "e35fc375-ad4b-41d3-984d-ba8943a2b0bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "str1 = '“I wanna go home!” I say as I sit on the kitchen floor watching my mother cook. “What do you mean?” she asks, giving me a questioning look. “Ethiopia?” “I don’t know.” Home. For most people, the word can be easily defined as the place where they grew up or live now. By that definition, the house in which I have lived for the past seven years would be my home. The problem is, I often find myself saying, “I wanna go home,” while sitting in that very house. The other candidate is the place where I grew up, but that could be either of two places: my home country of Ethiopia or my adopted hometown of Westbrook, Maine. I cannot choose one over the other. For better or for worse, each has shaped the person I am today more than can be expressed in words. Ethiopia is the place where I experienced so many of my “firsts.” Maine is the place where I developed my individuality. At the same time, neither can truly be my home. Though Ethiopia was my home at one point, it is no longer the same place I knew as a child because I am no longer that child. I can no longer relate to the culture the way I once did. As my sister often tells me, I have become “Americanized.” On the other hand, I have never felt at home in Maine. The first memory I have of Maine is my first day visiting Reiche Elementary, the school I would be attending. I stood in front of a group of seven- and eight-year-old boys and girls. Every face was pointed at me, every pair of eyes wide and expectant. I grabbed the fabric of my mother’s skirt and buried my face into the side of her leg. These children were all so different. Every child had a skin color different from mine. Though I picked out a few familiar words, I could not understand what they were saying. I knew I didn’t belong there, but there was no chance of hopping on a plane and going back to Ethiopia. I knew that, and the thought terrified me. I had never felt as uncomfortable and uncertain as I did that day. That day has stayed with me, along with the discomfort and uncertainty. Though the intensity of those feelings has faded, it has not gone away, and it is not likely to leave me soon. I cannot deny, however, that the environment Maine has provided has shaped me profoundly. Living in Maine has made me who I am today just as much as being born and raised in Ethiopia. Ethiopia gave me my cultural and family identity. Ethiopia is the place that comes to mind when I think of my family, since my entire extended family remains there. It is also the place that comes to mind when I think of my motivation, since I was raised in a culture that taught me to give one hundred percent at all times. Yet, the fact remains that I have lived in Maine for nearly ten years of my life. This environment has influenced me more than even I can comprehend. So, the question becomes: which of these places (if either) should I consider my home? In all honesty, I cannot choose one physical place and give it the title of “home.” Instead, I elect to compose my own definition of home, a definition that does not force me to choose between the two places in which I grew up. My definition allows me to think of home as a place in my mind, a state of mind that enables me to remember my childhood years in Ethiopia and the opportunities given to me by living in the U.S. It has taken a long time to define what home means to me — and even longer to find it — but doing so has given me an amazing sense of hope and comfort. In my mind, it is a place where I can escape. It is a place from which I draw strength when life gets too hectic or when I am faced with challenges that seem too great to overcome. It is what I really mean — what I have always meant — when I say that I want to go home.'\n",
        "count_sentences(str1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFPH87zSevv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6628cc54-e30c-4381-965d-78ac915d63ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "df_essays['SentenceCount'] = df_essays['Essay Text'].apply(count_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "BJNQzf5Lfy25",
        "outputId": "c3bf4522-6dab-4bd7-c193-cb6894e220b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "5  My eyes widen. “It’s all Greek to me,” I whisp...  Excellent (A+)   \n",
              "6  I could still hear her words, the words my tea...   Average (B-C)   \n",
              "7  It was a wet and dreary October evening. I sho...   Average (B-C)   \n",
              "8  Oreos. On the exterior, a firm chocolate crust...   Average (B-C)   \n",
              "9  Whether I was blowing out candles, writing a l...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  \n",
              "0             35  \n",
              "1             28  \n",
              "2             40  \n",
              "3             20  \n",
              "4             23  \n",
              "5             46  \n",
              "6             31  \n",
              "7             30  \n",
              "8             43  \n",
              "9             21  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35bccdaa-bc98-4d96-a3bc-dff44e75e83f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>My eyes widen. “It’s all Greek to me,” I whisp...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I could still hear her words, the words my tea...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>It was a wet and dreary October evening. I sho...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Oreos. On the exterior, a firm chocolate crust...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Whether I was blowing out candles, writing a l...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35bccdaa-bc98-4d96-a3bc-dff44e75e83f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35bccdaa-bc98-4d96-a3bc-dff44e75e83f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35bccdaa-bc98-4d96-a3bc-dff44e75e83f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df_essays[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "aUjVRoOwieWV",
        "outputId": "af1ef6c3-4d83-4e3a-9da9-04c777bb9b4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'“Jooooorrrrddddannnnn,” my mom screamed with utter fear and panic in her voice. Surprisingly, amongst all of the chaos, her voice was all that I heard. I’m not sure if I was disoriented, bewildered or just in complete shock but at that particular moment, I felt nothing. That feeling of nothingness lasted 2.5 seconds because then the excruciating pain began. My knee felt as if someone had hit me with a Mack truck going 90 miles per hour. For the first time in my life, I had experienced real pain. I was 10 years old and I shattered my knee.\\nI have always been a well rounded student. My focus has always been on my school and everything that comes along with it, which included extra-curricular activities. I was an avid gymnast. I had been in gymnastics since I was 3 years old. My parents were both extremely athletic. My dad was an All-American college football player and my mom was a cheerleader, so it was only fitting that I participated in something athletically strenuous as well. They decided the earlier I began, the better I would be. I tried gymnastics and fell in love. I became a star athlete. I won several trophies and had my picture on posters, and at bus stops. We also took pictures next to the bus stops that had my picture there. My dad brags about the fact that Chelsea Piers in New York City had a poster of me hung in the lobby as soon as you entered. I had been traveling regularly for gymnastics meets and I was on top of the world.\\nI practiced every day after school as well as on weekends. I had just had my 10th birthday and I was at gymnastics practice as usual. I remember the day being rainy and dreary. It was my turn to get on the uneven bars. You would think that I would have a gut feeling or something but there was nothing. I did everything regularly but something happened on the dismount. I didn’t get enough air prior to landing and that led to my feet not properly planting and my knee taking the brunt of the impact. I was rushed to the hospital and received several knee surgeries. To this day I have a 4 inch long and ½ inch wide scar on my knee. I did gymnastics for another year and my parents decided that they couldn’t afford it anymore. I eventually turned all my energy into my studies and volunteer activities and that’s when I discovered my love of helping others.\\nOver the next couple years, I stayed focused and found a new outlet for my athletic nature. I joined my high school weightlifting team and have been so for the past 3 years. I won the conference competition 2 years in a row and I’m currently working on the 3rd one. My goal is to receive the title of strongest girl in Seminole County. I was also featured in the newspaper, which made my parents extremely proud. In addition to school and weightlifting, I work at Universal Studios in Orlando, FL. I love my job. My favorite part is interacting with tourists and the regulars. I am extremely personable and this job allows me to improve my interactive skills because I deal with people from different walks of life.\\nI have always been told that I am extremely mature for my age. I just feel that I have been honored and blessed to have had experiences that I have had. I know what it feels like to receive and I have learned what it is like to give back to others. I find great enjoyment in being a support system for people who needs it. I am a part of the anti-bullying club and I volunteer at numerous soup kitchens on a monthly basis. I love the feeling that it gives me. This feeling has lead me to want to enter the medical field where I can help people. Just like my doctors, coaches, family, and friends have helped me over the years. My goal is to become an obstetrician. I have also learned that working at Universal Studios forces me to remember that life is about having fun. It doesn’t matter how old you become, fun never ages. The way you have fun might change, but having fun itself never gets old.\\nMy diverse experiences, personable nature, and desire to give back to others would be a great asset to the university.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_essays.iloc[700].values[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eAUJiVinI55"
      },
      "source": [
        "## **COUNTING WORDS w/o STOP WORDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvtu9ecSk3Lo"
      },
      "outputs": [],
      "source": [
        "#nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kEbKR23ltbS",
        "outputId": "8822855c-9c5b-464d-e91a-e903a6dc4d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "#nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv9-wnJ3lkNg"
      },
      "outputs": [],
      "source": [
        "# word_tokens = word_tokenize(df_essays.iloc[729].values[0])\n",
        "# stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB6RJteKi_RG"
      },
      "outputs": [],
      "source": [
        "# def count_non_stop_words(essay):\n",
        "#   word_tokens = word_tokenize(essay)\n",
        "#   filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "#   return len(filtered_sentence)\n",
        "# def count_non_stop_words(essay):\n",
        "#   word_tokens = word_tokenize(essay)\n",
        "#   filtered_sentence = [w for w in word_tokens]\n",
        "#   return len(filtered_sentence)\n",
        "def count_all_words(essay):\n",
        "  doc = nlp(essay)\n",
        "  return(len(doc))\n",
        "  # filtered_sentence = []\n",
        "  # for tok in doc:\n",
        "  #   if tok.is_stop == False:\n",
        "  #     filtered_sentence.append(tok)\n",
        "  # print(filtered_sentence)\n",
        "  # return len(filtered_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = '“I wanna go home!” I say as I sit on the kitchen floor watching my mother cook. “What do you mean?” she asks, giving me a questioning look. “Ethiopia?” “I don’t know.” Home. For most people, the word can be easily defined as the place where they grew up or live now. By that definition, the house in which I have lived for the past seven years would be my home. The problem is, I often find myself saying, “I wanna go home,” while sitting in that very house. The other candidate is the place where I grew up, but that could be either of two places: my home country of Ethiopia or my adopted hometown of Westbrook, Maine. I cannot choose one over the other. For better or for worse, each has shaped the person I am today more than can be expressed in words. Ethiopia is the place where I experienced so many of my “firsts.” Maine is the place where I developed my individuality. At the same time, neither can truly be my home. Though Ethiopia was my home at one point, it is no longer the same place I knew as a child because I am no longer that child. I can no longer relate to the culture the way I once did. As my sister often tells me, I have become “Americanized.” On the other hand, I have never felt at home in Maine. The first memory I have of Maine is my first day visiting Reiche Elementary, the school I would be attending. I stood in front of a group of seven- and eight-year-old boys and girls. Every face was pointed at me, every pair of eyes wide and expectant. I grabbed the fabric of my mother’s skirt and buried my face into the side of her leg. These children were all so different. Every child had a skin color different from mine. Though I picked out a few familiar words, I could not understand what they were saying. I knew I didn’t belong there, but there was no chance of hopping on a plane and going back to Ethiopia. I knew that, and the thought terrified me. I had never felt as uncomfortable and uncertain as I did that day. That day has stayed with me, along with the discomfort and uncertainty. Though the intensity of those feelings has faded, it has not gone away, and it is not likely to leave me soon. I cannot deny, however, that the environment Maine has provided has shaped me profoundly. Living in Maine has made me who I am today just as much as being born and raised in Ethiopia. Ethiopia gave me my cultural and family identity. Ethiopia is the place that comes to mind when I think of my family, since my entire extended family remains there. It is also the place that comes to mind when I think of my motivation, since I was raised in a culture that taught me to give one hundred percent at all times. Yet, the fact remains that I have lived in Maine for nearly ten years of my life. This environment has influenced me more than even I can comprehend. So, the question becomes: which of these places (if either) should I consider my home? In all honesty, I cannot choose one physical place and give it the title of “home.” Instead, I elect to compose my own definition of home, a definition that does not force me to choose between the two places in which I grew up. My definition allows me to think of home as a place in my mind, a state of mind that enables me to remember my childhood years in Ethiopia and the opportunities given to me by living in the U.S. It has taken a long time to define what home means to me — and even longer to find it — but doing so has given me an amazing sense of hope and comfort. In my mind, it is a place where I can escape. It is a place from which I draw strength when life gets too hectic or when I am faced with challenges that seem too great to overcome. It is what I really mean — what I have always meant — when I say that I want to go home.'\n",
        "count_all_words(str1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1ynXOBLvIC6",
        "outputId": "5d6eb108-d98c-4234-c77d-b50b28ff31c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "835"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crbb4-tokwAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d46d4c-4698-4f2f-b64b-524312531a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "df_essays['WordCount'] = df_essays['Essay Text'].apply(count_all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TTq9tyy4mFho",
        "outputId": "05a4d993-92e5-4ceb-b724-849764b910c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  WordCount  \n",
              "0             35        816  \n",
              "1             28        587  \n",
              "2             40       1005  \n",
              "3             20        571  \n",
              "4             23        549  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f55eed5-4b41-45d6-8f76-b1a679456b45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f55eed5-4b41-45d6-8f76-b1a679456b45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f55eed5-4b41-45d6-8f76-b1a679456b45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f55eed5-4b41-45d6-8f76-b1a679456b45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df_essays.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z4kWIEoUlVN"
      },
      "outputs": [],
      "source": [
        "#df_essays_mini = df_essays[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rlptvRvnNZo"
      },
      "source": [
        "## **COUNTING PARTS OF SPEECH**\n",
        "\n",
        "https://stackabuse.com/python-for-nlp-parts-of-speech-tagging-and-named-entity-recognition/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wPh_gWUnpVc"
      },
      "outputs": [],
      "source": [
        "def count_feature(postag,essay,wordcount,roundval):\n",
        "  doc=nlp(essay)\n",
        "  pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "  for k,v in sorted(pos_counts.items()):\n",
        "    if doc.vocab[k] == postag:\n",
        "      return round(v/wordcount,roundval)\n",
        "\n",
        "# def count_verb(essay,wordcount):\n",
        "#   doc=nlp(essay)\n",
        "#   pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "#   for k,v in sorted(pos_counts.items()):\n",
        "#     if doc.vocab[k] == 'VERB':\n",
        "#       return round(v/wordcount,0)\n",
        "\n",
        "# def count_noun(essay,wordcount):\n",
        "#   doc=nlp(essay)\n",
        "#   pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "#   for k,v in sorted(pos_counts.items()):\n",
        "#     if doc.vocab[k] == 'NOUN':\n",
        "#       return round(v/wordcount,0)\n",
        "\n",
        "# def count_adjective(essay,wordcount):\n",
        "#   doc=nlp(essay)\n",
        "#   pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "#   for k,v in sorted(pos_counts.items()):\n",
        "#     if doc.vocab[k] == 'ADJ':\n",
        "#       return round(v/wordcount,0)\n",
        "\n",
        "# def count_adverb(essay,wordcount):\n",
        "#   doc=nlp(essay)\n",
        "#   pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "#   for k,v in sorted(pos_counts.items()):\n",
        "#     if doc.vocab[k] == 'ADV':\n",
        "#       return round(v/wordcount,0)    \n",
        "\n",
        "# def count_pronoun(essay,wordcount):\n",
        "#   doc=nlp(essay)\n",
        "#   pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "#   for k,v in sorted(pos_counts.items()):\n",
        "#     if doc.vocab[k] == 'PRON':\n",
        "#       return round(v/wordcount,0)\n",
        "\n",
        "# def count_punctuations(essay,wordcount):\n",
        "#   doc=nlp(essay)\n",
        "#   pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "#   for k,v in sorted(pos_counts.items()):\n",
        "#     if doc.vocab[k] == 'PUNCT':\n",
        "#       return round(v/wordcount,0)                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8pJxJsPqgNi"
      },
      "outputs": [],
      "source": [
        "# df_essays['VerbCount']  = df_essays.apply(lambda x: count_feature('VERB',x['Essay Text'], 1,0), axis=1)\n",
        "# df_essays['NounCount']  = df_essays.apply(lambda x: count_feature('NOUN',x['Essay Text'], 1,0), axis=1)\n",
        "# df_essays['AdjCount']  = df_essays.apply(lambda x: count_feature('ADJ',x['Essay Text'], 1,0), axis=1)\n",
        "# df_essays['AdverbCount']  = df_essays.apply(lambda x: count_feature('ADV',x['Essay Text'], 1,0), axis=1)\n",
        "# df_essays['PronounCount']  = df_essays.apply(lambda x: count_feature('PRON',x['Essay Text'], 1,0), axis=1)\n",
        "# df_essays['PunctCount']  = df_essays.apply(lambda x: count_feature('PUNCT',x['Essay Text'], 1,0), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pnQqU6qseKf"
      },
      "outputs": [],
      "source": [
        "# df_essays.hist(figsize=(10,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4frdERS6g3c-"
      },
      "source": [
        "# Day 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4i17yI24l_g"
      },
      "source": [
        "# **Normalizing the grades distribution by Feature Counts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yaTeLHvAmUR"
      },
      "outputs": [],
      "source": [
        "# def display_stack_bar(col1,col2,title,xlabel,buffer,binsize):\n",
        "#   df_new = pd.DataFrame()\n",
        "#   bins_created = np.arange(min(df_essays[col1])-buffer, max(df_essays[col1]) + buffer, binsize) \n",
        "#   df_essays[col2] = pd.cut(df_essays[col1], bins=bins_created)\n",
        "#   df_essays.sort_values(by = col1,inplace=True)\n",
        "#   counts = df_essays.groupby([col2,'Essay Grading'],sort=False).SentenceCount.count().unstack()\n",
        "#   df_essays.drop([col2], axis=1,inplace=True)\n",
        "#   counts.replace(np.nan,0,inplace=True)\n",
        "#   counts[\"sum\"] = counts.sum(axis=1)\n",
        "#   df_new['Average (B-C)'] = counts['Average (B-C)']/counts['sum']\n",
        "#   df_new['Excellent (A+)'] = counts['Excellent (A+)']/counts['sum']\n",
        "#   df_new['Bad (D-F)'] = counts['Bad (D-F)']/counts['sum']\n",
        "#   ax = df_new.plot.bar(stacked=True,figsize=(10,10),width = 0.5)\n",
        "#   for p in ax.patches:\n",
        "#     width, height = p.get_width(), p.get_height()\n",
        "#     x, y = p.get_xy() \n",
        "#     ax.text(x+width/2, \n",
        "#             y+height/2, \n",
        "#             round(height,2), \n",
        "#             horizontalalignment='center', \n",
        "#             verticalalignment='center')  \n",
        "#   plt.title(title,fontsize=18)\n",
        "#   plt.xlabel(xlabel,fontsize=18)\n",
        "#   plt.xticks(fontsize=14,rotation=45)\n",
        "#   plt.ylabel('Number of Entries',fontsize=18)\n",
        "#   plt.show()\t\n",
        "\n",
        "# display_stack_bar('SentenceCount','SentenceCountCategory','Sentence Count for Different Grades','Sentence Counts',4,20)\n",
        "# display_stack_bar('WordCount','WordCountCategory','Word Count for Different Grades','Word Counts',30,100)\n",
        "# display_stack_bar('VerbCount','VerbCountCategory','Verb Count for Different Grades','Verb Counts',10,30)\n",
        "# display_stack_bar('NounCount','NounCountCategory','Noun Count for Different Grades','Noun Counts',10,50)\n",
        "# display_stack_bar('AdjCount','AdjectivesCountCategory','Adjectives Count for Different Grades','Adjective Counts',5,20)\n",
        "# display_stack_bar('AdverbCount','AdverbCountCategory','Adverb Count for Different Grades','Adverb Counts',2,10)\n",
        "# display_stack_bar('PronounCount','PronounCountCategory','Pronoun Count for Different Grades','Pronoun Counts',1,30)\n",
        "# display_stack_bar('PunctCount','PunctCountCategory','Punctuations Count for Different Grades','Punctuations Counts',10,25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIzaOkYtUuKu"
      },
      "source": [
        "# **Calculating VERB/NOUN/ADJ.... density**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H-9bMiksDIoS",
        "outputId": "05a63bf1-65ea-41d9-fd8c-60107ee79f47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5acb81ce-087a-4dca-9350-59ae7b64be03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>As a Chemistry student in Singapore Polytechni...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>14</td>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>At age 6, I remember the light filled openness...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>44</td>\n",
              "      <td>746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>When it comes to service workers, as a society...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>34</td>\n",
              "      <td>683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>The most exciting part was the laptop.\\nMy mom...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>33</td>\n",
              "      <td>769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>I live on the edge.\\nI live at the place where...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>42</td>\n",
              "      <td>559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5acb81ce-087a-4dca-9350-59ae7b64be03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5acb81ce-087a-4dca-9350-59ae7b64be03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5acb81ce-087a-4dca-9350-59ae7b64be03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Essay Text  ... WordCount\n",
              "729  As a Chemistry student in Singapore Polytechni...  ...       328\n",
              "730  At age 6, I remember the light filled openness...  ...       746\n",
              "731  When it comes to service workers, as a society...  ...       683\n",
              "732  The most exciting part was the laptop.\\nMy mom...  ...       769\n",
              "733  I live on the edge.\\nI live at the place where...  ...       559\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df_essays.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmBetysJNbLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202129c6-cafa-4ee6-badf-914f505577bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "df_essays['VerbCount']  = df_essays.apply(lambda x: count_feature('VERB',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "df_essays['NounCount']  = df_essays.apply(lambda x: count_feature('NOUN',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "df_essays['AdjCount']  = df_essays.apply(lambda x: count_feature('ADJ',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "df_essays['AdverbCount']  = df_essays.apply(lambda x: count_feature('ADV',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "df_essays['PronounCount']  = df_essays.apply(lambda x: count_feature('PRON',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "df_essays['PunctCount']  = df_essays.apply(lambda x: count_feature('PUNCT',x['Essay Text'], x['WordCount'],2), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Al20TUO1Ne2Q",
        "outputId": "252cf425-ad1a-41e0-e153-3d046dd0ca56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Essay Text   Essay Grading  \\\n",
              "729  As a Chemistry student in Singapore Polytechni...   Average (B-C)   \n",
              "730  At age 6, I remember the light filled openness...  Excellent (A+)   \n",
              "731  When it comes to service workers, as a society...  Excellent (A+)   \n",
              "732  The most exciting part was the laptop.\\nMy mom...  Excellent (A+)   \n",
              "733  I live on the edge.\\nI live at the place where...  Excellent (A+)   \n",
              "\n",
              "     SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "729             14        335       0.14       0.17      0.05         0.05   \n",
              "730             44        749       0.13       0.21      0.04         0.04   \n",
              "731             34        700       0.13       0.24      0.06         0.05   \n",
              "732             33        785       0.11       0.19      0.09         0.05   \n",
              "733             42        567       0.11       0.26      0.04         0.03   \n",
              "\n",
              "     PronounCount  PunctCount  \n",
              "729          0.07        0.10  \n",
              "730          0.07        0.11  \n",
              "731          0.06        0.11  \n",
              "732          0.07        0.12  \n",
              "733          0.07        0.11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-826d2126-455b-4bd8-b9f7-e3b53063de6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>As a Chemistry student in Singapore Polytechni...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>14</td>\n",
              "      <td>335</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>At age 6, I remember the light filled openness...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>44</td>\n",
              "      <td>749</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>When it comes to service workers, as a society...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>34</td>\n",
              "      <td>700</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>The most exciting part was the laptop.\\nMy mom...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>33</td>\n",
              "      <td>785</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733</th>\n",
              "      <td>I live on the edge.\\nI live at the place where...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>42</td>\n",
              "      <td>567</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-826d2126-455b-4bd8-b9f7-e3b53063de6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-826d2126-455b-4bd8-b9f7-e3b53063de6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-826d2126-455b-4bd8-b9f7-e3b53063de6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df_essays.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7686uu1VEbY"
      },
      "source": [
        "# **Let's visualize the dataset for normalization (w/o normalization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac-bX8h7VZAs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        },
        "outputId": "3aafb8ed-afbf-4cbd-d4d2-604e25f714e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0  20  40  60  80 100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def display_stack_bar(col1,col2,title,xlabel,buffer,binsize):\n",
        "  bins_created = np.arange(min(df_essays[col1])-buffer, max(df_essays[col1]) + buffer, binsize) \n",
        "  print(bins_created)\n",
        "  bins_created = [0,100]\n",
        "  df_essays[col2] = pd.cut(df_essays[col1], bins=bins_created)\n",
        "  df_essays.sort_values(by = col1,inplace=True)\n",
        "  counts = df_essays.groupby([col2,'Essay Grading'],sort=False).SentenceCount.count().unstack()\n",
        "  df_essays.drop([col2], axis=1,inplace=True)\n",
        "  counts.replace(np.nan,0,inplace=True)\n",
        "  ax = counts.plot.bar(stacked=True,figsize=(10,10),width = 0.5)\n",
        "  for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy() \n",
        "    ax.text(x+width/2, \n",
        "            y+height/2, \n",
        "            round(height,2), \n",
        "            horizontalalignment='center', \n",
        "            verticalalignment='center')  \n",
        "  plt.title(title,fontsize=18)\n",
        "  plt.xlabel(xlabel,fontsize=18)\n",
        "  plt.xticks(fontsize=14,rotation=45)\n",
        "  plt.ylabel('Number of Entries',fontsize=18)\n",
        "  plt.show()\t\n",
        "\n",
        "display_stack_bar('SentenceCount','SentenceCountCategory','Sentence Count for Different Grades','Sentence Counts',4,20)\n",
        "# display_stack_bar('WordCount','WordCountCategory','Word Count for Different Grades','Word Counts',30,100)\n",
        "# display_stack_bar('VerbCount','VerbCountCategory','Verb Count for Different Grades','Verb Counts',0,.05)\n",
        "# # display_stack_bar('NounCount','NounCountCategory','Noun Count for Different Grades','Noun Counts',10,50)\n",
        "# display_stack_bar('AdjCount','AdjectivesCountCategory','Adjectives Count for Different Grades','Adjective Counts',5,20)\n",
        "# display_stack_bar('AdverbCount','AdverbCountCategory','Adverb Count for Different Grades','Adverb Counts',2,10)\n",
        "# display_stack_bar('PronounCount','PronounCountCategory','Pronoun Count for Different Grades','Pronoun Counts',1,30)\n",
        "# display_stack_bar('PunctCount','PunctCountCategory','Punctuations Count for Different Grades','Punctuations Counts',10,25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DsFYa3tVpjO"
      },
      "source": [
        "# **Scatter Plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1N8ChpuVsGo"
      },
      "outputs": [],
      "source": [
        "# dict  = {2:'Excellent (A+)',1:'Average (B-C)',0:'Bad (D-F)'}\n",
        "# # Split the data into features and target label\n",
        "\n",
        "# df_essays_copy = df_essays.copy()\n",
        "\n",
        "# df_essays_copy['Essay Grading'] = df_essays_copy['Essay Grading'].apply(lambda x:2 if x==\"Excellent (A+)\" else 1 if x=='Average (B-C)' else 0)\n",
        "# df_essays_copy.drop(['Essay Text'], axis = 1,inplace=True,errors='ignore')\n",
        "# data = np.asarray(df_essays_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6VCaUpLV021"
      },
      "outputs": [],
      "source": [
        "# X = data[:,0:2] # SentenceCount WordCount\n",
        "# y = data[:,-1]\n",
        "\n",
        "# plt.figure(figsize=(8, 8), dpi=80)\n",
        "# plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k',label=dict[0])\n",
        "# plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k',label=dict[1])\n",
        "# plt.scatter(X[np.argwhere(y==2).flatten(),0], X[np.argwhere(y==2).flatten(),1],s = 50, color = 'yellow', edgecolor = 'k',label=dict[2])\n",
        "# plt.xlabel('SentenceCount')\n",
        "# plt.ylabel('WordCount')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpZ8rno-cq_A"
      },
      "outputs": [],
      "source": [
        "# X = data[:,6:8] # PronounCount PunctCount\n",
        "# y = data[:,-1]\n",
        "\n",
        "# plt.figure(figsize=(8, 8), dpi=80)\n",
        "# plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k',label=dict[0])\n",
        "# plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k',label=dict[1])\n",
        "# plt.scatter(X[np.argwhere(y==2).flatten(),0], X[np.argwhere(y==2).flatten(),1],s = 50, color = 'yellow', edgecolor = 'k',label=dict[2])\n",
        "# plt.xlabel('PronounCount')\n",
        "# plt.ylabel('PunctuationCount')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z8SF4tYczKH"
      },
      "outputs": [],
      "source": [
        "# X = data[:,4:6] # Adjective AdverbCount\n",
        "# y = data[:,-1]\n",
        "\n",
        "# plt.figure(figsize=(8, 8), dpi=80)\n",
        "# plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k',label=dict[0])\n",
        "# plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k',label=dict[1])\n",
        "# plt.scatter(X[np.argwhere(y==2).flatten(),0], X[np.argwhere(y==2).flatten(),1],s = 50, color = 'yellow', edgecolor = 'k',label=dict[2])\n",
        "# plt.xlabel('AdjectiveCount')\n",
        "# plt.ylabel('AdverbCount')\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FP11tulrc2SP"
      },
      "outputs": [],
      "source": [
        "# X = data[:,2:4] # VerbCount NounCount\n",
        "# y = data[:,-1]\n",
        "\n",
        "# plt.figure(figsize=(8, 8), dpi=80)\n",
        "# plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k',label=dict[0])\n",
        "# plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k',label=dict[1])\n",
        "# plt.scatter(X[np.argwhere(y==2).flatten(),0], X[np.argwhere(y==2).flatten(),1],s = 50, color = 'yellow', edgecolor = 'k',label=dict[2])\n",
        "# plt.xlabel('VerbCount')\n",
        "# plt.ylabel('NounCount')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF7tAlOz08sF"
      },
      "source": [
        "# **ROUGH WORK START**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_Qq2AJExHmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f8bcdc-b80e-438b-b380-85916e8a620f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4389: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ]
        }
      ],
      "source": [
        "df_essays.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNFDbCl3xLPp",
        "outputId": "1815f30c-cd87-443f-c707-01187194767b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Essay Text       0\n",
              "Essay Grading    0\n",
              "SentenceCount    0\n",
              "WordCount        0\n",
              "VerbCount        0\n",
              "NounCount        0\n",
              "AdjCount         0\n",
              "AdverbCount      0\n",
              "PronounCount     0\n",
              "PunctCount       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "df_essays.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SGZchNWxSi8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf25b639-01a4-43c1-af3e-701f48b4051c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "df_essays.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-20AddjxUpT",
        "outputId": "1b43047c-9129-4b67-985e-f1b4369cc8f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Essay Text       0\n",
              "Essay Grading    0\n",
              "SentenceCount    0\n",
              "WordCount        0\n",
              "VerbCount        0\n",
              "NounCount        0\n",
              "AdjCount         0\n",
              "AdverbCount      0\n",
              "PronounCount     0\n",
              "PunctCount       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df_essays.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wD9Q2Y_p0mTo",
        "outputId": "a1fae20f-5ff2-411c-dc46-33d11077b315"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1fbd47e5-62b0-4b54-8bde-9a4ae63e9063\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>798</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>588</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>994</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>560</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>544</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fbd47e5-62b0-4b54-8bde-9a4ae63e9063')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1fbd47e5-62b0-4b54-8bde-9a4ae63e9063 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1fbd47e5-62b0-4b54-8bde-9a4ae63e9063');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Essay Text  ... PunctCount\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...  ...       0.13\n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...  ...       0.09\n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  ...       0.11\n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...  ...       0.11\n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...  ...       0.12\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "df_essays.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38DJtcvC1Wv5"
      },
      "source": [
        "# **ROUGH WORK END**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfjYexk7Y_El"
      },
      "source": [
        "# **Active/Passive Voice Feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji48QHBg1gej"
      },
      "outputs": [],
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# function to check the type of sentence\n",
        "# def checkForSentType(inputEssay):  \n",
        "#     # running the model on sentence\n",
        "#     doc = nlp(inputEssay)\n",
        "#     sents = list(doc.sents)\n",
        "\n",
        "#     passive_rule = [{'DEP':'nsubjpass'},{'DEP':'aux','OP':'*'},{'DEP':'auxpass'},{'TAG':'VBN'}]\n",
        "#     matcher.add('Passive',None,passive_rule)\n",
        "#     matches = matcher(doc)\n",
        "#     #return (len(matches)/len(sents),(len(sents)-len(matches))/len(sents))\n",
        "#     return ((len(sents)-len(matches))/len(sents))\n",
        "def check_passive_voice(inputEssay):\n",
        "  # # running the model on sentence\n",
        "  doc = nlp(inputEssay)\n",
        "  dep_list = []\n",
        "  passive_list = []\n",
        "  sents = list(doc.sents)\n",
        "\n",
        "  for sents in doc.sents:\n",
        "    dep_list = []\n",
        "    for token in sents:# Tokenize the sentence into words/tokens\n",
        "      #print(token.text, token.pos_, token.dep_)  # form a list of various syntactic dependencies  \n",
        "      dep_list.append(token.dep_)\n",
        "\n",
        "    if ('nsubjpass') in dep_list or ('auxpass') in dep_list:\n",
        "      passive_list.append(sents)\n",
        "\n",
        "  return (round((len(sents)-len(passive_list))/len(sents),2)) # returning active voice sentences density\n",
        "\n",
        "def check_passive_voice_new(inputEssay): # Not used\n",
        "  passive_dict = {}\n",
        "  # # running the model on sentence\n",
        "  doc = nlp(inputEssay.EssayText)\n",
        "  dep_list = []\n",
        "  passive_list = []\n",
        "  passive_dict_inner = {}\n",
        "\n",
        "  passive_rule2 = [{'DEP': 'auxpass'}]\n",
        "  matcher.add('Passive2',[passive_rule2])\n",
        "\n",
        "  for sents in doc.sents:\n",
        "    dep_list = []\n",
        "    offset_list = []\n",
        "    for token in sents:# Tokenize the sentence into words/tokens\n",
        "      #print(token.text, token.pos_, token.dep_)  # form a list of various syntactic dependencies  \n",
        "      dep_list.append(token.dep_)\n",
        "\n",
        "    if ('nsubjpass') in dep_list or ('auxpass') in dep_list:\n",
        "      passive_dict_inner[\"startIndex\"] = sents.start_char\n",
        "      passive_dict_inner[\"endIndex\"]   = sents.end_char\n",
        "      passive_dict_inner[\"text\"]       = sents.text \n",
        "\n",
        "      # # running the model on sentence\n",
        "      doc_sent = nlp(sents.text)\n",
        "      #print(doc_sent)\n",
        "      found_matches = matcher(doc_sent)\n",
        "      #print(found_matches)\n",
        "      for match_id, start, end in found_matches:\n",
        "        string_id = nlp.vocab.strings[match_id]  # get string representation\n",
        "        span = doc_sent[start:end+1]                    # get the matched span\n",
        "        #print(span)\n",
        "        offset_list.extend((match.start(),match.end()+1) for match in re.finditer(str(span), doc.text.lower())) # need to be done at whole document level and not sentence level to get offset from 1.\n",
        "      \n",
        "      passive_dict_inner[\"characteroffset\"] = offset_list\n",
        "      passive_list.append(passive_dict_inner.copy())      \n",
        "      #passive_list.append(dict(text = sents,startIndex = sents.start_char,endIndex = sents.end_char))\n",
        "\n",
        "  passive_dict = dict(color = \"#FFA500\", description = \"Passive voice\",passive_voice = passive_list)\n",
        "  return (passive_dict)\n",
        "\n",
        "#df_essays[['NumberofPassiveVoice','NumberofActiveVoice']] = df_essays.apply(lambda row: pd.Series(checkForSentType(row['Essay Text'])),axis=1) \n",
        "df_essays['NumberofActiveVoice'] = df_essays.apply(lambda row: pd.Series(check_passive_voice(row['Essay Text'])),axis=1) \n",
        "\n",
        "df_essays.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_3VrTuIZQIB"
      },
      "source": [
        "# **Complex, Compound Complex,Compound,Simple sentences Feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyrkQTr_1uGD"
      },
      "outputs": [],
      "source": [
        "def getCountTypeSent_old(essay_text):\n",
        "  complex_comp_list=[]\n",
        "  complex_list=[]\n",
        "  compound_list=[]\n",
        "  simple_list=[]\n",
        "  dep_list = []\n",
        "  docu = nlp(essay_text)\n",
        "  num_sent = len([sent for sent in docu.sents]) # Counting the number of sentences\n",
        "\n",
        "  for sents in docu.sents:\n",
        "    for token in sents:# Tokenize the sentence into words/tokens\n",
        "      #subtree argument gives the subtree of the token when parsed in dependency parsing.\n",
        "      subtree = token.subtree\n",
        "      #Looking at the ancestors of a token can tell us how deep it is\n",
        "      k = list(token.ancestors)\n",
        "      #we need to add this to make the indexing work properly\n",
        "      k.append('added_to_get_proper_indexing')\n",
        "      #k=2 gives us the first level of the tree, k=3 will give us the next level.\n",
        "      if(len(k)==2):\n",
        "        #print([(t.text) for t in subtree], token.dep_)\n",
        "        dep_list.append(token.dep_)\n",
        "      #we missed the root phrase in the previous \n",
        "      if(token.dep_=='ROOT'):\n",
        "        k =[token.text]\n",
        "      #print(k, 'root')\n",
        "\n",
        "    #complex sentences have (advcl) in their dependency tree\n",
        "    #compound sentences have (cc)-> coordination and (conj)-> conjuction in their dependency tree\n",
        "    #compound complex sentences have both the above\n",
        "    #simple sentences have neither.\n",
        "    if ('advcl') in dep_list and ('cc') in dep_list and ('conj') in dep_list:\n",
        "      complex_comp_list.append('Complex-compound sentence')\n",
        "    elif ('advcl') in dep_list:\n",
        "      complex_list.append('Complex sentence')\n",
        "    elif ('cc') in dep_list and ('conj') in dep_list:\n",
        "      compound_list.append('Compound sentence')\n",
        "    else:\n",
        "      simple_list.append('Simple sentence')\n",
        "  return (len(complex_comp_list)/num_sent,len(complex_list)/num_sent,len(compound_list)/num_sent,len(simple_list)/num_sent)\n",
        "  \n",
        "\n",
        "###### New functionality\n",
        "\n",
        "# Sentence type functionality start\n",
        "SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
        "OBJECTS = [\"dobj\", \"dative\", \"attr\", \"oprd\"]\n",
        "\n",
        "def getSubsFromConjunctions(subs):\n",
        "    moreSubs = []\n",
        "    for sub in subs:\n",
        "        # rights is a generator\n",
        "        rights = list(sub.rights)\n",
        "        #print(rights)\n",
        "        rightDeps = {tok.lower_ for tok in rights}\n",
        "        if \"and\" in rightDeps:\n",
        "            moreSubs.extend([tok for tok in rights if tok.dep_ in SUBJECTS or tok.pos_ == \"NOUN\"])\n",
        "            if len(moreSubs) > 0:\n",
        "                moreSubs.extend(getSubsFromConjunctions(moreSubs))\n",
        "    return moreSubs\n",
        "\n",
        "def findSubs(tok):\n",
        "    head = tok.head\n",
        "    while head.pos_ != \"VERB\" and head.pos_ != \"NOUN\" and head.head != head:\n",
        "        head = head.head\n",
        "    if head.pos_ == \"VERB\":\n",
        "        subs = [tok for tok in head.lefts if tok.dep_ == \"SUB\"]\n",
        "        if len(subs) > 0:\n",
        "            verbNegated = isNegated(head)\n",
        "            subs.extend(getSubsFromConjunctions(subs))\n",
        "            return subs, verbNegated\n",
        "        elif head.head != head:\n",
        "            return findSubs(head)\n",
        "    elif head.pos_ == \"NOUN\":\n",
        "        return [head], isNegated(tok)\n",
        "    return [], False\n",
        "\n",
        "def isNegated(tok):\n",
        "    negations = {\"no\", \"not\", \"n't\", \"never\", \"none\"}\n",
        "    for dep in list(tok.lefts) + list(tok.rights):\n",
        "        if dep.lower_ in negations:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def findSVs(tokens):\n",
        "    svs = []\n",
        "    verbs = [tok for tok in tokens if tok.pos_ == \"VERB\" or tok.pos_ == \"AUX\"]\n",
        "    for v in verbs:\n",
        "        subs, verbNegated = getAllSubs(v)\n",
        "        if len(subs) > 0:\n",
        "          svs.append((subs[-1].orth_, \"!\" + v.orth_ if verbNegated else v.orth_))\n",
        "            # for sub in subs:\n",
        "            #     svs.append((sub.orth_, \"!\" + v.orth_ if verbNegated else v.orth_))\n",
        "    return svs\n",
        "\n",
        "def getAllSubs(v):\n",
        "    verbNegated = isNegated(v)\n",
        "    subs = [tok for tok in v.lefts if tok.dep_ in SUBJECTS and tok.pos_ != \"DET\"]\n",
        "    #print(subs)\n",
        "    if len(subs) > 0:\n",
        "        subs.extend(getSubsFromConjunctions(subs))\n",
        "    else:\n",
        "        foundSubs, verbNegated = findSubs(v)\n",
        "        subs.extend(foundSubs)\n",
        "    return subs, verbNegated\n",
        "\n",
        "def testSVOs(input_sent):\n",
        "    tok = nlp(input_sent)\n",
        "    svs = findSVs(tok)\n",
        "    return (len(svs))\n",
        "\n",
        "def getCountTypeSent(essay_text):\n",
        "  s_conj = ['after','although','as','because','before','even though','if','since','though','unless','until','when','whenever','whereas','wherever','while','where','that','who','no matter']\n",
        "  exceptions = ['as soon as']\n",
        "\n",
        "  complex_comp_list=[]\n",
        "  complex_list=[]\n",
        "  compound_list=[]\n",
        "  simple_list=[]\n",
        "  dep_list = []\n",
        "  ret_dict = {}\n",
        "  docu = nlp(essay_text)\n",
        "  num_sent = len([sent for sent in docu.sents]) # Counting the number of sentences\n",
        "  simple_dict_inner = {}\n",
        "  complex_comp_dict_inner = {}\n",
        "  complex_dict_inner = {}\n",
        "  compound_dict_inner = {}\n",
        "\n",
        "  for sents in docu.sents:    \n",
        "    for s in exceptions:\n",
        "      res = re.search(r\"\\b\" + re.escape(s) + r\"\\b\", sents.text.lower())\n",
        "      if res:\n",
        "        break\n",
        "    \n",
        "    for s in s_conj:\n",
        "      res_sj = re.search(r\"\\b\" + re.escape(s) + r\"\\b\", sents.text.lower())\n",
        "      if res_sj:\n",
        "        break\n",
        "\n",
        "    if testSVOs(sents.text) == 1 and not res_sj:#any(tok in tok_list for tok in s_conj):                    # Simple sentence as only 1 subject verb pair and no subord conj\n",
        "      simple_dict_inner[\"startIndex\"] = sents.start_char\n",
        "      simple_dict_inner[\"endIndex\"]   = sents.end_char\n",
        "      simple_dict_inner[\"text\"]       = sents.text \n",
        "      simple_list.append(simple_dict_inner.copy()) \n",
        "    elif res_sj and not res:#any(tok in tok_list for tok in s_conj) and not res:                            # Complex sentence as more than 1 subject verb pair and subord conjunction.\n",
        "      complex_dict_inner[\"startIndex\"] = sents.start_char\n",
        "      complex_dict_inner[\"endIndex\"]   = sents.end_char\n",
        "      complex_dict_inner[\"text\"]       = sents.text \n",
        "      complex_list.append(complex_dict_inner.copy())     \n",
        "    else:\n",
        "      compound_dict_inner[\"startIndex\"] = sents.start_char\n",
        "      compound_dict_inner[\"endIndex\"]   = sents.end_char\n",
        "      compound_dict_inner[\"text\"]       = sents.text \n",
        "      compound_list.append(compound_dict_inner.copy()) \n",
        "\n",
        "  ret_dict['Complex-compound'] = dict(color = \"#FFA500\", description = \"Complex compound\", highlights= complex_comp_list)\n",
        "  ret_dict['Complex']          = dict(color = \"#90EE90\", description = \"Complex\", highlights = complex_list)\n",
        "  ret_dict['Compound']         = dict(color = \"#FFA07A\", description = \"Compound\", highlights = compound_list)\n",
        "  ret_dict['Simple']           = dict(color = \"#B0C4DE\", description = \"Simple\", highlights = simple_list)\n",
        "\n",
        "  return (len(complex_list)/num_sent,len(compound_list)/num_sent,len(simple_list)/num_sent)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays[['NumComplex','NumCompund','NumSimple']] = df_essays.apply(lambda row: pd.Series(getCountTypeSent(row['Essay Text'])),axis=1) "
      ],
      "metadata": {
        "id": "QySumc9A3mD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1VrPc2pK3Fp"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install py-readability-metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQRVYGR05Y2h",
        "outputId": "d96de6a0-21d6-438d-e596-4a011e4c58d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py-readability-metrics\n",
            "  Downloading py_readability_metrics-1.4.5-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from py-readability-metrics) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->py-readability-metrics) (1.15.0)\n",
            "Installing collected packages: py-readability-metrics\n",
            "Successfully installed py-readability-metrics-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip  install readability-lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "FjDaBlpb6emk",
        "outputId": "d6b30f9a-c271-44d8-8452-061746264bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting readability-lxml\n",
            "  Downloading readability_lxml-0.8.1-py3-none-any.whl (20 kB)\n",
            "Collecting cssselect\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from readability-lxml) (3.0.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from readability-lxml) (4.2.6)\n",
            "Installing collected packages: cssselect, readability-lxml\n",
            "Successfully installed cssselect-1.1.0 readability-lxml-0.8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "readability"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr1kzp1q5e4g",
        "outputId": "75753693-43e5-42b6-a0ce-3c68d52ef54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF9YZAixLBdA"
      },
      "outputs": [],
      "source": [
        "def get_flesch_score(essay_text):\n",
        "  from readability import Readability\n",
        "  r = Readability(essay_text)\n",
        "  fk = r.flesch_kincaid()\n",
        "  readability_score = fk.score\n",
        "  return round(readability_score,2)\n",
        "\n",
        "df_essays['FleschScore'] = df_essays.apply(lambda x: get_flesch_score(x['Essay Text']),axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ionff7JVNExp",
        "outputId": "c4d5b17d-22c3-4775-8ded-5b445c9207bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Essay Text   Essay Grading  \\\n",
              "0   THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1   I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2   WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3   THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4   THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "5   My eyes widen. “It’s all Greek to me,” I whisp...  Excellent (A+)   \n",
              "6   I could still hear her words, the words my tea...   Average (B-C)   \n",
              "7   It was a wet and dreary October evening. I sho...   Average (B-C)   \n",
              "8   Oreos. On the exterior, a firm chocolate crust...   Average (B-C)   \n",
              "9   Whether I was blowing out candles, writing a l...   Average (B-C)   \n",
              "10  In most conventional classrooms, we are taught...  Excellent (A+)   \n",
              "11  When I was thirteen and visiting Liberia, I co...   Average (B-C)   \n",
              "12  The phenomenon of interdependency, man dependi...  Excellent (A+)   \n",
              "13  My fingers know instinctively, without a thoug...   Average (B-C)   \n",
              "14  When I turned twelve, my stepdad turned violen...   Average (B-C)   \n",
              "15  I was a straight A student until I got to high...  Excellent (A+)   \n",
              "16  My brother and I are exactly one year and one ...  Excellent (A+)   \n",
              "17  My parents are aerospace engineers, humble eve...   Average (B-C)   \n",
              "18  As I sip a mug of hot chocolate on a dreary wi...  Excellent (A+)   \n",
              "19  I believe that humans will always have the abi...   Average (B-C)   \n",
              "20  This past summer, I had the privilege of parti...   Average (B-C)   \n",
              "21  The ground beneath me began to shake as an oil...  Excellent (A+)   \n",
              "22  These days, birds are losing the battle of fav...   Average (B-C)   \n",
              "23  “ROSENCRANTZ AND GUILDENSTERN ARE DEAD” IS an ...   Average (B-C)   \n",
              "24  WHEN MY GRANDMOTHER CAME TO VISIT five years a...  Excellent (A+)   \n",
              "25  MY REASONS FOR WANTING To BE a doctor are very...  Excellent (A+)   \n",
              "26  SINCE I HAVE ALWAYS BEEN INTERESTED in science...   Average (B-C)   \n",
              "27  WHILE HEALING PEOPLE WILL BE MY main priority ...  Excellent (A+)   \n",
              "28  GROWING UP WITH SEPARATED PARENTS HAS not been...  Excellent (A+)   \n",
              "29  I TROD THE MUD IN THE misty spring rain. It wa...  Excellent (A+)   \n",
              "\n",
              "    SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "0              35        816       0.12       0.17      0.09         0.06   \n",
              "1              28        587       0.13       0.19      0.08         0.05   \n",
              "2              40       1005       0.11       0.15      0.08         0.05   \n",
              "3              20        571       0.12       0.16      0.07         0.06   \n",
              "4              23        549       0.10       0.19      0.06         0.05   \n",
              "5              46        736       0.14       0.21      0.06         0.03   \n",
              "6              31        712       0.14       0.18      0.05         0.03   \n",
              "7              30        736       0.14       0.21      0.06         0.07   \n",
              "8              43        756       0.13       0.17      0.09         0.04   \n",
              "9              21        698       0.13       0.17      0.06         0.05   \n",
              "10             19        293       0.13       0.18      0.06         0.04   \n",
              "11             30        740       0.14       0.19      0.09         0.05   \n",
              "12             29        691       0.12       0.22      0.05         0.04   \n",
              "13             25        591       0.11       0.19      0.08         0.04   \n",
              "14             22        580       0.16       0.17      0.06         0.05   \n",
              "15             36        746       0.17       0.17      0.05         0.03   \n",
              "16             34        611       0.12       0.17      0.07         0.06   \n",
              "17             34        695       0.14       0.14      0.07         0.04   \n",
              "18             21        556       0.12       0.17      0.08         0.05   \n",
              "19             36        593       0.16       0.15      0.05         0.04   \n",
              "20             19        642       0.12       0.23      0.06         0.02   \n",
              "21             35        758       0.14       0.20      0.06         0.05   \n",
              "22             26        683       0.12       0.20      0.07         0.05   \n",
              "23             10        263       0.10       0.14      0.09         0.06   \n",
              "24             26        596       0.14       0.18      0.07         0.05   \n",
              "25             20        413       0.16       0.16      0.08         0.06   \n",
              "26             23        604       0.11       0.19      0.06         0.03   \n",
              "27             18        455       0.17       0.17      0.06         0.07   \n",
              "28             21        565       0.12       0.20      0.07         0.04   \n",
              "29             36        558       0.15       0.22      0.06         0.04   \n",
              "\n",
              "    PronounCount  PunctCount  NumberofActiveVoice  NumComplex  NumCompund  \\\n",
              "0           0.06        0.12                 0.82    0.514286    0.314286   \n",
              "1           0.08        0.09                 0.85    0.357143    0.250000   \n",
              "2           0.08        0.11                 0.78    0.700000    0.125000   \n",
              "3           0.08        0.11                 0.75    0.600000    0.200000   \n",
              "4           0.05        0.11                 0.82    0.304348    0.434783   \n",
              "5           0.07        0.12                 0.93    0.260870    0.260870   \n",
              "6           0.08        0.11                 0.87    0.387097    0.290323   \n",
              "7           0.07        0.11                 1.00    0.400000    0.233333   \n",
              "8           0.06        0.12                 0.43    0.511628    0.209302   \n",
              "9           0.09        0.10                 0.92    0.809524    0.095238   \n",
              "10          0.08        0.13                 0.65    0.052632    0.421053   \n",
              "11          0.06        0.10                 0.90    0.533333    0.300000   \n",
              "12          0.06        0.11                 0.91    0.379310    0.482759   \n",
              "13          0.07        0.12                 0.97    0.360000    0.160000   \n",
              "14          0.11        0.09                 0.92    0.636364    0.136364   \n",
              "15          0.10        0.11                 0.69    0.472222    0.333333   \n",
              "16          0.10        0.10                 1.00    0.529412    0.176471   \n",
              "17          0.12        0.08                 0.91    0.500000    0.176471   \n",
              "18          0.08        0.09                 1.00    0.428571    0.333333   \n",
              "19          0.09        0.12                 0.50    0.388889    0.277778   \n",
              "20          0.04        0.11                 0.98    0.473684    0.421053   \n",
              "21          0.07        0.12                 0.94    0.400000    0.314286   \n",
              "22          0.08        0.11                 0.86    0.461538    0.423077   \n",
              "23          0.03        0.14                 0.88    0.200000    0.600000   \n",
              "24          0.06        0.10                 0.86    0.538462    0.346154   \n",
              "25          0.10        0.07                 0.85    0.550000    0.350000   \n",
              "26          0.06        0.13                 0.87    0.434783    0.434783   \n",
              "27          0.09        0.07                 0.93    0.722222    0.055556   \n",
              "28          0.07        0.10                 0.96    0.428571    0.285714   \n",
              "29          0.06        0.12                 0.78    0.444444    0.277778   \n",
              "\n",
              "    NumSimple  FleschScore  \n",
              "0    0.171429        10.19  \n",
              "1    0.392857         9.15  \n",
              "2    0.175000        11.02  \n",
              "3    0.200000        12.07  \n",
              "4    0.260870        11.67  \n",
              "5    0.478261         7.82  \n",
              "6    0.322581        10.36  \n",
              "7    0.366667        10.13  \n",
              "8    0.279070         9.18  \n",
              "9    0.095238        13.88  \n",
              "10   0.526316         7.10  \n",
              "11   0.166667        12.62  \n",
              "12   0.137931        12.67  \n",
              "13   0.480000        10.93  \n",
              "14   0.227273         9.73  \n",
              "15   0.194444        10.58  \n",
              "16   0.294118         7.37  \n",
              "17   0.323529         8.39  \n",
              "18   0.238095        11.96  \n",
              "19   0.333333         8.65  \n",
              "20   0.105263        17.27  \n",
              "21   0.285714         9.92  \n",
              "22   0.115385        12.54  \n",
              "23   0.200000        13.59  \n",
              "24   0.115385        11.89  \n",
              "25   0.100000        10.69  \n",
              "26   0.130435        13.83  \n",
              "27   0.222222         9.84  \n",
              "28   0.285714        11.52  \n",
              "29   0.277778         9.08  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7fe1dad-6ffe-45a3-a678-a40051de6f17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "      <th>NumberofActiveVoice</th>\n",
              "      <th>NumComplex</th>\n",
              "      <th>NumCompund</th>\n",
              "      <th>NumSimple</th>\n",
              "      <th>FleschScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>10.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>9.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>11.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>11.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>My eyes widen. “It’s all Greek to me,” I whisp...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>46</td>\n",
              "      <td>736</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>7.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I could still hear her words, the words my tea...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>31</td>\n",
              "      <td>712</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.322581</td>\n",
              "      <td>10.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>It was a wet and dreary October evening. I sho...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>30</td>\n",
              "      <td>736</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.11</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>10.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Oreos. On the exterior, a firm chocolate crust...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>43</td>\n",
              "      <td>756</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.511628</td>\n",
              "      <td>0.209302</td>\n",
              "      <td>0.279070</td>\n",
              "      <td>9.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Whether I was blowing out candles, writing a l...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>21</td>\n",
              "      <td>698</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>0.095238</td>\n",
              "      <td>13.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>In most conventional classrooms, we are taught...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>19</td>\n",
              "      <td>293</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>7.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>When I was thirteen and visiting Liberia, I co...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>30</td>\n",
              "      <td>740</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>12.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The phenomenon of interdependency, man dependi...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>29</td>\n",
              "      <td>691</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.379310</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>12.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>My fingers know instinctively, without a thoug...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>25</td>\n",
              "      <td>591</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>10.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>When I turned twelve, my stepdad turned violen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>22</td>\n",
              "      <td>580</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>9.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I was a straight A student until I got to high...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>36</td>\n",
              "      <td>746</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.472222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.194444</td>\n",
              "      <td>10.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>My brother and I are exactly one year and one ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>34</td>\n",
              "      <td>611</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>7.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>My parents are aerospace engineers, humble eve...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>34</td>\n",
              "      <td>695</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>8.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>As I sip a mug of hot chocolate on a dreary wi...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>21</td>\n",
              "      <td>556</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>11.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I believe that humans will always have the abi...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>36</td>\n",
              "      <td>593</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>8.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>This past summer, I had the privilege of parti...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>19</td>\n",
              "      <td>642</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>17.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The ground beneath me began to shake as an oil...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>35</td>\n",
              "      <td>758</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>9.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>These days, birds are losing the battle of fav...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>26</td>\n",
              "      <td>683</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>12.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>“ROSENCRANTZ AND GUILDENSTERN ARE DEAD” IS an ...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>10</td>\n",
              "      <td>263</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>13.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>WHEN MY GRANDMOTHER CAME TO VISIT five years a...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>26</td>\n",
              "      <td>596</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.538462</td>\n",
              "      <td>0.346154</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>11.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>MY REASONS FOR WANTING To BE a doctor are very...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>20</td>\n",
              "      <td>413</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>10.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>SINCE I HAVE ALWAYS BEEN INTERESTED in science...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>604</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>13.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>WHILE HEALING PEOPLE WILL BE MY main priority ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>18</td>\n",
              "      <td>455</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>9.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>GROWING UP WITH SEPARATED PARENTS HAS not been...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>21</td>\n",
              "      <td>565</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>11.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>I TROD THE MUD IN THE misty spring rain. It wa...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>36</td>\n",
              "      <td>558</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>9.08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7fe1dad-6ffe-45a3-a678-a40051de6f17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7fe1dad-6ffe-45a3-a678-a40051de6f17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7fe1dad-6ffe-45a3-a678-a40051de6f17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "df_essays.head(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmaT8BojZeMv"
      },
      "source": [
        "## **Number of 'Unique Words' Feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87a-XmO49-Ho"
      },
      "outputs": [],
      "source": [
        "#stop_words = set(stopwords.words('english'))\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def non_stop_words(essay):\n",
        "  word_tokens = word_tokenize(essay)\n",
        "  #filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "  filtered_sentence = [w for w in word_tokens]\n",
        "  str1 = ' '.join(filtered_sentence)\n",
        "  mylist = re.findall(r'[^!?.,-;]+',str1) # To remove punctuations\n",
        "  str1 = ''.join(mylist)\n",
        "  return str1,len(filtered_sentence)\n",
        "\n",
        "def word_count(essay):\n",
        "  out = []\n",
        "  seen = set()\n",
        "  string,length = non_stop_words(essay)\n",
        "  doc = nlp(string)\n",
        "  for word in doc:\n",
        "    if word.text not in seen:\n",
        "      if word.text != ' ':\n",
        "        out.append(word)\n",
        "        seen.add(word.text)\n",
        "  #print(len(seen))\n",
        "  return (len(seen)/length)   # Unique words density\n",
        "  #return (len(seen))   # Unique words set\n",
        "\n",
        "\n",
        "df_essays['UniqWordDensity']  = df_essays.apply(lambda x: word_count(x['Essay Text']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "QflsXi49_f4W",
        "outputId": "a57f4137-8845-4b2b-ac85-1f0880bd5b2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "0             35        816       0.12       0.17      0.09         0.06   \n",
              "1             28        587       0.13       0.19      0.08         0.05   \n",
              "2             40       1005       0.11       0.15      0.08         0.05   \n",
              "3             20        571       0.12       0.16      0.07         0.06   \n",
              "4             23        549       0.10       0.19      0.06         0.05   \n",
              "\n",
              "   PronounCount  PunctCount  NumberofActiveVoice  NumComplex  NumCompund  \\\n",
              "0          0.06        0.12                 0.82    0.514286    0.314286   \n",
              "1          0.08        0.09                 0.85    0.357143    0.250000   \n",
              "2          0.08        0.11                 0.78    0.700000    0.125000   \n",
              "3          0.08        0.11                 0.75    0.600000    0.200000   \n",
              "4          0.05        0.11                 0.82    0.304348    0.434783   \n",
              "\n",
              "   NumSimple  FleschScore  UniqWordDensity  \n",
              "0   0.171429        10.19         0.488722  \n",
              "1   0.392857         9.15         0.500000  \n",
              "2   0.175000        11.02         0.394366  \n",
              "3   0.200000        12.07         0.514286  \n",
              "4   0.260870        11.67         0.503676  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2062c62-7bf6-4704-a1d6-186c3226cd70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "      <th>NumberofActiveVoice</th>\n",
              "      <th>NumComplex</th>\n",
              "      <th>NumCompund</th>\n",
              "      <th>NumSimple</th>\n",
              "      <th>FleschScore</th>\n",
              "      <th>UniqWordDensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>10.19</td>\n",
              "      <td>0.488722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>9.15</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>11.02</td>\n",
              "      <td>0.394366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.07</td>\n",
              "      <td>0.514286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>11.67</td>\n",
              "      <td>0.503676</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2062c62-7bf6-4704-a1d6-186c3226cd70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2062c62-7bf6-4704-a1d6-186c3226cd70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2062c62-7bf6-4704-a1d6-186c3226cd70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df_essays.head()\n",
        "#print(df_test['Essay Text'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkYmwtwqZonb"
      },
      "outputs": [],
      "source": [
        "df_essays.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def showntell_essay(InputEssay):\n",
        "  doc  = nlp(InputEssay)\n",
        "  mental_tells = ['loved','realized','thought','hoped','considered','wondered','prayed','knew','saw','watched','heard','felt','could','see','seemed','appeared',\n",
        "  'looked','believed','reflected','disgusted','feared','show','noticed','smelled','wonder','walked','come','hate','decided','wished','feel','see','smell',\n",
        "  'fell']\n",
        "\n",
        "  emotional_tells = ['adoration','agitation','amazement','amusement','anger','anguish','annoyance','anticipation','anxiety','confidence','conflicted','confusion',\n",
        "  'contempt','curiosity','defeat','defensiveness','denial','depression','desire','desperation','determination','disappointment','disbelief','disgust','doubt','dread',\n",
        "  'eagerness','elation','embarrassment','envy','excitement','fear','frustration','gratitude','guilt','happiness','hatred','hopefulness','humiliation','hurt','impatience',\n",
        "  'indifference','insecurity','irritation','jealousy','loneliness','love','nervousness','nostalgia','overwhelmed','paranoia','peacefulness','pride','rage','regret','relief',\n",
        "  'reluctance','remorse','resentment','resignation','sadness','satisfaction','scorn','shame','skepticism','smugness','somberness','surprise','shock','suspicion','sympathy',\n",
        "  'terror','uncertainty','unease','wariness','worry']\n",
        "\n",
        "  motivational_tells = ['decided','because','tried','when']\n",
        "\n",
        "  emotional_adjectives = ['frustated', 'happy', 'tall', 'angry', 'sad', 'hungry', 'excited', 'embarrased', 'bright', 'shocked', 'hot', 'beautiful', \n",
        "                          'afraid', 'cold', 'interesting', 'confused', 'sweet', 'different', 'scared', 'mournful', 'furious', 'overwhelmed', 'stressed', \n",
        "                          'unique', 'overjoyed', 'scarier', 'tired', 'shy', 'giddy', 'anxious','chilly','friendly','ghastly','ghostly','holy','kingly',\n",
        "                          'knightly','lonely','lovely','orderly','prickly','queenly','surly','ugly','worldly','wrinkly']\n",
        "\n",
        "  adverbs_avoid = ['very', 'really', 'spectacularly','already' 'abruptly', 'absently', 'absentmindedly', 'accusingly', 'actually', 'adversely', 'affectionately', \n",
        "                  'amazingly', 'angrily', 'anxiously', 'arrogantly', 'bashfully', 'beautifully', 'boldly', 'bravely', 'breathlessly', 'brightly', 'briskly', 'broadly', \n",
        "                  'calmly', 'carefully', 'carelessly', 'certainly', 'cheaply', 'cheerfully', 'cleanly', 'clearly', 'cleverly', 'closely', 'clumsily', 'coaxingly', 'commonly', \n",
        "                  'compassionately', 'conspicuously', 'continually', 'coolly', 'correctly', 'crisply', 'crossly', 'curiously', 'daintily', 'dangerously', 'darkly', 'dearly', \n",
        "                  'deceivingly', 'delicately', 'delightfully', 'desperately', 'determinedly', 'diligently', 'disgustingly', 'distinctly', 'doggedly', 'dreamily', 'emptily', \n",
        "                  'energetically', 'enormously', 'enticingly', 'entirely', 'enviously', 'especially', 'evenly', 'exactly', 'excitedly', 'exclusively', 'expertly', 'extremely', \n",
        "                  'fairly', 'faithfully', 'famously', 'fearlessly', 'ferociously', 'fervently', 'finally', 'foolishly', 'fortunately', 'frankly', 'frantically', 'freely', \n",
        "                  'frenetically', 'frightfully', 'fully', 'furiously', 'generally', 'generously', 'gently', 'gleefully', 'gratefully', 'greatly', 'greedily', 'grumpily', \n",
        "                  'guiltily', 'happily', 'harshly', 'hatefully', 'heartily', 'heavily', 'helpfully', 'helplessly', 'highly', 'hopelessly', 'hungrily', 'immediately', 'importantly', \n",
        "                  'impulsively', 'inadvertently', 'increasingly', 'incredibly', 'innocently', 'instantly', 'intensely', 'intently', 'inwardly', 'jokingly', 'kindly', 'knowingly', \n",
        "                  'lawfully', 'lightly', 'likely', 'longingly', 'loudly', 'madly', 'marvelously', 'meaningfully', 'mechanically', 'meekly', 'mentally', 'messily', 'mindfully', 'miserably', \n",
        "                  'mockingly', 'mostly', 'mysteriously', 'naturally', 'nearly', 'neatly', 'negatively', 'nervously', 'nicely', 'obviously', 'occasionally', 'oddly', 'openly', 'outwardly', \n",
        "                  'partially', 'passionately', 'patiently', 'perfectly', 'perpetually', 'playfully', 'pleasantly', 'pleasingly', 'politely', 'poorly', 'positively', 'potentially', 'powerfully', \n",
        "                  'professionally', 'properly', 'proudly', 'quaveringly', 'queerly', 'quickly', 'quietly', 'quintessentially', 'rapidly', 'rapturously', 'ravenously', 'readily', 'reassuringly', \n",
        "                  'regretfully', 'reluctantly', 'reproachfully', 'restfully', 'righteously', 'rightfully', 'rigidly', 'rudely', 'sadly', 'safely', 'scarcely', 'searchingly', 'sedately', \n",
        "                  'seemingly', 'selfishly', 'separately', 'seriously', 'sharply', 'sheepishly', 'sleepily', 'slowly', 'slyly', 'softly', 'solidly', 'speedily', 'sternly', 'stingily', 'strictly', \n",
        "                  'stubbornly', 'successfully', 'superstitiously', 'surprisingly', 'suspiciously', 'sympathetically', 'tenderly', 'terribly', 'thankfully', 'thoroughly', 'thoughtfully', 'tightly', \n",
        "                  'totally', 'tremendously', 'triumphantly', 'truly', 'truthfully', 'understandably', 'unfairly', 'unfortunately', 'unhappily', 'unwillingly', 'urgently', 'usually', 'utterly', 'vastly', \n",
        "                  'venomously', 'viciously', 'violently', 'warmly', 'wearily wholly', 'wildly', 'wilfully', 'wisely', 'wonderfully', 'wonderingly', 'worriedly']\n",
        "\n",
        "  aux_tell_list = []\n",
        "  ment_tell_list = []\n",
        "  det_tell_list = []\n",
        "  motiv_tell_list = []\n",
        "  emot_adj_tell_list  = []\n",
        "  adv_tell_list  = []\n",
        "  adj_tell_list = []\n",
        "  sent_level_dict = {}\n",
        "  count = 0\n",
        "\n",
        "  output_dict = {}\n",
        "\n",
        "  adj_dict_inner = {}\n",
        "  adv_dict_inner = {}\n",
        "  aux_dict_inner = {}\n",
        "  emot_dict_inner = {}\n",
        "  det_dict_inner = {}\n",
        "  ment_dict_inner = {}\n",
        "  motiv_dict_inner = {}\n",
        "\n",
        "  doc_sents = [sent for sent in doc.sents]\n",
        "  len_tot_sents = len(doc_sents)\n",
        "  for sents in doc.sents:\n",
        "    count = 0\n",
        "    for ix,token in enumerate(sents):\n",
        "      tok_pos=token.idx\n",
        "      try:\n",
        "        if token.is_sent_start:    # checking for first token\n",
        "          if sents[ix].tag_ == 'PRP' or sents[ix].tag_ == 'PRP$' or sents[ix].tag_ == 'NN' :        # check for 'PRP' (Pronoun Personal) specifically with  'I','We','They','He','She'. 'You'.,check for 'PRP$' (Pronoun Possessive) my, our, your, his, her, its, and their,check for 'NN' (noun, singular or mass) i.e. 'Non-specific Nouns'\n",
        "            if sents[ix + 1].pos_ == 'AUX' or sents[ix + 1].pos_ == 'MD':                           # check for the token to the right for 'AUX' and 'MD'.\n",
        "              tok = (sents[ix:ix+2])     # getting the right token as well\n",
        "              right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "              aux_dict_inner[\"startIndex\"] = tok_pos\n",
        "              aux_dict_inner[\"endIndex\"]   = right_pos\n",
        "              aux_dict_inner[\"text\"]       = tok\n",
        "              aux_tell_list.append(aux_dict_inner.copy())          \n",
        "              count +=1\n",
        "              sent_level_dict[sents] = count\n",
        "            elif sents[ix + 1].pos_ == 'VERB':\n",
        "              if sents[ix+1].text.lower() in mental_tells or sents[ix+1].lemma_.lower() in mental_tells: # check if the token next to the first token is a 'VERB' out of 'mental tell' verbs.\n",
        "                tok = (sents[ix:ix+2])                                                                  # check for 'NN' (noun, singular or mass) i.e. 'Non-specific Nouns'\n",
        "                right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "                ment_dict_inner[\"startIndex\"] = tok_pos\n",
        "                ment_dict_inner[\"endIndex\"]   = right_pos\n",
        "                ment_dict_inner[\"text\"]       = tok\n",
        "                ment_tell_list.append(ment_dict_inner.copy())                \n",
        "                count +=1\n",
        "                sent_level_dict[sents] = count            \n",
        "          elif sents[ix].pos_ == 'DET':                                                             # check if the first token is a 'determiner' \n",
        "            if sents[ix + 1].pos_ == 'ADJ' or sents[ix + 1].tag_ == 'RBS':                          # and next one is 'adverb superlative' or an 'adjective'.\n",
        "                tok = (sents[ix:ix+2])\n",
        "                right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "                det_dict_inner[\"startIndex\"] = tok_pos\n",
        "                det_dict_inner[\"endIndex\"]   = right_pos\n",
        "                det_dict_inner[\"text\"]       = tok              \n",
        "                det_tell_list.append(det_dict_inner.copy())\n",
        "                count +=1\n",
        "                sent_level_dict[sents] = count          \n",
        "      except:\n",
        "        continue        \n",
        "      if token.text.lower() in motivational_tells or token.lemma_.lower() in motivational_tells:   # check if the token is out of the 'motivational tell' list\n",
        "          tok = token.text.lower()\n",
        "          right_pos = sents[ix+1].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "          motiv_dict_inner[\"startIndex\"] = tok_pos\n",
        "          motiv_dict_inner[\"endIndex\"]   = right_pos\n",
        "          motiv_dict_inner[\"text\"]       = tok       \n",
        "          motiv_tell_list.append(motiv_dict_inner.copy())\n",
        "          count +=1\n",
        "          sent_level_dict[sents] = count        \n",
        "      elif sents[ix].text.lower() == 'to' and sents[ix + 1].pos_ == 'VERB':                        # check if the word is of the form 'to [Verb]'\n",
        "          tok = (sents[ix:ix+2])\n",
        "          right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "          motiv_dict_inner[\"startIndex\"] = tok_pos\n",
        "          motiv_dict_inner[\"endIndex\"]   = right_pos\n",
        "          motiv_dict_inner[\"text\"]       = tok       \n",
        "          motiv_tell_list.append(motiv_dict_inner.copy())\n",
        "          count +=1\n",
        "          sent_level_dict[sents] = count        \n",
        "      elif any(x in sents[ix].text.lower() for x in ['with','in']) and (sents[ix + 1].pos_ == 'NOUN' or sents[ix + 1].pos_ == 'PROPN') and sents[ix + 1].text.lower() in emotional_tells: # check if the word is of the form 'with [noun] or in [noun]'\n",
        "          tok = (sents[ix:ix+2])\n",
        "          right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.  \n",
        "          emot_dict_inner[\"startIndex\"] = tok_pos\n",
        "          emot_dict_inner[\"endIndex\"]   = right_pos\n",
        "          emot_dict_inner[\"text\"]       = tok                                                         \n",
        "          emot_adj_tell_list.append(emot_dict_inner.copy())\n",
        "          count +=1\n",
        "          sent_level_dict[sents] = count        \n",
        "      elif token.pos_ == 'ADJ' and (token.text.lower() in emotional_adjectives or token.lemma_.lower() in emotional_adjectives):  # check if the word is out of the list of 'emotional' adjective word list\n",
        "        tok = token.text.lower()\n",
        "        right_pos = sents[ix+1].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "        adj_dict_inner[\"startIndex\"] = tok_pos\n",
        "        adj_dict_inner[\"endIndex\"]   = right_pos\n",
        "        adj_dict_inner[\"text\"]       = tok     \n",
        "        adj_tell_list.append(adj_dict_inner.copy())\n",
        "        count +=1\n",
        "        sent_level_dict[sents] = count      \n",
        "      elif token.pos_ == 'ADV' and (token.text.lower() in adverbs_avoid or token.lemma_.lower() in adverbs_avoid):             # check if the word is out of the list of 'adverb to avoid' word list\n",
        "        tok_pos=token.idx\n",
        "        right_pos = sents[ix+1].idx-1 # getting the right token's starting character offset.\n",
        "        tok = token.text.lower()\n",
        "        adv_dict_inner[\"startIndex\"] = tok_pos\n",
        "        adv_dict_inner[\"endIndex\"]   = right_pos\n",
        "        adv_dict_inner[\"text\"]       = tok  \n",
        "        adv_tell_list.append(adv_dict_inner.copy())\n",
        "        count +=1\n",
        "        sent_level_dict[sents] = count   \n",
        "  \n",
        "  return (len(sent_level_dict))\n",
        "df_essays['TellDensity']  = df_essays.apply(lambda x: showntell_essay(x['Essay Text']), axis=1)\n"
      ],
      "metadata": {
        "id": "V-r-ejB5NkWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "KyfX7qTxO1te",
        "outputId": "4684eff1-2232-4b8d-c110-ad4dfc664199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "0             35        816       0.12       0.17      0.09         0.06   \n",
              "1             28        587       0.13       0.19      0.08         0.05   \n",
              "2             40       1005       0.11       0.15      0.08         0.05   \n",
              "3             20        571       0.12       0.16      0.07         0.06   \n",
              "4             23        549       0.10       0.19      0.06         0.05   \n",
              "\n",
              "   PronounCount  PunctCount  NumberofActiveVoice  NumComplex  NumCompund  \\\n",
              "0          0.06        0.12                 0.82    0.514286    0.314286   \n",
              "1          0.08        0.09                 0.85    0.357143    0.250000   \n",
              "2          0.08        0.11                 0.78    0.700000    0.125000   \n",
              "3          0.08        0.11                 0.75    0.600000    0.200000   \n",
              "4          0.05        0.11                 0.82    0.304348    0.434783   \n",
              "\n",
              "   NumSimple  FleschScore  UniqWordDensity  TellDensity  \n",
              "0   0.171429        10.19         0.488722           22  \n",
              "1   0.392857         9.15         0.500000           16  \n",
              "2   0.175000        11.02         0.394366           24  \n",
              "3   0.200000        12.07         0.514286           10  \n",
              "4   0.260870        11.67         0.503676           13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-212a945b-2695-43ee-b802-32403f6cfae4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "      <th>NumberofActiveVoice</th>\n",
              "      <th>NumComplex</th>\n",
              "      <th>NumCompund</th>\n",
              "      <th>NumSimple</th>\n",
              "      <th>FleschScore</th>\n",
              "      <th>UniqWordDensity</th>\n",
              "      <th>TellDensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>10.19</td>\n",
              "      <td>0.488722</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>9.15</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>11.02</td>\n",
              "      <td>0.394366</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.07</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>11.67</td>\n",
              "      <td>0.503676</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-212a945b-2695-43ee-b802-32403f6cfae4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-212a945b-2695-43ee-b802-32403f6cfae4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-212a945b-2695-43ee-b802-32403f6cfae4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95-sX3IwZwa6"
      },
      "source": [
        "## **Using TfIdf Vectorizer**\n",
        "\n",
        "###Spacy use is limited to 'Text Preprocessing' but not into 'Vectorization' or training.\n",
        "\n",
        "### Next level of sophistication can be built by converting each word in the mail into its numerical value. We call this a 'word vectors'.\n",
        "\n",
        "## **Technique**:\n",
        "### An \"*inverse document frequency factor*\" is incorporated, which diminishes the weight of terms that occur very frequently in the document set and \t       increases the weight of the terms that occur rarely.\n",
        "\n",
        "### This technique is implemented using **TfIdf Vectorizer** which also creates a 'DTM' matrix . However, instead of filling up the DTM with the 'token counts' , it calculates 'term frequency inverse document \tfrequency' value for each word (TF-IDF)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kInX29u1NF9_"
      },
      "outputs": [],
      "source": [
        "# # Split the data into features and target label\n",
        "# y = df_essays['Essay Grading']\n",
        "# X = df_essays['Essay Text']\n",
        "\n",
        "# y = y.apply(lambda x:2 if x==\"Excellent (A+)\" else 1 if x=='Average (B-C)' else 0)\n",
        "\n",
        "\n",
        "# # Import train_test_split\n",
        "\n",
        "# # Split the 'features' and 'income' data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "#                                                     y, \n",
        "#                                                     test_size = 0.2, \n",
        "#                                                     random_state = 0)\n",
        "\n",
        "# # Show the results of the split\n",
        "# print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "# print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
        "\n",
        "# # Naïve Bayes:\n",
        "# text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "#                      ('clf', MultinomialNB()),\n",
        "# ])\n",
        "# text_clf_nb.fit(X_train, y_train)\n",
        "\n",
        "# y_train_pred = text_clf_nb.predict(X_train)\n",
        "# y_test_pred = text_clf_nb.predict(X_test)\n",
        "\n",
        "# # # Calculate the accuracy\n",
        "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "# print('The training accuracy is', train_accuracy)\n",
        "# print('The test accuracy is', test_accuracy)\n",
        "# print('F1 score: ', format(f1_score(y_test,y_test_pred,average='micro')))\n",
        "# confusion_matrix(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average number of characters per word.\n"
      ],
      "metadata": {
        "id": "ViX-AW7Y8xSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6I8IFC29J3M",
        "outputId": "580668ad-524d-461f-de2d-8fd52a78ee40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import re\n",
        "def count_words(essay):\n",
        "  mylist = re.findall(r'[^!?.,-;]+',essay) # To remove punctuations  \n",
        "  str1 = ' '.join(mylist)\n",
        "  str2 = word_tokenize(str1)\n",
        "  return len(str2)\n",
        "\n",
        "def char_count(essay):\n",
        "  mylist = re.findall(r'[^!?.,-;]+',essay) # To remove punctuations  \n",
        "  str1 = ''.join(mylist)    \n",
        "  docu = nlp(str1)\n",
        "  len_char = []\n",
        "  for token in docu:\n",
        "    #print(f'{token.idx} {token.lower_} {token.pos_} {spacy.explain(token.pos_)}  {token.tag_} {spacy.explain(token.tag_)} {token.dep_} {spacy.explain(token.dep_)}')\n",
        "    len_char.append(len(token))\n",
        "  return sum(len_char)\n",
        "\n",
        "def avg_char_count(essay):\n",
        "  return round(char_count(essay)/count_words(essay),2)\n",
        "\n",
        "df_essays['AvgChar']  = df_essays.apply(lambda x: avg_char_count(x['Essay Text']), axis=1)"
      ],
      "metadata": {
        "id": "uweRxySi8sq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average number of syllables per word"
      ],
      "metadata": {
        "id": "q9mIlHVy-B4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install syllables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t91R4xOQ-BVq",
        "outputId": "d7c5a739-6bb3-42a0-8df5-fb784139196f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting syllables\n",
            "  Downloading syllables-1.0.3-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: syllables\n",
            "Successfully installed syllables-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_syllables_per_word(essay):\n",
        "  import syllables\n",
        "  mylist = re.findall(r'[^!?.,-;]+',essay) # To remove punctuations  \n",
        "  str1 = ''.join(mylist)  \n",
        "  count_s = syllables.estimate(str1)\n",
        "  return round(count_s/count_words(essay),2)\n",
        "df_essays['Syllablesperword']  = df_essays.apply(lambda x: count_syllables_per_word(x['Essay Text']), axis=1)  "
      ],
      "metadata": {
        "id": "XjyjQADA-JEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lexical-diversity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyzpVi5X-p6F",
        "outputId": "a8122876-7400-418c-f549-cf67457cc8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lexical-diversity\n",
            "  Downloading lexical_diversity-0.1.1-py3-none-any.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 3.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: lexical-diversity\n",
            "Successfully installed lexical-diversity-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lexical diversity MTLD"
      ],
      "metadata": {
        "id": "-RBxd4ai_AUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lexical_diversity import lex_div as ld\n",
        "def calc_mtld(essay):\n",
        "  mylist = re.findall(r'[^!?.,-;]+',essay) # To remove punctuations  \n",
        "  str1 = ''.join(mylist) \n",
        "  return round(ld.mtld(str1),2)\n",
        "df_essays['mtld']  = df_essays.apply(lambda x: calc_mtld(x['Essay Text']), axis=1)  "
      ],
      "metadata": {
        "id": "Eqqslr-v-soF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NER List"
      ],
      "metadata": {
        "id": "3TQ9kTr0_af0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentage of named entities in all entities.\n",
        "def count_ner_per_ent(essay):\n",
        "  ner_list = []\n",
        "  doc=nlp(essay)\n",
        "  for entity in doc.ents:\n",
        "    ner_list.append(entity.text)\n",
        "  return round(len(ner_list)/count_words(essay),2)\n",
        "df_essays['namedEntities']  = df_essays.apply(lambda x: count_ner_per_ent(x['Essay Text']), axis=1)    "
      ],
      "metadata": {
        "id": "wZI9s26s_aB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entities per sentence"
      ],
      "metadata": {
        "id": "CCP196TgAOyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentage of named entities per sentence.\n",
        "def count_ner_per_sent(essay):\n",
        "  ner_list = []\n",
        "  doc=nlp(essay)\n",
        "  for entity in doc.ents:\n",
        "    ner_list.append(entity.text)\n",
        "  return round(len(ner_list)/count_sentences(essay),2)\n",
        "df_essays['nerPerSent']  = df_essays.apply(lambda x: count_ner_per_sent(x['Essay Text']), axis=1)      "
      ],
      "metadata": {
        "id": "QqBmBV2HAV00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "RebFQkNV9eYS",
        "outputId": "b363120a-e645-4b98-9c62-704d9afba7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "0             35        816       0.12       0.17      0.09         0.06   \n",
              "1             28        587       0.13       0.19      0.08         0.05   \n",
              "2             40       1005       0.11       0.15      0.08         0.05   \n",
              "3             20        571       0.12       0.16      0.07         0.06   \n",
              "4             23        549       0.10       0.19      0.06         0.05   \n",
              "\n",
              "   PronounCount  PunctCount  ...  NumCompund  NumSimple  FleschScore  \\\n",
              "0          0.06        0.12  ...    0.314286   0.171429        10.19   \n",
              "1          0.08        0.09  ...    0.250000   0.392857         9.15   \n",
              "2          0.08        0.11  ...    0.125000   0.175000        11.02   \n",
              "3          0.08        0.11  ...    0.200000   0.200000        12.07   \n",
              "4          0.05        0.11  ...    0.434783   0.260870        11.67   \n",
              "\n",
              "   UniqWordDensity  TellDensity  AvgChar  Syllablesperword   mtld  \\\n",
              "0         0.488722           22     4.46              1.49  14.18   \n",
              "1         0.500000           16     4.01              1.35  13.68   \n",
              "2         0.394366           24     4.34              1.51  13.34   \n",
              "3         0.514286           10     4.48              1.51  13.29   \n",
              "4         0.503676           13     4.72              1.58  13.60   \n",
              "\n",
              "   namedEntities  nerPerSent  \n",
              "0           0.05        0.94  \n",
              "1           0.04        0.75  \n",
              "2           0.07        1.65  \n",
              "3           0.03        0.75  \n",
              "4           0.07        1.52  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-819c04bf-f713-497f-99d6-a3006c47d21b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "      <th>...</th>\n",
              "      <th>NumCompund</th>\n",
              "      <th>NumSimple</th>\n",
              "      <th>FleschScore</th>\n",
              "      <th>UniqWordDensity</th>\n",
              "      <th>TellDensity</th>\n",
              "      <th>AvgChar</th>\n",
              "      <th>Syllablesperword</th>\n",
              "      <th>mtld</th>\n",
              "      <th>namedEntities</th>\n",
              "      <th>nerPerSent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>10.19</td>\n",
              "      <td>0.488722</td>\n",
              "      <td>22</td>\n",
              "      <td>4.46</td>\n",
              "      <td>1.49</td>\n",
              "      <td>14.18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>9.15</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>16</td>\n",
              "      <td>4.01</td>\n",
              "      <td>1.35</td>\n",
              "      <td>13.68</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>11.02</td>\n",
              "      <td>0.394366</td>\n",
              "      <td>24</td>\n",
              "      <td>4.34</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.07</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>10</td>\n",
              "      <td>4.48</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>11.67</td>\n",
              "      <td>0.503676</td>\n",
              "      <td>13</td>\n",
              "      <td>4.72</td>\n",
              "      <td>1.58</td>\n",
              "      <td>13.60</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-819c04bf-f713-497f-99d6-a3006c47d21b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-819c04bf-f713-497f-99d6-a3006c47d21b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-819c04bf-f713-497f-99d6-a3006c47d21b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CEFR Level"
      ],
      "metadata": {
        "id": "FP_FwY1PBMEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#from textacy.preprocess import normalize_whitespace, preprocess_text\n",
        "\n",
        "\n",
        "def categorizeText(input_text):\n",
        "    \"\"\"\n",
        "    :Returns: List = [MainLevel, Difficulty] (some sort of language level)\n",
        "    \"\"\"\n",
        "    if (not(isinstance(input_text, str)) or (len(input_text) <= 0)):\n",
        "        dicti = {\"unknown\": \"NOT OKAY!\", \"A1\": \"THIS!\", \"A2\" : \"IS!\", \"B1\": \"NOT!\", \"B2\": \"A!\", \"C1\": \"TEXT!\", \"C2\": \"NO!\"}\n",
        "        return [\"NO!\", \"NO!\", dicti]\n",
        "\n",
        "    # normalize text with NLP\n",
        "    processed_text = processText(input_text)\n",
        "    \n",
        "    # store words of text lowercase in list\n",
        "    words: list = [item.lower() for item in processed_text.split()]\n",
        "\n",
        "    # count frequency of word in text\n",
        "    word_frequency: dict = getWordFrequency(words)\n",
        "\n",
        "    # Dataframe, set der Worte mit Sprachniveau\n",
        "    # word, level\n",
        "    set_word_table = getWordLevelDataFrameForText(set(words))\n",
        "\n",
        "    # Viewing the distribution\n",
        "    verteilung = {}\n",
        "    tmp_count = 0\n",
        "    \n",
        "    #for each word from the text, ordered by level,\n",
        "    \n",
        "    for lvl in [\"unknown\", \"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]:\n",
        "        for word in set_word_table.loc[set_word_table['level']== lvl, \"word\"]:\n",
        "            tmp_count += word_frequency[word]\n",
        "        tmp_result = tmp_count/ len(words) * 100\n",
        "        verteilung[lvl] = round(tmp_result)\n",
        "        tmp_count = 0\n",
        "    \n",
        "    #Rank based on the highest level that contains more than n different words\n",
        "    n = 4\n",
        "    levels, counts = np.unique(set_word_table['level'], return_counts=True)\n",
        "    \n",
        "    if (len(levels) > 0):\n",
        "        tmp_index, = np.where(levels == \"unknown\") # löschen der Stellen, an denen die Werte für UNKNOWN Worte stehen, da diese kein Sprachniveau sind\n",
        "        levels = np.delete(levels, tmp_index)\n",
        "        counts = np.delete(counts, tmp_index)\n",
        "    max_level = np.max(levels[counts > n])\n",
        "    \n",
        "    #Difficulty rating of unknown words, limit: m\n",
        "    count_easy = 0\n",
        "    count_hard = 0\n",
        "    m = 6 # siehe Wolfram alpha 5.1\n",
        "    \n",
        "    for word in set_word_table.loc[set_word_table['level']== \"unknown\", \"word\"]:\n",
        "        if len(word) > m:\n",
        "            count_hard += 1\n",
        "        elif len(word) <= m:\n",
        "            count_easy += 1   \n",
        "    \n",
        "    if count_easy <= count_hard:\n",
        "        difficulty = \"hard\"\n",
        "    else:\n",
        "        difficulty = \"easy\"\n",
        "\n",
        "    # return list [mainLevel, level of difficulty, language level_distribution]\n",
        "    ret_list_str = [\"unknown\", \"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
        "    return [ret_list_str.index(m) for m in ret_list_str if m == max_level][0]\n",
        "    \n",
        "\n",
        "\n",
        "def getWordFrequency(words: list) -> dict:\n",
        "    \"\"\"\n",
        "    :Return: dictionary with word and count\n",
        "    \"\"\"\n",
        "    dici = {}\n",
        "\n",
        "    for word in words:\n",
        "        if word in dici:     \n",
        "            dici[word] += 1\n",
        "        else:\n",
        "            dici[word] = 1\n",
        "            \n",
        "    return dici\n",
        "\n",
        "\n",
        "def getWordLevelDataFrameForText(text):\n",
        "    \"\"\"\n",
        "    Eingabe: set(text)\n",
        "    Ausgabe: DataFrame mit word und level (A1 - C2, unknown) für das gegebene Set des Textes\n",
        "    \"\"\"\n",
        "\n",
        "    # create DataFrame\n",
        "    word_level_table = pd.DataFrame(columns=['word', 'level'])\n",
        "\n",
        "    # open CEFR vocabulary file for english\n",
        "    scriptDir = '/content/gdrive/MyDrive/EssayScoringDataSet/cefr/'\n",
        "    relPath = \"cefr_vocab_en.json\"\n",
        "    cefr_file = open(os.path.join(scriptDir, relPath))\n",
        "    cefr_data = json.load(cefr_file)\n",
        "\n",
        "    for w in set(text):\n",
        "\n",
        "        level: str = \"\"\n",
        "\n",
        "        # find the CEFR level info for the current word\n",
        "        for data in cefr_data:\n",
        "\n",
        "            if data[\"word\"] == w:\n",
        "                if data[\"level\"]:\n",
        "                    level  = data[\"level\"]\n",
        "                else:\n",
        "                    level = \"unknown\"\n",
        "\n",
        "        # add row WORD LEVEL\n",
        "        word_level_table = word_level_table.append(\n",
        "            pd.DataFrame(\n",
        "                [\n",
        "                    [w, level]\n",
        "                ], \n",
        "                    columns=['word', 'level']\n",
        "            )\n",
        "        )\n",
        "        \n",
        "    # close cefr json file\n",
        "    cefr_file.close()\n",
        "\n",
        "    return word_level_table\n",
        "\n",
        "\n",
        "def processText(text):\n",
        "\n",
        "    mylist = re.findall(r'[^!?.,-;]+',text) # To remove punctuations  \n",
        "    str1 = ' '.join(mylist)\n",
        "\n",
        "    # lemmatize the entire text\n",
        "    # first, split the text to a list of words\n",
        "    words = TextBlob(str1).words\n",
        "    # then, lemmatize each word\n",
        "    lemmatizedText = \"\"\n",
        "    for w in words:\n",
        "        lemmatizedText += \"{} \".format(w.lemmatize())\n",
        "\n",
        "    # normalize the whitespaces for texts which include s.l. 'Title    And I am ...'\n",
        "    return lemmatizedText"
      ],
      "metadata": {
        "id": "DlIlCiiNBORo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGfufD9xE33r",
        "outputId": "58729da6-05f1-476b-f270-feb14e40dd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays['CEFRLevel']  = df_essays.apply(lambda x: categorizeText(x['Essay Text']), axis=1)      "
      ],
      "metadata": {
        "id": "1EcUNSXXDuU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "F0q9T4T5FC2h",
        "outputId": "2190a1bd-2a04-427b-a869-1cc3f03ac757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "0             35        816       0.12       0.17      0.09         0.06   \n",
              "1             28        587       0.13       0.19      0.08         0.05   \n",
              "2             40       1005       0.11       0.15      0.08         0.05   \n",
              "3             20        571       0.12       0.16      0.07         0.06   \n",
              "4             23        549       0.10       0.19      0.06         0.05   \n",
              "\n",
              "   PronounCount  PunctCount  ...  NumSimple  FleschScore  UniqWordDensity  \\\n",
              "0          0.06        0.12  ...   0.171429        10.19         0.488722   \n",
              "1          0.08        0.09  ...   0.392857         9.15         0.500000   \n",
              "2          0.08        0.11  ...   0.175000        11.02         0.394366   \n",
              "3          0.08        0.11  ...   0.200000        12.07         0.514286   \n",
              "4          0.05        0.11  ...   0.260870        11.67         0.503676   \n",
              "\n",
              "   TellDensity  AvgChar  Syllablesperword   mtld  namedEntities  nerPerSent  \\\n",
              "0           22     4.46              1.49  14.18           0.05        0.94   \n",
              "1           16     4.01              1.35  13.68           0.04        0.75   \n",
              "2           24     4.34              1.51  13.34           0.07        1.65   \n",
              "3           10     4.48              1.51  13.29           0.03        0.75   \n",
              "4           13     4.72              1.58  13.60           0.07        1.52   \n",
              "\n",
              "   CEFRLevel  \n",
              "0          6  \n",
              "1          6  \n",
              "2          6  \n",
              "3          6  \n",
              "4          5  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89551f2d-59b1-4a02-bbd4-ab1e7dd73e65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "      <th>...</th>\n",
              "      <th>NumSimple</th>\n",
              "      <th>FleschScore</th>\n",
              "      <th>UniqWordDensity</th>\n",
              "      <th>TellDensity</th>\n",
              "      <th>AvgChar</th>\n",
              "      <th>Syllablesperword</th>\n",
              "      <th>mtld</th>\n",
              "      <th>namedEntities</th>\n",
              "      <th>nerPerSent</th>\n",
              "      <th>CEFRLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.171429</td>\n",
              "      <td>10.19</td>\n",
              "      <td>0.488722</td>\n",
              "      <td>22</td>\n",
              "      <td>4.46</td>\n",
              "      <td>1.49</td>\n",
              "      <td>14.18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.94</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>9.15</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>16</td>\n",
              "      <td>4.01</td>\n",
              "      <td>1.35</td>\n",
              "      <td>13.68</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.75</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>11.02</td>\n",
              "      <td>0.394366</td>\n",
              "      <td>24</td>\n",
              "      <td>4.34</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.65</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>12.07</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>10</td>\n",
              "      <td>4.48</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.75</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>11.67</td>\n",
              "      <td>0.503676</td>\n",
              "      <td>13</td>\n",
              "      <td>4.72</td>\n",
              "      <td>1.58</td>\n",
              "      <td>13.60</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.52</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89551f2d-59b1-4a02-bbd4-ab1e7dd73e65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89551f2d-59b1-4a02-bbd4-ab1e7dd73e65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89551f2d-59b1-4a02-bbd4-ab1e7dd73e65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AWL feature"
      ],
      "metadata": {
        "id": "WWNIKjMoH69i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awlify\n",
        "\n",
        "from awlify import awlify\n",
        "import json\n",
        "global awl_list\n",
        "awl_list = []\n",
        "def iterate_nested(d):\n",
        "  for k, v in d.items():\n",
        "      if isinstance(v, dict):\n",
        "          iterate_nested(v)\n",
        "      else:\n",
        "          if k == 'awl_words':\n",
        "            if v:\n",
        "              for val in v:\n",
        "                if isinstance(val, dict):\n",
        "                  iterate_nested(val)\n",
        "          elif k == 'word':\n",
        "            if v not in awl_list:\n",
        "              awl_list.append(v)\n",
        "  return len(awl_list)\n",
        "\n",
        "\n",
        "def get_count_AWL(essay):\n",
        "  result = awlify(essay)\n",
        "  res = json.loads(result)\n",
        "  awl_count  = iterate_nested(res)\n",
        "  word_count = count_non_stop_words(essay)\n",
        "  return round(awl_count/word_count,2)\n",
        "\n",
        "\n",
        "df_essays['AWLLevel']  = df_essays.apply(lambda x: get_count_AWL(x['Essay Text']), axis=1)      "
      ],
      "metadata": {
        "id": "r78cjq8wH_Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "xW-Tf2YPJqtu",
        "outputId": "dcfc8345-039d-4078-cbd5-c656dff59265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "0             35        816       0.12       0.17      0.09         0.06   \n",
              "1             28        587       0.13       0.19      0.08         0.05   \n",
              "2             40       1005       0.11       0.15      0.08         0.05   \n",
              "3             20        571       0.12       0.16      0.07         0.06   \n",
              "4             23        549       0.10       0.19      0.06         0.05   \n",
              "\n",
              "   PronounCount  PunctCount  ...  FleschScore  UniqWordDensity  TellDensity  \\\n",
              "0          0.06        0.12  ...        10.19         0.488722           22   \n",
              "1          0.08        0.09  ...         9.15         0.500000           16   \n",
              "2          0.08        0.11  ...        11.02         0.394366           24   \n",
              "3          0.08        0.11  ...        12.07         0.514286           10   \n",
              "4          0.05        0.11  ...        11.67         0.503676           13   \n",
              "\n",
              "   AvgChar  Syllablesperword   mtld  namedEntities  nerPerSent  CEFRLevel  \\\n",
              "0     4.46              1.49  14.18           0.05        0.94          6   \n",
              "1     4.01              1.35  13.68           0.04        0.75          6   \n",
              "2     4.34              1.51  13.34           0.07        1.65          6   \n",
              "3     4.48              1.51  13.29           0.03        0.75          6   \n",
              "4     4.72              1.58  13.60           0.07        1.52          5   \n",
              "\n",
              "   AWLLevel  \n",
              "0      0.03  \n",
              "1      0.12  \n",
              "2      0.11  \n",
              "3      0.25  \n",
              "4      0.29  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e34e9a3-ee94-4a81-b894-a3ac8db47c29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "      <th>...</th>\n",
              "      <th>FleschScore</th>\n",
              "      <th>UniqWordDensity</th>\n",
              "      <th>TellDensity</th>\n",
              "      <th>AvgChar</th>\n",
              "      <th>Syllablesperword</th>\n",
              "      <th>mtld</th>\n",
              "      <th>namedEntities</th>\n",
              "      <th>nerPerSent</th>\n",
              "      <th>CEFRLevel</th>\n",
              "      <th>AWLLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>...</td>\n",
              "      <td>10.19</td>\n",
              "      <td>0.488722</td>\n",
              "      <td>22</td>\n",
              "      <td>4.46</td>\n",
              "      <td>1.49</td>\n",
              "      <td>14.18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.94</td>\n",
              "      <td>6</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>...</td>\n",
              "      <td>9.15</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>16</td>\n",
              "      <td>4.01</td>\n",
              "      <td>1.35</td>\n",
              "      <td>13.68</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.75</td>\n",
              "      <td>6</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>11.02</td>\n",
              "      <td>0.394366</td>\n",
              "      <td>24</td>\n",
              "      <td>4.34</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.65</td>\n",
              "      <td>6</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>12.07</td>\n",
              "      <td>0.514286</td>\n",
              "      <td>10</td>\n",
              "      <td>4.48</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.75</td>\n",
              "      <td>6</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>11.67</td>\n",
              "      <td>0.503676</td>\n",
              "      <td>13</td>\n",
              "      <td>4.72</td>\n",
              "      <td>1.58</td>\n",
              "      <td>13.60</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.52</td>\n",
              "      <td>5</td>\n",
              "      <td>0.29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e34e9a3-ee94-4a81-b894-a3ac8db47c29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e34e9a3-ee94-4a81-b894-a3ac8db47c29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e34e9a3-ee94-4a81-b894-a3ac8db47c29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TTR"
      ],
      "metadata": {
        "id": "C7bGbr-1Kugt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ttr_stats(str1):\n",
        "  tok = ld.tokenize(str1)\n",
        "  flt = ld.flemmatize(str1)\n",
        "  return(ld.ttr(flt),ld.root_ttr(flt),ld.log_ttr(flt))\n",
        "\n",
        "df_essays[['ttr','root_ttr','log_ttr']] = df_essays.apply(lambda row: pd.Series(get_ttr_stats(row['Essay Text'])),axis=1) \n"
      ],
      "metadata": {
        "id": "CJ6uHZc4KwGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "oki6icIYLWxs",
        "outputId": "e98fec1a-c4db-4705-b706-f7fbb65b140c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  WordCount  VerbCount  NounCount  AdjCount  AdverbCount  \\\n",
              "0             35        816       0.12       0.17      0.09         0.06   \n",
              "1             28        587       0.13       0.19      0.08         0.05   \n",
              "2             40       1005       0.11       0.15      0.08         0.05   \n",
              "3             20        571       0.12       0.16      0.07         0.06   \n",
              "4             23        549       0.10       0.19      0.06         0.05   \n",
              "\n",
              "   PronounCount  PunctCount  ...  AvgChar  Syllablesperword   mtld  \\\n",
              "0          0.06        0.12  ...     4.46              1.49  14.18   \n",
              "1          0.08        0.09  ...     4.01              1.35  13.68   \n",
              "2          0.08        0.11  ...     4.34              1.51  13.34   \n",
              "3          0.08        0.11  ...     4.48              1.51  13.29   \n",
              "4          0.05        0.11  ...     4.72              1.58  13.60   \n",
              "\n",
              "   namedEntities  nerPerSent  CEFRLevel  AWLLevel       ttr   root_ttr  \\\n",
              "0           0.05        0.94          6      0.03  0.505780  13.305004   \n",
              "1           0.04        0.75          6      0.12  0.492395  11.292937   \n",
              "2           0.07        1.65          6      0.11  0.387244  11.474444   \n",
              "3           0.03        0.75          6      0.25  0.506000  11.314504   \n",
              "4           0.07        1.52          5      0.29  0.504167  11.045738   \n",
              "\n",
              "    log_ttr  \n",
              "0  0.895765  \n",
              "1  0.886921  \n",
              "2  0.860025  \n",
              "3  0.890384  \n",
              "4  0.889072  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-824d7282-6ae6-4648-9b9d-4fa3d458d270\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>WordCount</th>\n",
              "      <th>VerbCount</th>\n",
              "      <th>NounCount</th>\n",
              "      <th>AdjCount</th>\n",
              "      <th>AdverbCount</th>\n",
              "      <th>PronounCount</th>\n",
              "      <th>PunctCount</th>\n",
              "      <th>...</th>\n",
              "      <th>AvgChar</th>\n",
              "      <th>Syllablesperword</th>\n",
              "      <th>mtld</th>\n",
              "      <th>namedEntities</th>\n",
              "      <th>nerPerSent</th>\n",
              "      <th>CEFRLevel</th>\n",
              "      <th>AWLLevel</th>\n",
              "      <th>ttr</th>\n",
              "      <th>root_ttr</th>\n",
              "      <th>log_ttr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "      <td>816</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>...</td>\n",
              "      <td>4.46</td>\n",
              "      <td>1.49</td>\n",
              "      <td>14.18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.94</td>\n",
              "      <td>6</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.505780</td>\n",
              "      <td>13.305004</td>\n",
              "      <td>0.895765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "      <td>587</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.09</td>\n",
              "      <td>...</td>\n",
              "      <td>4.01</td>\n",
              "      <td>1.35</td>\n",
              "      <td>13.68</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.75</td>\n",
              "      <td>6</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.492395</td>\n",
              "      <td>11.292937</td>\n",
              "      <td>0.886921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>1005</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>4.34</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.34</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.65</td>\n",
              "      <td>6</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.387244</td>\n",
              "      <td>11.474444</td>\n",
              "      <td>0.860025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>571</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>4.48</td>\n",
              "      <td>1.51</td>\n",
              "      <td>13.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.75</td>\n",
              "      <td>6</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>11.314504</td>\n",
              "      <td>0.890384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "      <td>549</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.11</td>\n",
              "      <td>...</td>\n",
              "      <td>4.72</td>\n",
              "      <td>1.58</td>\n",
              "      <td>13.60</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.52</td>\n",
              "      <td>5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.504167</td>\n",
              "      <td>11.045738</td>\n",
              "      <td>0.889072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-824d7282-6ae6-4648-9b9d-4fa3d458d270')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-824d7282-6ae6-4648-9b9d-4fa3d458d270 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-824d7282-6ae6-4648-9b9d-4fa3d458d270');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Below, We will not use **'TfIdfVectorizer'** but will use the features engineered above to do training and predictions."
      ],
      "metadata": {
        "id": "r2CM9m64IEhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features and target label\n",
        "y = df_essays['Essay Grading']\n",
        "X = df_essays['Essay Text']\n",
        "\n",
        "y = y.apply(lambda x:2 if x==\"Excellent (A+)\" else 1 if x=='Average (B-C)' else 0)\n",
        "\n",
        "\n",
        "# Import train_test_split\n",
        "\n",
        "# Split the 'features' and 'income' data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state = 0)\n",
        "\n",
        "# Show the results of the split\n",
        "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
        "\n",
        "# Naïve Bayes:\n",
        "text_clf_nb = Pipeline([('tfidf', TfidfVectorizer()),\n",
        "                     ('clf', MultinomialNB()),\n",
        "])\n",
        "text_clf_nb.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = text_clf_nb.predict(X_train)\n",
        "y_test_pred = text_clf_nb.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print('The training accuracy is', train_accuracy)\n",
        "print('The test accuracy is', test_accuracy)\n",
        "print('F1 score: ', format(f1_score(y_test,y_test_pred,average='micro')))\n",
        "confusion_matrix(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "Bv3Wl8XILm6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSjdGFHrarkS",
        "outputId": "670e7469-08a0-4b38-eb55-f0f073c41db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set has 587 samples.\n",
            "Testing set has 147 samples.\n",
            "[[0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611114 0.4022906 ]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.5361122  0.40228954]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.0615984  0.53611498 0.40228663]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229057]\n",
            " [0.06510057 0.52160121 0.41329822]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611127 0.40229047]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06160905 0.53607199 0.40231896]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611116 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159854 0.53610993 0.40229153]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229057]\n",
            " [0.06159846 0.53614863 0.4022529 ]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159879 0.53620674 0.40219447]\n",
            " [0.06159826 0.53611115 0.40229059]\n",
            " [0.06159826 0.53611117 0.40229057]\n",
            " [0.07021541 0.50311029 0.4266743 ]\n",
            " [0.06159828 0.53611339 0.40228833]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159898 0.53610701 0.402294  ]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229057]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159827 0.53611114 0.4022906 ]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159828 0.53611106 0.40229066]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229057]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06162401 0.54048305 0.39789294]\n",
            " [0.06159833 0.53612455 0.40227712]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159782 0.53611133 0.40229085]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.09366699 0.44500383 0.46132918]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.5361114  0.40229034]\n",
            " [0.06160818 0.53607438 0.40231744]\n",
            " [0.06159826 0.53611192 0.40228981]\n",
            " [0.08226053 0.47043798 0.44730149]\n",
            " [0.06159825 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611119 0.40229055]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159871 0.53610918 0.40229211]\n",
            " [0.0617277  0.53554232 0.40272998]\n",
            " [0.0614918  0.53615106 0.40235714]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611137 0.40229037]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611124 0.40229051]\n",
            " [0.06159826 0.53611125 0.40229049]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159914 0.5361073  0.40229356]\n",
            " [0.06159827 0.53611111 0.40229062]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611157 0.40229017]\n",
            " [0.06159828 0.53611466 0.40228706]\n",
            " [0.06159826 0.53611117 0.40229057]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159844 0.53611036 0.4022912 ]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611118 0.40229056]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611116 0.40229058]\n",
            " [0.06162682 0.53598536 0.40238782]\n",
            " [0.06159816 0.5361112  0.40229064]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229057]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159911 0.53626111 0.40213978]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611119 0.40229055]\n",
            " [0.06159827 0.53611109 0.40229063]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]\n",
            " [0.06159826 0.53611117 0.40229058]]\n",
            "The training accuracy is 1.0\n",
            "The test accuracy is 0.5918367346938775\n",
            "F1 score:  0.5918367346938775\n"
          ]
        }
      ],
      "source": [
        "import dill as pickle\n",
        "\n",
        "# Split the data into features and target label\n",
        "y = df_essays['Essay Grading']\n",
        "X = df_essays.drop(['Essay Grading','Essay Text'], axis = 1)\n",
        "\n",
        "y = y.apply(lambda x:2 if x==\"Excellent (A+)\" else 1 if x=='Average (B-C)' else 0)\n",
        "\n",
        "# Import train_test_split\n",
        "\n",
        "# Split the 'features' and 'income' data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state = 0)\n",
        "\n",
        "# Show the results of the split\n",
        "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
        "\n",
        "model = SVC(kernel='rbf', gamma=1,random_state = 39,probability=True,C=1000)\n",
        "model.fit(X_train, y_train)\n",
        "# # # Making predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "print(model.predict_proba(X_test))\n",
        "\n",
        "# # #results = model.predict_proba(X_test)[0]\n",
        "\n",
        "\n",
        "# Calculate the accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print('The training accuracy is', train_accuracy)\n",
        "print('The test accuracy is', test_accuracy)\n",
        "print('F1 score: ', format(f1_score(y_test,y_test_pred,average='micro')))\n",
        "confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "filename = os.path.join(\"/content/gdrive/MyDrive/Textify.ai/\",\"ModelNewFeatures.pkl\")\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nGKJDCizH8wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr= LogisticRegression(solver='lbfgs', random_state=0,max_iter =10000)\n",
        "lr.fit(X_train, y_train)\n",
        "print(lr.predict_proba(X_test))\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print('The training accuracy is', train_accuracy)\n",
        "print('The test accuracy is', test_accuracy)\n",
        "print('F1 score: ', format(f1_score(y_test,y_test_pred,average='micro')))\n",
        "confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "filename = os.path.join(\"/content/gdrive/MyDrive/Textify.ai/\",\"LogRegEssayGrader.sav\")\n",
        "pickle.dump(model, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaLNNr8IldiN",
        "outputId": "c8a0a46d-8c7a-47c1-d3ab-656579935797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.05964791 0.45074232 0.48960977]\n",
            " [0.05274692 0.5551043  0.39214878]\n",
            " [0.0452368  0.48115391 0.47360929]\n",
            " [0.06358353 0.43112011 0.50529636]\n",
            " [0.06506717 0.58349105 0.35144178]\n",
            " [0.07999556 0.51697433 0.40303011]\n",
            " [0.09322853 0.52615274 0.38061873]\n",
            " [0.0569626  0.47721097 0.46582643]\n",
            " [0.05825424 0.49806721 0.44367855]\n",
            " [0.05478746 0.53056968 0.41464285]\n",
            " [0.04290894 0.49689084 0.46020022]\n",
            " [0.0264493  0.40978816 0.56376254]\n",
            " [0.05512549 0.4773674  0.46750711]\n",
            " [0.05691351 0.57101006 0.37207643]\n",
            " [0.10466586 0.46314488 0.43218926]\n",
            " [0.04070966 0.55913844 0.4001519 ]\n",
            " [0.05120049 0.49518147 0.45361804]\n",
            " [0.04460006 0.47765829 0.47774165]\n",
            " [0.09501053 0.58082151 0.32416796]\n",
            " [0.043364   0.59819852 0.35843748]\n",
            " [0.0724021  0.49410761 0.43349029]\n",
            " [0.09387508 0.62694389 0.27918103]\n",
            " [0.03670768 0.44015577 0.52313655]\n",
            " [0.05228771 0.50270403 0.44500825]\n",
            " [0.07947787 0.60246255 0.31805958]\n",
            " [0.04334199 0.56987659 0.38678142]\n",
            " [0.05805367 0.52686674 0.41507959]\n",
            " [0.04246836 0.52903429 0.42849734]\n",
            " [0.06910599 0.5572574  0.37363661]\n",
            " [0.06776058 0.53291572 0.3993237 ]\n",
            " [0.07017221 0.48832128 0.44150651]\n",
            " [0.05025994 0.52521305 0.42452701]\n",
            " [0.06091559 0.47845175 0.46063267]\n",
            " [0.03865509 0.49830965 0.46303526]\n",
            " [0.05197493 0.54931795 0.39870712]\n",
            " [0.05209415 0.49448202 0.45342383]\n",
            " [0.04674729 0.52807511 0.4251776 ]\n",
            " [0.057041   0.49433851 0.44862048]\n",
            " [0.09329967 0.5010516  0.40564873]\n",
            " [0.05103589 0.6172934  0.33167071]\n",
            " [0.06955038 0.66704747 0.26340215]\n",
            " [0.05963982 0.52787283 0.41248735]\n",
            " [0.07963374 0.56784462 0.35252164]\n",
            " [0.0508643  0.54519181 0.40394389]\n",
            " [0.08838949 0.63579768 0.27581283]\n",
            " [0.07003391 0.54722886 0.38273723]\n",
            " [0.06254542 0.57085718 0.36659741]\n",
            " [0.07481639 0.47694657 0.44823704]\n",
            " [0.05512851 0.46712542 0.47774607]\n",
            " [0.05390927 0.55717727 0.38891346]\n",
            " [0.0775158  0.51587671 0.40660749]\n",
            " [0.03664851 0.40696916 0.55638233]\n",
            " [0.10076852 0.62323553 0.27599595]\n",
            " [0.08886225 0.46095801 0.45017974]\n",
            " [0.06575343 0.54056919 0.39367738]\n",
            " [0.10055054 0.50280441 0.39664504]\n",
            " [0.04875575 0.6070766  0.34416764]\n",
            " [0.05471375 0.5636359  0.38165036]\n",
            " [0.0729499  0.5259953  0.4010548 ]\n",
            " [0.04299694 0.52766079 0.42934227]\n",
            " [0.05597236 0.54734381 0.39668383]\n",
            " [0.07193556 0.51076528 0.41729915]\n",
            " [0.05755518 0.60887308 0.33357174]\n",
            " [0.06649185 0.45935357 0.47415458]\n",
            " [0.05977665 0.58572192 0.35450144]\n",
            " [0.04549534 0.58638631 0.36811835]\n",
            " [0.10310454 0.63848422 0.25841124]\n",
            " [0.08606694 0.56732611 0.34660695]\n",
            " [0.07740043 0.61729814 0.30530143]\n",
            " [0.05792815 0.55711455 0.3849573 ]\n",
            " [0.08309458 0.6072366  0.30966882]\n",
            " [0.04097575 0.52585772 0.43316653]\n",
            " [0.09675482 0.47731342 0.42593176]\n",
            " [0.08406719 0.6005472  0.31538561]\n",
            " [0.07282855 0.52582087 0.40135059]\n",
            " [0.04602545 0.55555086 0.39842369]\n",
            " [0.05120049 0.49518147 0.45361804]\n",
            " [0.05836807 0.52437769 0.41725424]\n",
            " [0.05412593 0.47624526 0.46962881]\n",
            " [0.05911659 0.49473672 0.44614669]\n",
            " [0.05043351 0.53967402 0.40989248]\n",
            " [0.05156977 0.47138683 0.47704339]\n",
            " [0.08954666 0.55474101 0.35571233]\n",
            " [0.05466059 0.48372624 0.46161317]\n",
            " [0.06627457 0.61737971 0.31634572]\n",
            " [0.0631823  0.56584177 0.37097593]\n",
            " [0.08895478 0.60226197 0.30878325]\n",
            " [0.0802081  0.69983056 0.21996134]\n",
            " [0.10530474 0.54877272 0.34592254]\n",
            " [0.04164224 0.5711518  0.38720596]\n",
            " [0.08963033 0.52300523 0.38736444]\n",
            " [0.05844291 0.49972222 0.44183486]\n",
            " [0.05742498 0.56471793 0.37785709]\n",
            " [0.06959979 0.65060732 0.27979289]\n",
            " [0.06871822 0.61806551 0.31321627]\n",
            " [0.13040216 0.61877993 0.25081791]\n",
            " [0.03971888 0.40924744 0.55103369]\n",
            " [0.08969949 0.54603196 0.36426856]\n",
            " [0.06083695 0.54872453 0.39043852]\n",
            " [0.07137181 0.53131328 0.39731491]\n",
            " [0.14460988 0.38639263 0.46899749]\n",
            " [0.12838945 0.55311105 0.3184995 ]\n",
            " [0.06445436 0.62541266 0.31013299]\n",
            " [0.05786916 0.54048306 0.40164778]\n",
            " [0.06060312 0.56714365 0.37225323]\n",
            " [0.07898272 0.42905796 0.49195932]\n",
            " [0.03586641 0.5620584  0.40207519]\n",
            " [0.06166833 0.53076709 0.40756459]\n",
            " [0.05258913 0.58042375 0.36698711]\n",
            " [0.0966881  0.57273509 0.33057681]\n",
            " [0.06212795 0.54821991 0.38965214]\n",
            " [0.18642468 0.56249699 0.25107833]\n",
            " [0.06446706 0.44903119 0.48650175]\n",
            " [0.0966475  0.51250376 0.39084873]\n",
            " [0.06247517 0.51265961 0.42486522]\n",
            " [0.10104222 0.4592807  0.43967708]\n",
            " [0.06043306 0.54674408 0.39282286]\n",
            " [0.04806034 0.53011292 0.42182673]\n",
            " [0.05337212 0.53370092 0.41292696]\n",
            " [0.05164899 0.55150334 0.39684767]\n",
            " [0.04259124 0.50483675 0.45257201]\n",
            " [0.04639987 0.51935414 0.43424598]\n",
            " [0.05436084 0.41362981 0.53200935]\n",
            " [0.04376278 0.40418232 0.5520549 ]\n",
            " [0.08108783 0.47142674 0.44748543]\n",
            " [0.05971919 0.60904147 0.33123934]\n",
            " [0.05614916 0.53122271 0.41262813]\n",
            " [0.05276878 0.54727589 0.39995533]\n",
            " [0.04839193 0.49533081 0.45627725]\n",
            " [0.05035125 0.52546829 0.42418046]\n",
            " [0.06543926 0.45386484 0.4806959 ]\n",
            " [0.07558506 0.48952371 0.43489123]\n",
            " [0.10662404 0.44943182 0.44394414]\n",
            " [0.06440061 0.55460133 0.38099806]\n",
            " [0.03552197 0.55943854 0.40503949]\n",
            " [0.06349848 0.592257   0.34424451]\n",
            " [0.08535489 0.49259137 0.42205374]\n",
            " [0.04825168 0.48750022 0.4642481 ]\n",
            " [0.1182167  0.59697912 0.28480419]\n",
            " [0.05166942 0.47991246 0.46841812]\n",
            " [0.06547729 0.63913801 0.29538469]\n",
            " [0.10832562 0.51629132 0.37538306]\n",
            " [0.05854367 0.47980192 0.46165441]\n",
            " [0.04221743 0.49120845 0.46657412]\n",
            " [0.0488747  0.61488031 0.33624499]\n",
            " [0.03827892 0.41488588 0.5468352 ]\n",
            " [0.08616207 0.49854763 0.4152903 ]]\n",
            "The training accuracy is 0.989778534923339\n",
            "The test accuracy is 0.5850340136054422\n",
            "F1 score:  0.5850340136054422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global str\n",
        "\n",
        "import dill as pickle\n",
        "import spacy\n",
        "import nltk\n",
        "import textwrap\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import re\n",
        "from textatistic import Textatistic\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def showntell_essay(InputEssay):\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "  doc  = nlp(InputEssay)\n",
        "  mental_tells = ['loved','realized','thought','hoped','considered','wondered','prayed','knew','saw','watched','heard','felt','could','see','seemed','appeared',\n",
        "  'looked','believed','reflected','disgusted','feared','show','noticed','smelled','wonder','walked','come','hate','decided','wished','feel','see','smell',\n",
        "  'fell']\n",
        "\n",
        "  emotional_tells = ['adoration','agitation','amazement','amusement','anger','anguish','annoyance','anticipation','anxiety','confidence','conflicted','confusion',\n",
        "  'contempt','curiosity','defeat','defensiveness','denial','depression','desire','desperation','determination','disappointment','disbelief','disgust','doubt','dread',\n",
        "  'eagerness','elation','embarrassment','envy','excitement','fear','frustration','gratitude','guilt','happiness','hatred','hopefulness','humiliation','hurt','impatience',\n",
        "  'indifference','insecurity','irritation','jealousy','loneliness','love','nervousness','nostalgia','overwhelmed','paranoia','peacefulness','pride','rage','regret','relief',\n",
        "  'reluctance','remorse','resentment','resignation','sadness','satisfaction','scorn','shame','skepticism','smugness','somberness','surprise','shock','suspicion','sympathy',\n",
        "  'terror','uncertainty','unease','wariness','worry']\n",
        "\n",
        "  motivational_tells = ['decided','because','tried','when']\n",
        "\n",
        "  emotional_adjectives = ['frustated', 'happy', 'tall', 'angry', 'sad', 'hungry', 'excited', 'embarrased', 'bright', 'shocked', 'hot', 'beautiful', \n",
        "                          'afraid', 'cold', 'interesting', 'confused', 'sweet', 'different', 'scared', 'mournful', 'furious', 'overwhelmed', 'stressed', \n",
        "                          'unique', 'overjoyed', 'scarier', 'tired', 'shy', 'giddy', 'anxious','chilly','friendly','ghastly','ghostly','holy','kingly',\n",
        "                          'knightly','lonely','lovely','orderly','prickly','queenly','surly','ugly','worldly','wrinkly']\n",
        "\n",
        "  adverbs_avoid = ['very', 'really', 'spectacularly','already' 'abruptly', 'absently', 'absentmindedly', 'accusingly', 'actually', 'adversely', 'affectionately', \n",
        "                  'amazingly', 'angrily', 'anxiously', 'arrogantly', 'bashfully', 'beautifully', 'boldly', 'bravely', 'breathlessly', 'brightly', 'briskly', 'broadly', \n",
        "                  'calmly', 'carefully', 'carelessly', 'certainly', 'cheaply', 'cheerfully', 'cleanly', 'clearly', 'cleverly', 'closely', 'clumsily', 'coaxingly', 'commonly', \n",
        "                  'compassionately', 'conspicuously', 'continually', 'coolly', 'correctly', 'crisply', 'crossly', 'curiously', 'daintily', 'dangerously', 'darkly', 'dearly', \n",
        "                  'deceivingly', 'delicately', 'delightfully', 'desperately', 'determinedly', 'diligently', 'disgustingly', 'distinctly', 'doggedly', 'dreamily', 'emptily', \n",
        "                  'energetically', 'enormously', 'enticingly', 'entirely', 'enviously', 'especially', 'evenly', 'exactly', 'excitedly', 'exclusively', 'expertly', 'extremely', \n",
        "                  'fairly', 'faithfully', 'famously', 'fearlessly', 'ferociously', 'fervently', 'finally', 'foolishly', 'fortunately', 'frankly', 'frantically', 'freely', \n",
        "                  'frenetically', 'frightfully', 'fully', 'furiously', 'generally', 'generously', 'gently', 'gleefully', 'gratefully', 'greatly', 'greedily', 'grumpily', \n",
        "                  'guiltily', 'happily', 'harshly', 'hatefully', 'heartily', 'heavily', 'helpfully', 'helplessly', 'highly', 'hopelessly', 'hungrily', 'immediately', 'importantly', \n",
        "                  'impulsively', 'inadvertently', 'increasingly', 'incredibly', 'innocently', 'instantly', 'intensely', 'intently', 'inwardly', 'jokingly', 'kindly', 'knowingly', \n",
        "                  'lawfully', 'lightly', 'likely', 'longingly', 'loudly', 'madly', 'marvelously', 'meaningfully', 'mechanically', 'meekly', 'mentally', 'messily', 'mindfully', 'miserably', \n",
        "                  'mockingly', 'mostly', 'mysteriously', 'naturally', 'nearly', 'neatly', 'negatively', 'nervously', 'nicely', 'obviously', 'occasionally', 'oddly', 'openly', 'outwardly', \n",
        "                  'partially', 'passionately', 'patiently', 'perfectly', 'perpetually', 'playfully', 'pleasantly', 'pleasingly', 'politely', 'poorly', 'positively', 'potentially', 'powerfully', \n",
        "                  'professionally', 'properly', 'proudly', 'quaveringly', 'queerly', 'quickly', 'quietly', 'quintessentially', 'rapidly', 'rapturously', 'ravenously', 'readily', 'reassuringly', \n",
        "                  'regretfully', 'reluctantly', 'reproachfully', 'restfully', 'righteously', 'rightfully', 'rigidly', 'rudely', 'sadly', 'safely', 'scarcely', 'searchingly', 'sedately', \n",
        "                  'seemingly', 'selfishly', 'separately', 'seriously', 'sharply', 'sheepishly', 'sleepily', 'slowly', 'slyly', 'softly', 'solidly', 'speedily', 'sternly', 'stingily', 'strictly', \n",
        "                  'stubbornly', 'successfully', 'superstitiously', 'surprisingly', 'suspiciously', 'sympathetically', 'tenderly', 'terribly', 'thankfully', 'thoroughly', 'thoughtfully', 'tightly', \n",
        "                  'totally', 'tremendously', 'triumphantly', 'truly', 'truthfully', 'understandably', 'unfairly', 'unfortunately', 'unhappily', 'unwillingly', 'urgently', 'usually', 'utterly', 'vastly', \n",
        "                  'venomously', 'viciously', 'violently', 'warmly', 'wearily wholly', 'wildly', 'wilfully', 'wisely', 'wonderfully', 'wonderingly', 'worriedly']\n",
        "\n",
        "  aux_tell_list = []\n",
        "  ment_tell_list = []\n",
        "  det_tell_list = []\n",
        "  motiv_tell_list = []\n",
        "  emot_adj_tell_list  = []\n",
        "  adv_tell_list  = []\n",
        "  adj_tell_list = []\n",
        "  sent_level_dict = {}\n",
        "  count = 0\n",
        "\n",
        "  output_dict = {}\n",
        "\n",
        "  adj_dict_inner = {}\n",
        "  adv_dict_inner = {}\n",
        "  aux_dict_inner = {}\n",
        "  emot_dict_inner = {}\n",
        "  det_dict_inner = {}\n",
        "  ment_dict_inner = {}\n",
        "  motiv_dict_inner = {}\n",
        "\n",
        "  doc_sents = [sent for sent in doc.sents]\n",
        "  len_tot_sents = len(doc_sents)\n",
        "  for sents in doc.sents:\n",
        "    count = 0\n",
        "    for ix,token in enumerate(sents):\n",
        "      tok_pos=token.idx\n",
        "      if token.is_sent_start:    # checking for first token\n",
        "        if sents[ix].tag_ == 'PRP' or sents[ix].tag_ == 'PRP$' or sents[ix].tag_ == 'NN' :        # check for 'PRP' (Pronoun Personal) specifically with  'I','We','They','He','She'. 'You'.,check for 'PRP$' (Pronoun Possessive) my, our, your, his, her, its, and their,check for 'NN' (noun, singular or mass) i.e. 'Non-specific Nouns'\n",
        "          if sents[ix + 1].pos_ == 'AUX' or sents[ix + 1].pos_ == 'MD':                           # check for the token to the right for 'AUX' and 'MD'.\n",
        "            tok = (sents[ix:ix+2])     # getting the right token as well\n",
        "            right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "            aux_dict_inner[\"startIndex\"] = tok_pos\n",
        "            aux_dict_inner[\"endIndex\"]   = right_pos\n",
        "            aux_dict_inner[\"text\"]       = tok\n",
        "            aux_tell_list.append(aux_dict_inner.copy())          \n",
        "            count +=1\n",
        "            sent_level_dict[sents] = count\n",
        "          elif sents[ix + 1].pos_ == 'VERB':\n",
        "            if sents[ix+1].text.lower() in mental_tells or sents[ix+1].lemma_.lower() in mental_tells: # check if the token next to the first token is a 'VERB' out of 'mental tell' verbs.\n",
        "              tok = (sents[ix:ix+2])                                                                  # check for 'NN' (noun, singular or mass) i.e. 'Non-specific Nouns'\n",
        "              right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "              ment_dict_inner[\"startIndex\"] = tok_pos\n",
        "              ment_dict_inner[\"endIndex\"]   = right_pos\n",
        "              ment_dict_inner[\"text\"]       = tok\n",
        "              ment_tell_list.append(ment_dict_inner.copy())                \n",
        "              count +=1\n",
        "              sent_level_dict[sents] = count            \n",
        "        elif sents[ix].pos_ == 'DET':                                                             # check if the first token is a 'determiner' \n",
        "          if sents[ix + 1].pos_ == 'ADJ' or sents[ix + 1].tag_ == 'RBS':                          # and next one is 'adverb superlative' or an 'adjective'.\n",
        "              tok = (sents[ix:ix+2])\n",
        "              right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "              det_dict_inner[\"startIndex\"] = tok_pos\n",
        "              det_dict_inner[\"endIndex\"]   = right_pos\n",
        "              det_dict_inner[\"text\"]       = tok              \n",
        "              det_tell_list.append(det_dict_inner.copy())\n",
        "              count +=1\n",
        "              sent_level_dict[sents] = count            \n",
        "      if token.text.lower() in motivational_tells or token.lemma_.lower() in motivational_tells:   # check if the token is out of the 'motivational tell' list\n",
        "          tok = token.text.lower()\n",
        "          right_pos = sents[ix+1].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "          motiv_dict_inner[\"startIndex\"] = tok_pos\n",
        "          motiv_dict_inner[\"endIndex\"]   = right_pos\n",
        "          motiv_dict_inner[\"text\"]       = tok       \n",
        "          motiv_tell_list.append(motiv_dict_inner.copy())\n",
        "          count +=1\n",
        "          sent_level_dict[sents] = count        \n",
        "      elif sents[ix].text.lower() == 'to' and sents[ix + 1].pos_ == 'VERB':                        # check if the word is of the form 'to [Verb]'\n",
        "          tok = (sents[ix:ix+2])\n",
        "          right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "          motiv_dict_inner[\"startIndex\"] = tok_pos\n",
        "          motiv_dict_inner[\"endIndex\"]   = right_pos\n",
        "          motiv_dict_inner[\"text\"]       = tok       \n",
        "          motiv_tell_list.append(motiv_dict_inner.copy())\n",
        "          count +=1\n",
        "          sent_level_dict[sents] = count        \n",
        "      elif any(x in sents[ix].text.lower() for x in ['with','in']) and (sents[ix + 1].pos_ == 'NOUN' or sents[ix + 1].pos_ == 'PROPN') and sents[ix + 1].text.lower() in emotional_tells: # check if the word is of the form 'with [noun] or in [noun]'\n",
        "          tok = (sents[ix:ix+2])\n",
        "          right_pos = sents[ix+2].idx-1 # getting the right 2 token's starting character offset.  \n",
        "          emot_dict_inner[\"startIndex\"] = tok_pos\n",
        "          emot_dict_inner[\"endIndex\"]   = right_pos\n",
        "          emot_dict_inner[\"text\"]       = tok                                                         \n",
        "          emot_adj_tell_list.append(emot_dict_inner.copy())\n",
        "          count +=1\n",
        "          sent_level_dict[sents] = count        \n",
        "      elif token.pos_ == 'ADJ' and (token.text.lower() in emotional_adjectives or token.lemma_.lower() in emotional_adjectives):  # check if the word is out of the list of 'emotional' adjective word list\n",
        "        tok = token.text.lower()\n",
        "        right_pos = sents[ix+1].idx-1 # getting the right 2 token's starting character offset.                                                    \n",
        "        adj_dict_inner[\"startIndex\"] = tok_pos\n",
        "        adj_dict_inner[\"endIndex\"]   = right_pos\n",
        "        adj_dict_inner[\"text\"]       = tok     \n",
        "        adj_tell_list.append(adj_dict_inner.copy())\n",
        "        count +=1\n",
        "        sent_level_dict[sents] = count      \n",
        "      elif token.pos_ == 'ADV' and (token.text.lower() in adverbs_avoid or token.lemma_.lower() in adverbs_avoid):             # check if the word is out of the list of 'adverb to avoid' word list\n",
        "        tok_pos=token.idx\n",
        "        right_pos = sents[ix+1].idx-1 # getting the right token's starting character offset.\n",
        "        tok = token.text.lower()\n",
        "        adv_dict_inner[\"startIndex\"] = tok_pos\n",
        "        adv_dict_inner[\"endIndex\"]   = right_pos\n",
        "        adv_dict_inner[\"text\"]       = tok  \n",
        "        adv_tell_list.append(adv_dict_inner.copy())\n",
        "        count +=1\n",
        "        sent_level_dict[sents] = count   \n",
        "  \n",
        "  return (len(sent_level_dict))\n",
        "\n",
        "def non_stop_words(essay):\n",
        "  word_tokens = word_tokenize(essay)\n",
        "  filtered_sentence = [w for w in word_tokens]\n",
        "  str1 = ' '.join(filtered_sentence)\n",
        "  mylist = re.findall(r'[^!?.,-;]+',str1) # To remove punctuations\n",
        "  str1 = ''.join(mylist)\n",
        "  return str1,len(filtered_sentence)\n",
        "\n",
        "def word_count(essay):\n",
        "  out = []\n",
        "  seen = set()\n",
        "  string,length = non_stop_words(essay)\n",
        "  doc = nlp(string)\n",
        "  for word in doc:\n",
        "    if word.text not in seen:\n",
        "      if word.text != ' ':\n",
        "        out.append(word)\n",
        "        seen.add(word.text)\n",
        "  return (len(seen)/length)   # Unique words density\n",
        "\n",
        "def get_flesch_score(essay_text):\n",
        "  #readability_score = Textatistic(essay_text).scores\n",
        "  return 50.0 #round(readability_score['flesch_score'],2)\n",
        "\n",
        "\n",
        "def getCountTypeSent(essay_text):\n",
        "  complex_comp_list=[]\n",
        "  complex_list=[]\n",
        "  compound_list=[]\n",
        "  simple_list=[]\n",
        "  dep_list = []\n",
        "  docu = nlp(essay_text)\n",
        "  num_sent = len([sent for sent in docu.sents]) # Counting the number of sentences\n",
        "\n",
        "  for sents in docu.sents:\n",
        "    for token in sents:# Tokenize the sentence into words/tokens\n",
        "      #subtree argument gives the subtree of the token when parsed in dependency parsing.\n",
        "      subtree = token.subtree\n",
        "      #Looking at the ancestors of a token can tell us how deep it is\n",
        "      k = list(token.ancestors)\n",
        "      #we need to add this to make the indexing work properly\n",
        "      k.append('added_to_get_proper_indexing')\n",
        "      #k=2 gives us the first level of the tree, k=3 will give us the next level.\n",
        "      if(len(k)==2):\n",
        "        #print([(t.text) for t in subtree], token.dep_)\n",
        "        dep_list.append(token.dep_)\n",
        "      #we missed the root phrase in the previous \n",
        "      if(token.dep_=='ROOT'):\n",
        "        k =[token.text]\n",
        "      #print(k, 'root')\n",
        "\n",
        "    #complex sentences have (advcl) in their dependency tree\n",
        "    #compound sentences have (cc)-> coordination and (conj)-> conjuction in their dependency tree\n",
        "    #compound complex sentences have both the above\n",
        "    #simple sentences have neither.\n",
        "    if ('advcl') in dep_list and ('cc') in dep_list and ('conj') in dep_list:\n",
        "      complex_comp_list.append('Complex-compound sentence')\n",
        "    elif ('advcl') in dep_list:\n",
        "      complex_list.append('Complex sentence')\n",
        "    elif ('cc') in dep_list and ('conj') in dep_list:\n",
        "      compound_list.append('Compound sentence')\n",
        "    else:\n",
        "      simple_list.append('Simple sentence')\n",
        "  return (len(complex_comp_list)/num_sent,len(complex_list)/num_sent,len(compound_list)/num_sent,len(simple_list)/num_sent)\n",
        "\n",
        "def check_passive_voice(inputEssay):\n",
        "  # # running the model on sentence\n",
        "  doc = nlp(inputEssay)\n",
        "  dep_list = []\n",
        "  passive_list = []\n",
        "  sents = list(doc.sents)\n",
        "\n",
        "  for sents in doc.sents:\n",
        "    dep_list = []\n",
        "    for token in sents:# Tokenize the sentence into words/tokens\n",
        "      #print(token.text, token.pos_, token.dep_)  # form a list of various syntactic dependencies  \n",
        "      dep_list.append(token.dep_)\n",
        "\n",
        "    if ('nsubjpass') in dep_list or ('auxpass') in dep_list:\n",
        "      passive_list.append(sents)\n",
        "\n",
        "  return (round((len(sents)-len(passive_list))/len(sents),2)) # returning active voice sentences density\n",
        "\n",
        "def count_feature(postag,essay,wordcount,roundval):\n",
        "  doc=nlp(essay)\n",
        "  pos_counts = doc.count_by(spacy.attrs.POS)\n",
        "  for k,v in sorted(pos_counts.items()):\n",
        "    if doc.vocab[k] == postag:\n",
        "      return round(v/wordcount,roundval)\n",
        "\n",
        "def count_non_stop_words(essay):\n",
        "    doc=nlp(essay)\n",
        "    return len(doc)\n",
        "\n",
        "def count_sentences(essay):\n",
        "  doc = nlp(essay)\n",
        "  doc_sents = [sent for sent in doc.sents]\n",
        "  return len(doc_sents)\n",
        "  \n",
        "\n",
        "def score_main(input_essay):\n",
        "  ret_dict = {}\n",
        "  lines={}\n",
        "  wrapper = textwrap.TextWrapper()\n",
        "  word_list = wrapper.wrap(text=input_essay)\n",
        "  print(\"HIII\")\n",
        "  print(word_list)\n",
        "  text = ''.join(str(v) for v in word_list)\n",
        "  lines[0] = text     # creating a dummy dictionary to be later converted to Dataframe.\n",
        "\n",
        "  df_test = pd.DataFrame(lines.values(),columns=['Essay Text'])\n",
        "  df_test['SentenceCount'] = df_test['Essay Text'].apply(count_sentences)\n",
        "  df_test['WordCount'] = df_test['Essay Text'].apply(count_non_stop_words)\n",
        "  df_test['VerbCount']  = df_test.apply(lambda x: count_feature('VERB',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "  df_test['NounCount']  = df_test.apply(lambda x: count_feature('NOUN',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "  df_test['AdjCount']  = df_test.apply(lambda x: count_feature('ADJ',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "  df_test['AdverbCount']  = df_test.apply(lambda x: count_feature('ADV',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "  df_test['PronounCount']  = df_test.apply(lambda x: count_feature('PRON',x['Essay Text'], x['WordCount'],2), axis=1)\n",
        "  df_test['PunctCount']  = df_test.apply(lambda x: count_feature('PUNCT',x['Essay Text'], x['WordCount'],2), axis=1) \n",
        "  df_test['NumberofActiveVoice'] = df_test.apply(lambda row: pd.Series(check_passive_voice(row['Essay Text'])),axis=1) \n",
        "  df_test[['NumComplexComp','NumComplex','NumCompund','NumSimple']] = df_test.apply(lambda row: pd.Series(getCountTypeSent(row['Essay Text'])),axis=1) \n",
        "  df_test['FleschScore'] = df_test.apply(lambda x: get_flesch_score(x['Essay Text']),axis=1) \n",
        "  df_test['UniqWordDensity']  = df_test.apply(lambda x: word_count(x['Essay Text']), axis=1)\n",
        "  df_test['TellDensity']  = df_test.apply(lambda x: showntell_essay(x['Essay Text']), axis=1)\n",
        "  print(df_test.head())\n",
        "\n",
        "\n",
        "  Xinput = df_test.drop(['Essay Text'], axis = 1)\n",
        "  ret_dict['predictions'] = lr.predict_proba(Xinput).tolist()\n",
        "  ret_dict['classes'] = lr.classes_.tolist()\n",
        "  return ret_dict\n",
        "  #return df_test\n",
        "\n",
        "# main\n",
        "input_str = 'I was Sweat poured down my face as I am struggled to breathe. I am to obey I was dehydrated I am to obey and who am trying as hard as I could not to up. From the bleachers and the I am sidelines, the eyes of every member of the crowd I was were focused intently on I am me. One side of the gym hoped am fail, and the other side prayed that I would succeed. The muscles in my legs were undergoing uncontrollable spasms. It seemed that I could not continue, but if I surrendered to the pleas of my body, I would not only be failing myself, but failing everyone on my wrestling team. All I could think about was winning my match. I absolutely had to win. As I looked around at the large crowd in my opponent’s school gymnasium, panic struck me, but then I convinced myself that I would win this match no matter what. The piercing noise of the referee’s whistle split the air, and I knew it was time to continue. We had reached double overtime, something that I had never seen occur throughout my four years of competitive wrestling. The importance of this match was very clear. Each point the judges awarded could mean the difference between winning and losing the tournament. If I could control my opponent for thirty more seconds, I would be walking out of the ring with my chin up. The first ten seconds of the match passed quickly. Then, seemingly time stood still. The other team began chanting to inspire my opponent. Each second seemed like an hour. I felt eternity pass by. My opponent stood up, but I maintained the control. My team began to count down the last five seconds of the match. My mind and my body were fighting their own battle. As my teammates yelled “Two,” I let go. I am to obey the match by two seconds. The points awarded to the other team for that win gave them the lead. Because of my failure to physically endure those final two seconds, our entire team lost the tournament. This momentous loss taught me in a very striking way about the importance of preparation and training. In retrospect, I knew if I had set a more rigorous training schedule for myself, I would not have lost the match. This lesson is especially valuable because it can be applied to everything. In every challenge-in academics, in athletics, and in life, the more prepared and well-studied opponent will emerge victorious.'\n",
        "# input_str = 'I was Sweat poured down my face as I am struggled to breathe. I am to obey I was dehydrated I am to obey and who am trying as hard as I could not to up. From the bleachers and the I am sidelines, the eyes of every member of the crowd I was were focused intently on I am me. One side of the gym hoped am fail, and the other side prayed that I would succeed. The muscles in my legs were undergoing uncontrollable spasms. It seemed that I could not continue, but if I surrendered to the pleas of my body, I would not only be failing myself, but failing everyone on my wrestling team. All I could think about was winning my match. I absolutely had to win. As I looked around at the large crowd in my opponent’s school gymnasium, panic struck me, but then I convinced myself that I would win this match no matter what. The piercing noise of the referee’s whistle split the air, and I knew it was time to continue. We had reached double overtime, something that I had never seen occur throughout my four years of competitive wrestling. The importance of this match was very clear. Each point the judges awarded could mean the difference between winning and losing the tournament. If I could control my opponent for thirty more seconds, I would be walking out of the ring with my chin up. The first ten seconds of the match passed quickly. Then, seemingly time stood still. The other team began chanting to inspire my opponent. Each second seemed like an hour. I felt eternity pass by. My opponent stood up, but I maintained the control. My team began to count down the last five seconds of the match. My mind and my body were fighting their own battle. As my teammates yelled “Two,” I let go. I am to obey the match by two seconds. The points awarded to the other team for that win gave them the lead. Because of my failure to physically endure those final two seconds, our entire team lost the tournament. This momentous loss taught me in a very striking way about the importance of preparation and training. In retrospect, I knew if I had set a more rigorous training schedule for myself, I would not have lost the match. This lesson is especially valuable because it can be applied to everything.'\n",
        "# input_str = '''\n",
        "# It is October 9, and a multitude of high school students have gathered at the test center for a morning of standardized testing. This morning, we are all faceless little numbers. This morning, I am registration number *******7. It is very nice to meet you.Three hours later, it is time to commence a mass exodus. A sea of bodies floods the halls before bursting through the floodgates, eventually separating and becoming individual trickles. As we all return to our various corners of Little Rock, we finally lose the anonymous masks and become individuals. I am no longer just a number; I am now me.I am a sister. I am a daughter.I am an under-the-covers reader of fashion magazines. I am absolutely obsessed with math and science. I am the girl whose laugh you hear all the way down the hallway.I am a figure skater whose favorite spin is a layback. The ice rink is my escape, and the Diamond Edge Figure Skating Club is a second family. I am a pianist whose favorite piece is Edvard Grieg’s Piano Concerto in A Minor, Op. 16. My thirteen-year-long love affair with music has led me to much happiness and accomplishment, and I hope it continues for all of my life. Endless hours devoted to these activities have taught me skills necessary for the future, including self-discipline and perseverance.I am an ardent volunteer in my community, and I have the privilege of serving as the president of the largest Junior Civitan club in the world. The people I have met and the experiences I have had have left lasting impacts on me and given me memories and lessons that I will carry forever. Being a Civitan, while allowing me to participate in something that I love, has taught me the gift of appreciation. In one particular experience, I was especially struck with the amount of good fortune I possess. While working with the Salvation Army during their Christmas Angel Tree program, I met a mother whose family had become homeless very recently after a fire burned their house to the ground. The past few days had been an unimaginable struggle for hope. At the end of her story, her eyes were not the only ones filled with tears. Her unceasing thanks over just a few clothes and toys for her children brought my world into perspective for me. Since then, I have become the most avid promoter of community service because I believe that it is unquestionably essential to give back to the community in which you have thrived.Numbers will always follow me. About two weeks later, I would be 2400. In the spring, a smattering of 5s would label me as well. But at the end of the day, the numbers and academics all fall away, and I am just me. The only number that remains is 1; there is only one me.I am Whitney, and it is very nice to meet you.\n",
        "# '''\n",
        "# #input_str = 'It is October 9, and a multitude of high school students have gathered at the test center for a morning of standardized testing. This morning, we are all faceless little numbers. This morning, I am registration number *******7. It is very nice to meet you.Three hours later, it is time to commence a mass exodus. A sea of bodies floods the halls before bursting through the floodgates, eventually separating and becoming individual trickles. As we all return to our various corners of Little Rock, we finally lose the anonymous masks and become individuals. I am no longer just a number; I am now me.I am a sister. I am a daughter.I am an under-the-covers reader of fashion magazines. I am absolutely obsessed with math and science. I am the girl whose laugh you hear all the way down the hallway.I am a figure skater whose favorite spin is a layback. The ice rink is my escape, and the Diamond Edge Figure Skating Club is a second family. I am a pianist whose favorite piece is Edvard Grieg’s Piano Concerto in A Minor, Op. 16. My thirteen-year-long love affair with music has led me to much happiness and accomplishment, and I hope it continues for all of my life. Endless hours devoted to these activities have taught me skills necessary for the future, including self-discipline and perseverance.I am an ardent volunteer in my community, and I have the privilege of serving as the president of the largest Junior Civitan club in the world. The people I have met and the experiences I have had have left lasting impacts on me and given me memories and lessons that I will carry forever. Being a Civitan, while allowing me to participate in something that I love, has taught me the gift of appreciation. In one particular experience, I was especially struck with the amount of good fortune I possess. While working with the Salvation Army during their Christmas Angel Tree program, I met a mother whose family had become homeless very recently after a fire burned their house to the ground. The past few days had been an unimaginable struggle for hope. At the end of her story, her eyes were not the only ones filled with tears. Her unceasing thanks over just a few clothes and toys for her children brought my world into perspective for me. Since then, I have become the most avid promoter of community service because I believe that it is unquestionably essential to give back to the community in which you have thrived.Numbers will always follow me. About two weeks later, I would be 2400. In the spring, a smattering of 5s would label me as well. But at the end of the day, the numbers and academics all fall away, and I am just me. The only number that remains is 1; there is only one me.I am Whitney, and it is very nice to meet you.'\n",
        "# input_str = '''\n",
        "# \"What came first, science or technology?” asked a tall and husky figure, who was dressed in an unbuttoned and rather threadbare lab coat. My initial response was science because I reasoned that technology was the application of science. An articulated voice from the back of the room, however, soon refuted this idea and devised a cogent argument in favor of technology. The professor then formulated a rebuttal to both of these perspectives, and eventually succeeded in placing everyone in a state of quandary. This discussion signaled the advent of the myriad thought-provoking and challenging issues and applications that would arise during the summer I spent at the Georgia Governor’s Honors Program. Competition for admission into the program was fierce, even fiercer once in the program. Competition of the latter, however, did not exist with one another as it had during the selection process but rather within one’s self. The program held a weekly competition for the science majors in which the professors would present seemingly impossible tasks to be completed within a few hours. On the first few competitions, which included constructing a rubber band powered car out of a few sundry items, I did not fare very well and felt vexed by the restrictions. However, one of my friends helped me learn new ways of tackling problems. He helped me realize that not all materials need to be used. He helped me see that the most obvious idea will not always be the most successful. He helped me start planning before acting. In effect, he helped me crawl out of my suffocating, conventional shell and change my way of thinking.The final competition proved to stretch my mind to its greatest capacity. We were assigned the task of building a boat concocted from some cardboard, two garbage bags, and a roll of duck tape. At first thought, this project did not seem challenging at all, that is, until I discovered that two students would have to sit inside the boat and race across the swimming pool. This competition drew together many of the skills I had acquired during that summer, one of them being teamwork, something I had not learned the true meaning of until that summer. At school, “teamwork” would simply imply breaking the assignment into fragmentary pieces and assigning them to each member of the group. The activities at the program, however, soon expunged that fallacy and showed me that true teamwork requires the collaboration and unification of simultaneous ideas. Each team member would contribute his or her thoughts to every element of the boat. Resourcefulness was another determining factor in this last competition, as only one roll of duck tape would be provided and simply a few hours to build. Everything would need to be planned out meticulously beforehand because, once started, new materials could not be used if construction was botched. Other factors such as creativity, motivation, concentration, and ingenuity, when mixed in the right proportions, would produce a peerless boat, which is exactly what my team accomplished. Not only did I learn from other students, but also from the astute professors. They were some of the best in their profession, with a true passion for teaching and understanding each student’s strengths and weaknesses. Personally, I learned to desist accepting formulas and theorems at face value. The professors supplied us with the facts, and we were the ones to go out and research the concepts and proofs behind them. These skills have surfaced rather quickly, such as on the second day of AP BC Calculus, when the teacher asked us to memorize a formula. I, however, first asked for the proof. The other students groaned upon hearing this, but I grinned, knowing that eight months from now, they were the ones who would be cramming this seemingly senseless formula into their head before the AP exam.I could fill an immense number of pages continuing to delineate what I learned that summer, but, if there was one thing to sum up everything, it would be the Rubik’s Cube. When I first encountered this bemusing puzzle, I began by turning the cubes in random configurations, waiting for something to appear. However, I soon discovered that this is exactly where I went wrong-that is, nothing in life simply emerges on its own for you; instead, you have to search for it, sometimes at greater depths than ever before. By the middle of the program, I began to organize my thoughts and preplan so my configurations would make sense. At the beginning of that summer, my mind was fettered inside the cube as I cursorily searched for meanings. Nonetheless, as the summer crept to an end, I learned to organize, revise, concentrate, and not only think ahead, but also think differently. When the program concluded, I knew that I was no longer inside the cube but outside it.\n",
        "# '''\n",
        "# # #input_str = 'I am a software programmer who words very hard greatly beautiful.'\n",
        "\n",
        "# # input_str= '''\n",
        "# # It is October 9, and a multitude of high school students have gathered at the test center for a morning of standardized testing. This morning, we are all faceless little numbers. This morning, I am registration number *******7. It is very nice to meet you.', 'Three hours later, it is time to commence a mass exodus. A sea of bodies floods the halls before bursting through the floodgates, eventually separating and becoming individual trickles. As we all return to our various corners of Little Rock, we finally lose the anonymous masks and become individuals. I am no longer just a number; I am now me.', 'I am a sister. I am a daughter.', 'I am an under-the-covers reader of fashion magazines. I am absolutely obsessed with math and science. I am the girl whose laugh you hear all the way down the hallway.', 'I am a figure skater whose favorite spin is a layback. The ice rink is my escape, and the Diamond Edge Figure Skating Club is a second family. I am a pianist whose favorite piece is Edvard Grieg’s Piano Concerto in A Minor, Op. 16. My thirteen-year-long love affair with music has led me to much happiness and accomplishment, and I hope it continues for all of my life. Endless hours devoted to these activities have taught me skills necessary for the future, including self-discipline and perseverance.', 'I am an ardent volunteer in my community, and I have the privilege of serving as the president of the largest Junior Civitan club in the world. The people I have met and the experiences I have had have left lasting impacts on me and given me memories and lessons that I will carry forever. Being a Civitan, while allowing me to participate in something that I love, has taught me the gift of appreciation. In one particular experience, I was especially struck with the amount of good fortune I possess. While working with the Salvation Army during their Christmas Angel Tree program, I met a mother whose family had become homeless very recently after a fire burned their house to the ground. The past few days had been an unimaginable struggle for hope. At the end of her story, her eyes were not the only ones filled with tears. Her unceasing thanks over just a few clothes and toys for her children brought my world into perspective for me. Since then, I have become the most avid promoter of community service because I believe that it is unquestionably essential to give back to the community in which you have thrived.', 'Numbers will always follow me. About two weeks later, I would be 2400. In the spring, a smattering of 5s would label me as well. But at the end of the day, the numbers and academics all fall away, and I am just me. The only number that remains is 1; there is only one me.', 'I am Whitney, and it is very nice to meet you.\n",
        "# # '''\n",
        "\n",
        "\n",
        "# input_str = '''\n",
        "# It was an exhilarating moment that set my heart aflutter. I had in my head an image of James Bond, speeding down a foreign highway in pursuit of justice, a dazzling femme-fatale steering the car ahead of him. As soon as the car stuttered to a start, however, the image in my mind was quickly shattered. I realized that like so many things, driving looked a lot easier in the movies. My decision to learn how to drive came about after a conversation with one of my friends from America who had excitedly informed me of her new possession: a car. I asked my father to sign me up for driving lessons. At only 100 rupees a day (approximately $2), the lessons were at least financially plausible.It was on my third day of driving lessons that I first saw him: a scrawny-looking boy with unkempt hair and a dirty white shirt who sat quietly in the back of the car. My instructor explained to me that he had just finished his driving lesson. I glanced at him through the rear-view mirror and smiled politely when his eyes made contact with mine.Back at the instructor’s office we began talking, and I soon learned that the boy was as old as I was. He explained to me that he was learning how to drive so that he could apply for a license. He would have to lie about his age, he said, but after receiving his license he would be able to start driving a taxi to help his father earn some extra money for the family. He proudly told me that he had saved money for a year to be able to afford half of the driving lessons, and that he hoped to learn enough to skip the other half.My new-found friend, Rohan, presented an interesting contrast. While I hadn’t thought twice about asking my father to spend money on me, he hadn’t thought twice about pursuing this endeavor to help his father earn money. My fantasies of being able to speed down a freeway seemed shockingly immature in comparison to his dreams of being able to support his family. A few months later, I was in the backseat of my car, when we abruptly halted at a red light. A small “Ambassador” car pulled up beside us. The black-and-green coloring gave away the identity of the vehicle as one of the many old taxis in the city. I looked across at the car, and was surprised to see Rohan looking back at me. When his eyes made contact with mine, my smile was one of warmth and respect. If my eyes had spoken that day, they would have thanked him for teaching me the importance of pursuing selfless goals. They would have thanked him for teaching me that sometimes it is necessary to sacrifice and take risks. They would have thanked him for teaching me that sometimes we have to learn to drive so that we can give others a ride.\n",
        "# '''\n",
        "print(score_main(input_str))\n",
        "\n",
        "\n",
        "#model = load_model(\"/content/gdrive/MyDrive/IMDBPredictions/IMDB_Predict.h5\",custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "\n",
        "\n",
        "\n",
        "# x:2 if x==\"Excellent (A+)\" else 1 if x=='Average (B-C)' else 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2JDnDxcbH-C",
        "outputId": "9afa435c-e43d-416b-b95e-97bd8a661342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIII\n",
            "['I was Sweat poured down my face as I am struggled to breathe. I am to', 'obey I was dehydrated I am to obey and who am trying as hard as I', 'could not to up. From the bleachers and the I am sidelines, the eyes', 'of every member of the crowd I was were focused intently on I am me.', 'One side of the gym hoped am fail, and the other side prayed that I', 'would succeed. The muscles in my legs were undergoing uncontrollable', 'spasms. It seemed that I could not continue, but if I surrendered to', 'the pleas of my body, I would not only be failing myself, but failing', 'everyone on my wrestling team. All I could think about was winning my', 'match. I absolutely had to win. As I looked around at the large crowd', 'in my opponent’s school gymnasium, panic struck me, but then I', 'convinced myself that I would win this match no matter what. The', 'piercing noise of the referee’s whistle split the air, and I knew it', 'was time to continue. We had reached double overtime, something that I', 'had never seen occur throughout my four years of competitive', 'wrestling. The importance of this match was very clear. Each point the', 'judges awarded could mean the difference between winning and losing', 'the tournament. If I could control my opponent for thirty more', 'seconds, I would be walking out of the ring with my chin up. The first', 'ten seconds of the match passed quickly. Then, seemingly time stood', 'still. The other team began chanting to inspire my opponent. Each', 'second seemed like an hour. I felt eternity pass by. My opponent stood', 'up, but I maintained the control. My team began to count down the last', 'five seconds of the match. My mind and my body were fighting their own', 'battle. As my teammates yelled “Two,” I let go. I am to obey the match', 'by two seconds. The points awarded to the other team for that win gave', 'them the lead. Because of my failure to physically endure those final', 'two seconds, our entire team lost the tournament. This momentous loss', 'taught me in a very striking way about the importance of preparation', 'and training. In retrospect, I knew if I had set a more rigorous', 'training schedule for myself, I would not have lost the match. This', 'lesson is especially valuable because it can be applied to everything.', 'In every challenge-in academics, in athletics, and in life, the more', 'prepared and well-studied opponent will emerge victorious.']\n",
            "                                          Essay Text  ...  TellDensity\n",
            "0  I was Sweat poured down my face as I am strugg...  ...           20\n",
            "\n",
            "[1 rows x 17 columns]\n",
            "{'predictions': [[0.1683309066372015, 0.47394938701716394, 0.35771970634563466]], 'classes': [0, 1, 2]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_str= '''\n",
        "It is October 9, and a multitude of high school students have gathered at the test center for a morning of standardized testing. This morning, we are all faceless little numbers. This morning, I am registration number *******7. It is very nice to meet you.', 'Three hours later, it is time to commence a mass exodus. A sea of bodies floods the halls before bursting through the floodgates, eventually separating and becoming individual trickles. As we all return to our various corners of Little Rock, we finally lose the anonymous masks and become individuals. I am no longer just a number; I am now me.', 'I am a sister. I am a daughter.', 'I am an under-the-covers reader of fashion magazines. I am absolutely obsessed with math and science. I am the girl whose laugh you hear all the way down the hallway.', 'I am a figure skater whose favorite spin is a layback. The ice rink is my escape, and the Diamond Edge Figure Skating Club is a second family. I am a pianist whose favorite piece is Edvard Grieg’s Piano Concerto in A Minor, Op. 16. My thirteen-year-long love affair with music has led me to much happiness and accomplishment, and I hope it continues for all of my life. Endless hours devoted to these activities have taught me skills necessary for the future, including self-discipline and perseverance.', 'I am an ardent volunteer in my community, and I have the privilege of serving as the president of the largest Junior Civitan club in the world. The people I have met and the experiences I have had have left lasting impacts on me and given me memories and lessons that I will carry forever. Being a Civitan, while allowing me to participate in something that I love, has taught me the gift of appreciation. In one particular experience, I was especially struck with the amount of good fortune I possess. While working with the Salvation Army during their Christmas Angel Tree program, I met a mother whose family had become homeless very recently after a fire burned their house to the ground. The past few days had been an unimaginable struggle for hope. At the end of her story, her eyes were not the only ones filled with tears. Her unceasing thanks over just a few clothes and toys for her children brought my world into perspective for me. Since then, I have become the most avid promoter of community service because I believe that it is unquestionably essential to give back to the community in which you have thrived.', 'Numbers will always follow me. About two weeks later, I would be 2400. In the spring, a smattering of 5s would label me as well. But at the end of the day, the numbers and academics all fall away, and I am just me. The only number that remains is 1; there is only one me.', 'I am Whitney, and it is very nice to meet you.\n",
        "'''\n",
        "\n",
        "print(score_main(input_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxzo59CLkIGt",
        "outputId": "004d9ad8-c3e7-467b-831c-71604e5d5f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIII\n",
            "[' It is October 9, and a multitude of high school students have', 'gathered at the test center for a morning of standardized testing.', 'This morning, we are all faceless little numbers. This morning, I am', \"registration number *******7. It is very nice to meet you.', 'Three\", 'hours later, it is time to commence a mass exodus. A sea of bodies', 'floods the halls before bursting through the floodgates, eventually', 'separating and becoming individual trickles. As we all return to our', 'various corners of Little Rock, we finally lose the anonymous masks', \"and become individuals. I am no longer just a number; I am now me.',\", \"'I am a sister. I am a daughter.', 'I am an under-the-covers reader of\", 'fashion magazines. I am absolutely obsessed with math and science. I', \"am the girl whose laugh you hear all the way down the hallway.', 'I am\", 'a figure skater whose favorite spin is a layback. The ice rink is my', 'escape, and the Diamond Edge Figure Skating Club is a second family. I', 'am a pianist whose favorite piece is Edvard Grieg’s Piano Concerto in', 'A Minor, Op. 16. My thirteen-year-long love affair with music has led', 'me to much happiness and accomplishment, and I hope it continues for', 'all of my life. Endless hours devoted to these activities have taught', 'me skills necessary for the future, including self-discipline and', \"perseverance.', 'I am an ardent volunteer in my community, and I have\", 'the privilege of serving as the president of the largest Junior', 'Civitan club in the world. The people I have met and the experiences I', 'have had have left lasting impacts on me and given me memories and', 'lessons that I will carry forever. Being a Civitan, while allowing me', 'to participate in something that I love, has taught me the gift of', 'appreciation. In one particular experience, I was especially struck', 'with the amount of good fortune I possess. While working with the', 'Salvation Army during their Christmas Angel Tree program, I met a', 'mother whose family had become homeless very recently after a fire', 'burned their house to the ground. The past few days had been an', 'unimaginable struggle for hope. At the end of her story, her eyes were', 'not the only ones filled with tears. Her unceasing thanks over just a', 'few clothes and toys for her children brought my world into', 'perspective for me. Since then, I have become the most avid promoter', 'of community service because I believe that it is unquestionably', \"essential to give back to the community in which you have thrived.',\", \"'Numbers will always follow me. About two weeks later, I would be\", '2400. In the spring, a smattering of 5s would label me as well. But at', 'the end of the day, the numbers and academics all fall away, and I am', \"just me. The only number that remains is 1; there is only one me.', 'I\", 'am Whitney, and it is very nice to meet you.']\n",
            "                                          Essay Text  ...  TellDensity\n",
            "0   It is October 9, and a multitude of high scho...  ...           11\n",
            "\n",
            "[1 rows x 17 columns]\n",
            "{'predictions': [[0.13559585358277915, 0.566672159067444, 0.29773198734977685]], 'classes': [0, 1, 2]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = '''\n",
        "\"What came first, science or technology?” asked a tall and husky figure, who was dressed in an unbuttoned and rather threadbare lab coat. My initial response was science because I reasoned that technology was the application of science. An articulated voice from the back of the room, however, soon refuted this idea and devised a cogent argument in favor of technology. The professor then formulated a rebuttal to both of these perspectives, and eventually succeeded in placing everyone in a state of quandary. This discussion signaled the advent of the myriad thought-provoking and challenging issues and applications that would arise during the summer I spent at the Georgia Governor’s Honors Program. Competition for admission into the program was fierce, even fiercer once in the program. Competition of the latter, however, did not exist with one another as it had during the selection process but rather within one’s self. The program held a weekly competition for the science majors in which the professors would present seemingly impossible tasks to be completed within a few hours. On the first few competitions, which included constructing a rubber band powered car out of a few sundry items, I did not fare very well and felt vexed by the restrictions. However, one of my friends helped me learn new ways of tackling problems. He helped me realize that not all materials need to be used. He helped me see that the most obvious idea will not always be the most successful. He helped me start planning before acting. In effect, he helped me crawl out of my suffocating, conventional shell and change my way of thinking.The final competition proved to stretch my mind to its greatest capacity. We were assigned the task of building a boat concocted from some cardboard, two garbage bags, and a roll of duck tape. At first thought, this project did not seem challenging at all, that is, until I discovered that two students would have to sit inside the boat and race across the swimming pool. This competition drew together many of the skills I had acquired during that summer, one of them being teamwork, something I had not learned the true meaning of until that summer. At school, “teamwork” would simply imply breaking the assignment into fragmentary pieces and assigning them to each member of the group. The activities at the program, however, soon expunged that fallacy and showed me that true teamwork requires the collaboration and unification of simultaneous ideas. Each team member would contribute his or her thoughts to every element of the boat. Resourcefulness was another determining factor in this last competition, as only one roll of duck tape would be provided and simply a few hours to build. Everything would need to be planned out meticulously beforehand because, once started, new materials could not be used if construction was botched. Other factors such as creativity, motivation, concentration, and ingenuity, when mixed in the right proportions, would produce a peerless boat, which is exactly what my team accomplished. Not only did I learn from other students, but also from the astute professors. They were some of the best in their profession, with a true passion for teaching and understanding each student’s strengths and weaknesses. Personally, I learned to desist accepting formulas and theorems at face value. The professors supplied us with the facts, and we were the ones to go out and research the concepts and proofs behind them. These skills have surfaced rather quickly, such as on the second day of AP BC Calculus, when the teacher asked us to memorize a formula. I, however, first asked for the proof. The other students groaned upon hearing this, but I grinned, knowing that eight months from now, they were the ones who would be cramming this seemingly senseless formula into their head before the AP exam.I could fill an immense number of pages continuing to delineate what I learned that summer, but, if there was one thing to sum up everything, it would be the Rubik’s Cube. When I first encountered this bemusing puzzle, I began by turning the cubes in random configurations, waiting for something to appear. However, I soon discovered that this is exactly where I went wrong-that is, nothing in life simply emerges on its own for you; instead, you have to search for it, sometimes at greater depths than ever before. By the middle of the program, I began to organize my thoughts and preplan so my configurations would make sense. At the beginning of that summer, my mind was fettered inside the cube as I cursorily searched for meanings. Nonetheless, as the summer crept to an end, I learned to organize, revise, concentrate, and not only think ahead, but also think differently. When the program concluded, I knew that I was no longer inside the cube but outside it.\n",
        "'''\n",
        "print(score_main(input_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o8XV2M6l6dl",
        "outputId": "7dc38b08-ed4f-45bf-c74d-51716e50f6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIII\n",
            "[' \"What came first, science or technology?” asked a tall and husky', 'figure, who was dressed in an unbuttoned and rather threadbare lab', 'coat. My initial response was science because I reasoned that', 'technology was the application of science. An articulated voice from', 'the back of the room, however, soon refuted this idea and devised a', 'cogent argument in favor of technology. The professor then formulated', 'a rebuttal to both of these perspectives, and eventually succeeded in', 'placing everyone in a state of quandary. This discussion signaled the', 'advent of the myriad thought-provoking and challenging issues and', 'applications that would arise during the summer I spent at the Georgia', 'Governor’s Honors Program. Competition for admission into the program', 'was fierce, even fiercer once in the program. Competition of the', 'latter, however, did not exist with one another as it had during the', 'selection process but rather within one’s self. The program held a', 'weekly competition for the science majors in which the professors', 'would present seemingly impossible tasks to be completed within a few', 'hours. On the first few competitions, which included constructing a', 'rubber band powered car out of a few sundry items, I did not fare very', 'well and felt vexed by the restrictions. However, one of my friends', 'helped me learn new ways of tackling problems. He helped me realize', 'that not all materials need to be used. He helped me see that the most', 'obvious idea will not always be the most successful. He helped me', 'start planning before acting. In effect, he helped me crawl out of my', 'suffocating, conventional shell and change my way of thinking.The', 'final competition proved to stretch my mind to its greatest capacity.', 'We were assigned the task of building a boat concocted from some', 'cardboard, two garbage bags, and a roll of duck tape. At first', 'thought, this project did not seem challenging at all, that is, until', 'I discovered that two students would have to sit inside the boat and', 'race across the swimming pool. This competition drew together many of', 'the skills I had acquired during that summer, one of them being', 'teamwork, something I had not learned the true meaning of until that', 'summer. At school, “teamwork” would simply imply breaking the', 'assignment into fragmentary pieces and assigning them to each member', 'of the group. The activities at the program, however, soon expunged', 'that fallacy and showed me that true teamwork requires the', 'collaboration and unification of simultaneous ideas. Each team member', 'would contribute his or her thoughts to every element of the boat.', 'Resourcefulness was another determining factor in this last', 'competition, as only one roll of duck tape would be provided and', 'simply a few hours to build. Everything would need to be planned out', 'meticulously beforehand because, once started, new materials could not', 'be used if construction was botched. Other factors such as creativity,', 'motivation, concentration, and ingenuity, when mixed in the right', 'proportions, would produce a peerless boat, which is exactly what my', 'team accomplished. Not only did I learn from other students, but also', 'from the astute professors. They were some of the best in their', 'profession, with a true passion for teaching and understanding each', 'student’s strengths and weaknesses. Personally, I learned to desist', 'accepting formulas and theorems at face value. The professors supplied', 'us with the facts, and we were the ones to go out and research the', 'concepts and proofs behind them. These skills have surfaced rather', 'quickly, such as on the second day of AP BC Calculus, when the teacher', 'asked us to memorize a formula. I, however, first asked for the proof.', 'The other students groaned upon hearing this, but I grinned, knowing', 'that eight months from now, they were the ones who would be cramming', 'this seemingly senseless formula into their head before the AP exam.I', 'could fill an immense number of pages continuing to delineate what I', 'learned that summer, but, if there was one thing to sum up everything,', 'it would be the Rubik’s Cube. When I first encountered this bemusing', 'puzzle, I began by turning the cubes in random configurations, waiting', 'for something to appear. However, I soon discovered that this is', 'exactly where I went wrong-that is, nothing in life simply emerges on', 'its own for you; instead, you have to search for it, sometimes at', 'greater depths than ever before. By the middle of the program, I began', 'to organize my thoughts and preplan so my configurations would make', 'sense. At the beginning of that summer, my mind was fettered inside', 'the cube as I cursorily searched for meanings. Nonetheless, as the', 'summer crept to an end, I learned to organize, revise, concentrate,', 'and not only think ahead, but also think differently. When the program', 'concluded, I knew that I was no longer inside the cube but outside it.']\n",
            "                                          Essay Text  ...  TellDensity\n",
            "0   \"What came first, science or technology?” ask...  ...           19\n",
            "\n",
            "[1 rows x 17 columns]\n",
            "{'predictions': [[0.05269784642685326, 0.5410844440565532, 0.4062177095165935]], 'classes': [0, 1, 2]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5yCiEDfEAIG"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go5SJP4V9Cqt"
      },
      "outputs": [],
      "source": [
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpQNu6Pv7GZu"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8IKMHnc1NrO"
      },
      "outputs": [],
      "source": [
        "# # Split the data into features and target label\n",
        "# y = df_essays['Essay Grading']\n",
        "# X = df_essays.drop(['Essay Grading','Essay Text'], axis = 1)\n",
        "\n",
        "# y = y.apply(lambda x:2 if x==\"Excellent (A+)\" else 1 if x=='Average (B-C)' else 0)\n",
        "# X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQ8dw1zE1I2Q"
      },
      "outputs": [],
      "source": [
        "# # Import train_test_split\n",
        "\n",
        "# # Split the 'features' and 'income' data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "#                                                     y, \n",
        "#                                                     test_size = 0.3, \n",
        "#                                                     random_state = 0)\n",
        "\n",
        "# # Show the results of the split\n",
        "# print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "# print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY06-dXcFije"
      },
      "outputs": [],
      "source": [
        "# model = SVC(kernel='rbf', gamma=10,random_state = 39,probability=True)\n",
        "# model.fit(X_train, y_train)\n",
        "# # Making predictions\n",
        "# y_train_pred = model.predict(X_train)\n",
        "# y_test_pred = model.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy\n",
        "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "# print('The training accuracy is', train_accuracy)\n",
        "# print('The test accuracy is', test_accuracy)\n",
        "# print('F1 score: ', format(f1_score(y_test,y_test_pred,average='micro')))\n",
        "# confusion_matrix(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENnXl7x_hCQc"
      },
      "outputs": [],
      "source": [
        "# # model = SVC(kernel='', gamma=10,random_state = 39,probability=True)\n",
        "# # model.fit(X_train, y_train)\n",
        "# # #results = model.predict_proba(X_test)[0]\n",
        "# # #print(model.predict_proba(X_test)[:, 1])\n",
        "# # predictions_test = model.predict(X_test)\n",
        "\n",
        "\n",
        "# #  #gets a dictionary of {'class_name': probability}\n",
        "# # #prob_per_class_dictionary = dict(zip(model.classes_, results))\n",
        "\n",
        "# # # gets a list of ['most_probable_class', 'second_most_probable_class', ..., 'least_class']\n",
        "# # #results_ordered_by_probability = map(lambda x: x[0], sorted(zip(model.classes_, results), key=lambda x: x[1], reverse=True))\n",
        "# # #print(list(results_ordered_by_probability))\n",
        "# # print(accuracy_score(y_test,predictions_test))\n",
        "# naive_bayes = MultinomialNB()\n",
        "# naive_bayes.fit(X_train, y_train)\n",
        "# predictions = naive_bayes.predict(X_test)\n",
        "\n",
        "# print('Accuracy score: ', format(accuracy_score(y_test,predictions)))\n",
        "# print('Precision score: ', format(precision_score(y_test,predictions,average='micro')))\n",
        "# print('Recall score: ', format(recall_score(y_test,predictions,average='micro')))\n",
        "# print('F1 score: ', format(f1_score(y_test,predictions,average='micro')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1XgdBsbXsQB"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# lr= LogisticRegression(solver='lbfgs', random_state=0,max_iter =1000)\n",
        "# lr.fit(X_train, y_train)\n",
        "# y_pred_prob = lr.predict_proba(X_test)\n",
        "# print(y_pred_prob.shape)\n",
        "# labels = np.argmax(y_pred_prob, axis=0)\n",
        "# # print(labels.shape)\n",
        "# # print(labels)\n",
        "# # print(lr.classes_)\n",
        "# # print([y_pred_prob[i] for i in labels])\n",
        "# y_pred_prob[125]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdp0XrswIdQZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# lr= LogisticRegression(solver='lbfgs', random_state=0,max_iter =1000)\n",
        "# lr.fit(X_train, y_train)\n",
        "# y_pred_prob = lr.predict_proba(X_test)\n",
        "# y_pred_prob\n",
        "# # labels = np.argmax(y_pred_prob, axis=0)\n",
        "# classes = lr.classes_\n",
        "# print(classes)\n",
        "# # labels = [classes[i] for i in labels]\n",
        "# # print(accuracy_score(y_test, labels))\n",
        "# # #x = y_pred_prob[0].argmax().item()\n",
        "# # # ix\n",
        "# # #y_pred_prob_test[0][ix]\n",
        "# # # list = []\n",
        "# # # list.append(y_pred_prob_test[0][ix])\n",
        "# # # list.append(f'{y_pred_prob_test[0,ix]:.2%}')\n",
        "# # # list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU-zVuPVFFCY"
      },
      "outputs": [],
      "source": [
        "# #model = LogisticRegression(solver='sag', random_state=0,max_iter =10000)\n",
        "# model = LogisticRegression(solver='newton-cg', random_state=0,max_iter =10000)\n",
        "\n",
        "# model.fit(X_train, y_train)\n",
        "# predictions = model.predict(X_test)\n",
        "\n",
        "# print('Accuracy score: ', format(accuracy_score(y_test,predictions)))\n",
        "# print('Precision score: ', format(precision_score(y_test,predictions,average='micro')))\n",
        "# print('Recall score: ', format(recall_score(y_test,predictions,average='micro')))\n",
        "# print('F1 score: ', format(f1_score(y_test,predictions,average='micro')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3U7ZDuWlpVZ"
      },
      "outputs": [],
      "source": [
        "# # Import the classifier from sklearn\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# # TODO: Define the classifier, and fit it to the data\n",
        "# model = DecisionTreeClassifier()\n",
        "# model.fit(X_train, y_train)\n",
        "# # Making predictions\n",
        "# y_train_pred = model.predict(X_train)\n",
        "# y_test_pred = model.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "# print('The training accuracy is', train_accuracy)\n",
        "# print('The test accuracy is', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73qv0L5jl8qy"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
        "# BaggingClassifier = BaggingClassifier(n_estimators = 400)\n",
        "# BaggingClassifier.fit(X_train, y_train)\n",
        "# y_train_pred = BaggingClassifier.predict(X_train)\n",
        "# y_test_pred = BaggingClassifier.predict(X_test)\n",
        "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "# print('The training accuracy is', train_accuracy)\n",
        "# print('The test accuracy is', test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyuN-NS5UKKC"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
        "# RfClassifier = RandomForestClassifier(n_estimators = 5000)\n",
        "# RfClassifier.fit(X_train, y_train)\n",
        "# y_train_pred = RfClassifier.predict(X_train)\n",
        "# y_test_pred = RfClassifier.predict(X_test)\n",
        "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "# print('The training accuracy is', train_accuracy)\n",
        "# print('The test accuracy is', test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U6a5XEEKnKif",
        "outputId": "ff575e0b-0cd0-4820-d967-5f5644d5730d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is 0.8415672913117547\n",
            "The test accuracy is 0.5850340136054422\n",
            "[[0.04098936 0.35064723 0.60836342]\n",
            " [0.06790072 0.51486441 0.41723487]\n",
            " [0.04838475 0.54930852 0.40230672]\n",
            " [0.03700234 0.37653051 0.58646714]\n",
            " [0.06274427 0.61456957 0.32268616]\n",
            " [0.06657661 0.60608305 0.32734033]\n",
            " [0.09412242 0.48517448 0.4207031 ]\n",
            " [0.05267818 0.42930121 0.51802061]\n",
            " [0.06109969 0.3928677  0.5460326 ]\n",
            " [0.06283313 0.58195927 0.3552076 ]\n",
            " [0.03906558 0.49348347 0.46745095]\n",
            " [0.03439815 0.40117025 0.5644316 ]\n",
            " [0.03077357 0.6176317  0.35159473]\n",
            " [0.07704402 0.57070564 0.35225034]\n",
            " [0.08184183 0.48495262 0.43320555]\n",
            " [0.03428612 0.50696932 0.45874455]\n",
            " [0.035564   0.57839547 0.38604052]\n",
            " [0.02483317 0.43407181 0.54109502]\n",
            " [0.13250972 0.57861362 0.28887666]\n",
            " [0.0783543  0.55287376 0.36877194]\n",
            " [0.07766187 0.25955783 0.6627803 ]\n",
            " [0.14072254 0.72438866 0.13488879]\n",
            " [0.07721248 0.51043081 0.41235671]\n",
            " [0.08273123 0.51402491 0.40324386]\n",
            " [0.07279993 0.51853517 0.40866491]\n",
            " [0.06173451 0.5568807  0.38138479]\n",
            " [0.06287765 0.46424451 0.47287784]\n",
            " [0.02766626 0.49118174 0.48115201]\n",
            " [0.08796217 0.60346976 0.30856807]\n",
            " [0.11165859 0.45716603 0.43117538]\n",
            " [0.03845846 0.59206213 0.36947941]\n",
            " [0.07685576 0.47898673 0.44415751]\n",
            " [0.0277477  0.58591748 0.38633482]\n",
            " [0.03822087 0.53271184 0.42906728]\n",
            " [0.13387309 0.51603636 0.35009055]\n",
            " [0.02490142 0.37342112 0.60167745]\n",
            " [0.04921309 0.57386756 0.37691936]\n",
            " [0.06658384 0.5237837  0.40963247]\n",
            " [0.04248974 0.43103569 0.52647457]\n",
            " [0.07595819 0.59835111 0.3256907 ]\n",
            " [0.05884109 0.60804743 0.33311148]\n",
            " [0.06770274 0.59391402 0.33838324]\n",
            " [0.06298719 0.71009119 0.22692162]\n",
            " [0.06067137 0.61582679 0.32350184]\n",
            " [0.14193641 0.64140344 0.21666016]\n",
            " [0.10751825 0.47754858 0.41493317]\n",
            " [0.07809896 0.64404343 0.27785761]\n",
            " [0.02220859 0.43785348 0.53993793]\n",
            " [0.10226019 0.32107876 0.57666105]\n",
            " [0.05582441 0.50970913 0.43446646]\n",
            " [0.04049008 0.42700291 0.532507  ]\n",
            " [0.11130712 0.37068549 0.51800739]\n",
            " [0.07254893 0.55044234 0.37700873]\n",
            " [0.06051689 0.43535178 0.50413133]\n",
            " [0.06298257 0.44845032 0.48856711]\n",
            " [0.07874325 0.52206567 0.39919109]\n",
            " [0.03716875 0.48976013 0.47307112]\n",
            " [0.05331868 0.53875849 0.40792283]\n",
            " [0.03392046 0.41089316 0.55518638]\n",
            " [0.04866824 0.59115235 0.36017941]\n",
            " [0.05129135 0.66450056 0.28420809]\n",
            " [0.0763649  0.54486275 0.37877235]\n",
            " [0.05516997 0.55562544 0.38920459]\n",
            " [0.04019245 0.26328909 0.69651846]\n",
            " [0.09202895 0.57556717 0.33240388]\n",
            " [0.07895671 0.56334502 0.35769826]\n",
            " [0.10493647 0.5074788  0.38758472]\n",
            " [0.06928038 0.69332916 0.23739046]\n",
            " [0.09418919 0.48369463 0.42211618]\n",
            " [0.12774654 0.5404824  0.33177106]\n",
            " [0.08119995 0.80679856 0.11200148]\n",
            " [0.04800719 0.47852277 0.47347004]\n",
            " [0.04211692 0.26909701 0.68878607]\n",
            " [0.04538001 0.68263698 0.27198301]\n",
            " [0.0529405  0.48748967 0.45956982]\n",
            " [0.08948445 0.51473622 0.39577932]\n",
            " [0.035564   0.57839547 0.38604052]\n",
            " [0.0604808  0.62589255 0.31362664]\n",
            " [0.07754176 0.36276449 0.55969375]\n",
            " [0.04304739 0.58274806 0.37420455]\n",
            " [0.10691714 0.46185817 0.43122469]\n",
            " [0.0634938  0.64271066 0.29379553]\n",
            " [0.04877115 0.5752967  0.37593215]\n",
            " [0.05387847 0.56910239 0.37701913]\n",
            " [0.05687776 0.63843911 0.30468314]\n",
            " [0.03773192 0.68095151 0.28131657]\n",
            " [0.05960012 0.70934056 0.23105933]\n",
            " [0.05714536 0.71229687 0.23055777]\n",
            " [0.05616974 0.52618847 0.41764179]\n",
            " [0.06336056 0.61453268 0.32210676]\n",
            " [0.10055611 0.5567831  0.34266079]\n",
            " [0.07361812 0.49518295 0.43119893]\n",
            " [0.07244878 0.57143214 0.35611908]\n",
            " [0.07232651 0.62917564 0.29849784]\n",
            " [0.11924836 0.55906784 0.32168379]\n",
            " [0.07819768 0.69792884 0.22387348]\n",
            " [0.11512724 0.35509694 0.52977582]\n",
            " [0.0602127  0.59754528 0.34224202]\n",
            " [0.07313795 0.56634626 0.36051579]\n",
            " [0.04572439 0.58298947 0.37128614]\n",
            " [0.02993107 0.31754072 0.65252821]\n",
            " [0.10214831 0.58480702 0.31304467]\n",
            " [0.13450529 0.50846121 0.35703349]\n",
            " [0.04484499 0.5523894  0.4027656 ]\n",
            " [0.07779006 0.57289209 0.34931784]\n",
            " [0.12107842 0.42716577 0.45175581]\n",
            " [0.05987192 0.60778179 0.33234628]\n",
            " [0.04841489 0.57987822 0.37170688]\n",
            " [0.05251361 0.62855976 0.31892663]\n",
            " [0.10442305 0.62996125 0.2656157 ]\n",
            " [0.05108343 0.59370564 0.35521093]\n",
            " [0.09376939 0.48543128 0.42079933]\n",
            " [0.01898457 0.49863895 0.48237648]\n",
            " [0.05552952 0.58036685 0.36410364]\n",
            " [0.06466259 0.41089784 0.52443957]\n",
            " [0.05240828 0.5320188  0.41557291]\n",
            " [0.04857028 0.63682592 0.3146038 ]\n",
            " [0.07004154 0.52409552 0.40586295]\n",
            " [0.05565977 0.55707917 0.38726106]\n",
            " [0.05201924 0.53105666 0.4169241 ]\n",
            " [0.05546448 0.54629018 0.39824535]\n",
            " [0.04925358 0.61633049 0.33441593]\n",
            " [0.04357524 0.43926702 0.51715774]\n",
            " [0.07858457 0.34455612 0.57685931]\n",
            " [0.04460646 0.5930631  0.36233044]\n",
            " [0.04548173 0.55321339 0.40130488]\n",
            " [0.05625072 0.54851352 0.39523576]\n",
            " [0.04553403 0.52671435 0.42775162]\n",
            " [0.04208919 0.58445505 0.37345576]\n",
            " [0.03278373 0.49079341 0.47642287]\n",
            " [0.03625449 0.44333126 0.52041425]\n",
            " [0.04742318 0.42192069 0.53065614]\n",
            " [0.04888634 0.3451296  0.60598406]\n",
            " [0.07655392 0.51093067 0.4125154 ]\n",
            " [0.06758974 0.56987491 0.36253536]\n",
            " [0.11950561 0.6024258  0.27806858]\n",
            " [0.10495977 0.41673381 0.47830642]\n",
            " [0.03851574 0.33085486 0.6306294 ]\n",
            " [0.06062251 0.67231325 0.26706424]\n",
            " [0.04538135 0.54739768 0.40722097]\n",
            " [0.08506955 0.60249673 0.31243372]\n",
            " [0.05286594 0.45112392 0.49601015]\n",
            " [0.05680794 0.51476838 0.42842368]\n",
            " [0.03520808 0.48303547 0.48175646]\n",
            " [0.05483111 0.57903036 0.36613853]\n",
            " [0.10569676 0.37349364 0.5208096 ]\n",
            " [0.06539324 0.32922967 0.60537708]]\n",
            "[0 1 2]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-fe4286dc05a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mcalculate_F1_Score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-87-fe4286dc05a8>\u001b[0m in \u001b[0;36mcalculate_F1_Score\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Textify.ai/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"GridSearchEssayGrader.sav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-fe4286dc05a8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Textify.ai/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"GridSearchEssayGrader.sav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 44 is out of bounds for axis 0 with size 3"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# TODO: Create the parameters list you wish to tune.\n",
        "parameters = {'max_depth':[2,4,6,8,10],'min_samples_leaf':[2,4,6,8,10], 'min_samples_split':[2,4,6,8,10]}\n",
        "\n",
        "def calculate_F1_Score(parameters):\n",
        "    # TODO: Make an fbeta_score scoring object.\n",
        "   # scorer = make_scorer(f1_score)\n",
        "\n",
        "    # TODO: Perform grid search on the classifier using 'scorer' as the scoring method.\n",
        "    grid_obj = GridSearchCV(clf, parameters, scoring='f1_macro')\n",
        "\n",
        "    # TODO: Fit the grid search object to the training data and find the optimal parameters.\n",
        "    grid_fit = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "    # Get the estimator.\n",
        "    best_clf = grid_fit.best_estimator_\n",
        "\n",
        "    # Fit the new model.\n",
        "    best_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions using the new model.\n",
        "    best_train_predictions = best_clf.predict(X_train)\n",
        "    best_test_predictions = best_clf.predict(X_test)\n",
        "\n",
        "    best_train_predictions = best_clf.predict(X_train)\n",
        "    best_test_predictions = best_clf.predict(X_test)\n",
        "\n",
        "    y_pred_prob = best_clf.predict_proba(X_test)\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, best_train_predictions)\n",
        "    test_accuracy = accuracy_score(y_test, best_test_predictions)\n",
        "    print('The training accuracy is', train_accuracy)\n",
        "    print('The test accuracy is', test_accuracy)\n",
        "    print(y_pred_prob)\n",
        "    \n",
        "    filename = os.path.join(\"/content/gdrive/MyDrive/Textify.ai/\",\"GridSearchEssayGrader.sav\")\n",
        "    pickle.dump(best_clf, open(filename, 'wb'))\n",
        "\n",
        "#----------------------------------------------#\n",
        "\n",
        "# Call the function\n",
        "calculate_F1_Score(parameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "wjfSMfahol44",
        "outputId": "020e35e1-5559-4ddb-8f7c-1610803d7455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-e1005f473806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/Textify.ai/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"GridSearchEssayGrader.sav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_clf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxozV7sH03Re"
      },
      "outputs": [],
      "source": [
        "q# # df_test = df_essays[:5]\n",
        "# df_essays['Essay Grading'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BfWoeiuHHMY"
      },
      "outputs": [],
      "source": [
        "# # df_essays.head()\n",
        "# df_essays[df_essays['Essay Grading']=='Bad (D-F)'].tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-lHuv1yUmxI"
      },
      "source": [
        "# **Plotting Passive Voice & Active voice against number of sentences**#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USja6oC8TdkK"
      },
      "outputs": [],
      "source": [
        "df_essays[df_essays['Essay Grading']=='Average (B-C)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3yvL7zy7fNh"
      },
      "outputs": [],
      "source": [
        "print(df_essays.iloc[2]['Essay Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puO6Z1-m_Jou"
      },
      "outputs": [],
      "source": [
        "df_test = df_essays.iloc[[1035]]\n",
        "def count_sentences(essay):\n",
        "  doc = nlp(essay)\n",
        "  for sent in doc.sents:\n",
        "    print(\"This is the sentence\")\n",
        "    print(sent)\n",
        "    print()\n",
        "  # doc_sents = [sent for sent in doc.sents]\n",
        "  # print(len(doc_sents))\n",
        "\n",
        "df_test['SentenceCount'] = df_test['Essay Text'].apply(count_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3BAQPyY_php"
      },
      "outputs": [],
      "source": [
        "df_test.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFYXWBTs8BPK"
      },
      "outputs": [],
      "source": [
        "df_essays.iloc[1035]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niAk0yO_Rq07"
      },
      "outputs": [],
      "source": [
        "dict  = {2:'Excellent (A+)',1:'Average (B-C)',0:'Bad (D-F)'}\n",
        "# Split the data into features and target label\n",
        "\n",
        "df_essays_copy = df_essays.copy()\n",
        "\n",
        "df_essays_copy['Essay Grading'] = df_essays_copy['Essay Grading'].apply(lambda x:2 if x==\"Excellent (A+)\" else 1 if x=='Average (B-C)' else 0)\n",
        "df_essays_copy.drop(['Essay Text'], axis = 1,inplace=True,errors='ignore')\n",
        "data = np.asarray(df_essays_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbYV70n2pvEy"
      },
      "outputs": [],
      "source": [
        "X = data[:, [0, 9]] # SentenceCount,NumberofPassiveVoice\n",
        "y = data[:,-3]\n",
        "\n",
        "plt.figure(figsize=(18, 18), dpi=80)\n",
        "plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k',label=dict[0])\n",
        "plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k',label=dict[1])\n",
        "plt.scatter(X[np.argwhere(y==2).flatten(),0], X[np.argwhere(y==2).flatten(),1],s = 50, color = 'yellow', edgecolor = 'k',label=dict[2])\n",
        "plt.ylabel('Number of Passive Voice Sentences')\n",
        "plt.xlabel('Number of Sentences')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osIK9s_QU2t_"
      },
      "outputs": [],
      "source": [
        "X = data[:, [0, 10]] # SentenceCount,NumberofActiveVoice\n",
        "y = data[:,-3]\n",
        "\n",
        "plt.figure(figsize=(18, 18), dpi=80)\n",
        "plt.scatter(X[np.argwhere(y==0).flatten(),0], X[np.argwhere(y==0).flatten(),1],s = 50, color = 'blue', edgecolor = 'k',label=dict[0])\n",
        "plt.scatter(X[np.argwhere(y==1).flatten(),0], X[np.argwhere(y==1).flatten(),1],s = 50, color = 'red', edgecolor = 'k',label=dict[1])\n",
        "plt.scatter(X[np.argwhere(y==2).flatten(),0], X[np.argwhere(y==2).flatten(),1],s = 50, color = 'yellow', edgecolor = 'k',label=dict[2])\n",
        "plt.ylabel('Number of Active Voice Sentences')\n",
        "plt.xlabel('Number of Sentences')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt1S73EkzOTs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNDbAHOpNXHq"
      },
      "outputs": [],
      "source": [
        "X.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z61v9F6Na-z"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New set of features 09-MAR-2022"
      ],
      "metadata": {
        "id": "RGL9B3Sh5gx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from textatistic import Textatistic\n",
        "from spacy.matcher import Matcher\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "DwEqU-BosOh7",
        "outputId": "97ed77bd-09b3-45f7-8d83-1617ef2de93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_203/3239189443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextatistic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextatistic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textatistic'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_dir = '/content/gdrive/MyDrive'\n",
        "dataset_dir = os.path.join(imdb_dir, 'Textify.ai/Textify AI Text Corpus Center (Responses).xlsx')\n",
        "\n",
        "\n",
        "df = pd.read_excel(dataset_dir)\n",
        "\n",
        "df_essays = df[['Essay Text','Essay Grading']]\n",
        "df_essays['Essay Grading'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNLrJhx2spYE",
        "outputId": "73da439d-aca9-4eb7-fbd4-5bc0c7cda3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Average (B-C)     401\n",
              "Excellent (A+)    288\n",
              "Bad (D-F)          45\n",
              "Name: Essay Grading, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhhfSzDnNfRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2519bf-1ad1-49e8-cb1e-080c2863948b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "def count_sentences(essay):\n",
        "  doc = nlp(essay)\n",
        "  doc_sents = [sent for sent in doc.sents]\n",
        "  return len(doc_sents)\n",
        "  # return len(list(doc.sents))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "str1 = '“I wanna go home!” I say as I sit on the kitchen floor watching my mother cook. “What do you mean?” she asks, giving me a questioning look. “Ethiopia?” “I don’t know.” Home. For most people, the word can be easily defined as the place where they grew up or live now. By that definition, the house in which I have lived for the past seven years would be my home. The problem is, I often find myself saying, “I wanna go home,” while sitting in that very house. The other candidate is the place where I grew up, but that could be either of two places: my home country of Ethiopia or my adopted hometown of Westbrook, Maine. I cannot choose one over the other. For better or for worse, each has shaped the person I am today more than can be expressed in words. Ethiopia is the place where I experienced so many of my “firsts.” Maine is the place where I developed my individuality. At the same time, neither can truly be my home. Though Ethiopia was my home at one point, it is no longer the same place I knew as a child because I am no longer that child. I can no longer relate to the culture the way I once did. As my sister often tells me, I have become “Americanized.” On the other hand, I have never felt at home in Maine. The first memory I have of Maine is my first day visiting Reiche Elementary, the school I would be attending. I stood in front of a group of seven- and eight-year-old boys and girls. Every face was pointed at me, every pair of eyes wide and expectant. I grabbed the fabric of my mother’s skirt and buried my face into the side of her leg. These children were all so different. Every child had a skin color different from mine. Though I picked out a few familiar words, I could not understand what they were saying. I knew I didn’t belong there, but there was no chance of hopping on a plane and going back to Ethiopia. I knew that, and the thought terrified me. I had never felt as uncomfortable and uncertain as I did that day. That day has stayed with me, along with the discomfort and uncertainty. Though the intensity of those feelings has faded, it has not gone away, and it is not likely to leave me soon. I cannot deny, however, that the environment Maine has provided has shaped me profoundly. Living in Maine has made me who I am today just as much as being born and raised in Ethiopia. Ethiopia gave me my cultural and family identity. Ethiopia is the place that comes to mind when I think of my family, since my entire extended family remains there. It is also the place that comes to mind when I think of my motivation, since I was raised in a culture that taught me to give one hundred percent at all times. Yet, the fact remains that I have lived in Maine for nearly ten years of my life. This environment has influenced me more than even I can comprehend. So, the question becomes: which of these places (if either) should I consider my home? In all honesty, I cannot choose one physical place and give it the title of “home.” Instead, I elect to compose my own definition of home, a definition that does not force me to choose between the two places in which I grew up. My definition allows me to think of home as a place in my mind, a state of mind that enables me to remember my childhood years in Ethiopia and the opportunities given to me by living in the U.S. It has taken a long time to define what home means to me — and even longer to find it — but doing so has given me an amazing sense of hope and comfort. In my mind, it is a place where I can escape. It is a place from which I draw strength when life gets too hectic or when I am faced with challenges that seem too great to overcome. It is what I really mean — what I have always meant — when I say that I want to go home.'\n",
        "count_sentences(str1)\n",
        "\n",
        "df_essays['SentenceCount'] = df_essays['Essay Text'].apply(count_sentences)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ydKRpYOV5j67",
        "outputId": "c37daef5-8b7b-4510-98f2-5fdd25347a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b04a2173-412b-40ef-b77d-b4aa6bcf2b6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b04a2173-412b-40ef-b77d-b4aa6bcf2b6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b04a2173-412b-40ef-b77d-b4aa6bcf2b6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b04a2173-412b-40ef-b77d-b4aa6bcf2b6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  \n",
              "0             35  \n",
              "1             28  \n",
              "2             40  \n",
              "3             20  \n",
              "4             23  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lexical-diversity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v96mYqe55-aa",
        "outputId": "08cfecc4-cd4b-4ba8-df22-339ff3d5cec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lexical-diversity\n",
            "  Downloading lexical_diversity-0.1.1-py3-none-any.whl (117 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 30 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 61 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 71 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 117 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: lexical-diversity\n",
            "Successfully installed lexical-diversity-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lexical_diversity import lex_div as ld"
      ],
      "metadata": {
        "id": "MXMUXS-b5__r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#str1 = '“I wanna go home!” I say as I sit on the kitchen floor watching my mother cook. “What do you mean?” she asks, giving me a questioning look. “Ethiopia?” “I don’t know.” Home. For most people, the word can be easily defined as the place where they grew up or live now. By that definition, the house in which I have lived for the past seven years would be my home. The problem is, I often find myself saying, “I wanna go home,” while sitting in that very house. The other candidate is the place where I grew up, but that could be either of two places: my home country of Ethiopia or my adopted hometown of Westbrook, Maine. I cannot choose one over the other. For better or for worse, each has shaped the person I am today more than can be expressed in words. Ethiopia is the place where I experienced so many of my “firsts.” Maine is the place where I developed my individuality. At the same time, neither can truly be my home. Though Ethiopia was my home at one point, it is no longer the same place I knew as a child because I am no longer that child. I can no longer relate to the culture the way I once did. As my sister often tells me, I have become “Americanized.” On the other hand, I have never felt at home in Maine. The first memory I have of Maine is my first day visiting Reiche Elementary, the school I would be attending. I stood in front of a group of seven- and eight-year-old boys and girls. Every face was pointed at me, every pair of eyes wide and expectant. I grabbed the fabric of my mother’s skirt and buried my face into the side of her leg. These children were all so different. Every child had a skin color different from mine. Though I picked out a few familiar words, I could not understand what they were saying. I knew I didn’t belong there, but there was no chance of hopping on a plane and going back to Ethiopia. I knew that, and the thought terrified me. I had never felt as uncomfortable and uncertain as I did that day. That day has stayed with me, along with the discomfort and uncertainty. Though the intensity of those feelings has faded, it has not gone away, and it is not likely to leave me soon. I cannot deny, however, that the environment Maine has provided has shaped me profoundly. Living in Maine has made me who I am today just as much as being born and raised in Ethiopia. Ethiopia gave me my cultural and family identity. Ethiopia is the place that comes to mind when I think of my family, since my entire extended family remains there. It is also the place that comes to mind when I think of my motivation, since I was raised in a culture that taught me to give one hundred percent at all times. Yet, the fact remains that I have lived in Maine for nearly ten years of my life. This environment has influenced me more than even I can comprehend. So, the question becomes: which of these places (if either) should I consider my home? In all honesty, I cannot choose one physical place and give it the title of “home.” Instead, I elect to compose my own definition of home, a definition that does not force me to choose between the two places in which I grew up. My definition allows me to think of home as a place in my mind, a state of mind that enables me to remember my childhood years in Ethiopia and the opportunities given to me by living in the U.S. It has taken a long time to define what home means to me — and even longer to find it — but doing so has given me an amazing sense of hope and comfort. In my mind, it is a place where I can escape. It is a place from which I draw strength when life gets too hectic or when I am faced with challenges that seem too great to overcome. It is what I really mean — what I have always meant — when I say that I want to go home.'\n",
        "\n",
        "#str1 = \"As UK Foreign Secretary Liz Truss and US Secretary of State Antony Blinken were meeting, Ukraine's President Zelensky tweeted another demand that they institute a no-fly zone over Ukraine.After a direct strike by Russian troops on a children’s hospital in Mariupol he asked how much longer the world will be an accomplice ignoring terror Demanding that Nato close the skies and stop the killing.\"\n",
        "\n",
        "# BADLY WRITTEN ESSAY\n",
        "#str1 = \"I hate wet and reiny days.It rained a lot in 1816.... a lot - like everyday; the weather in Europe was abnormally wet because it rained in Switzerland on 130 out of the 183 days from April to September. If I was Mary Shelley I might decide to write a book too. Afterall, it was the onnly thing you could do without TV or anything. She said that she passed the summer of 1816 in the environs of Geneva...we occasionally amused ourselves with some German stories of ghosts... These tales excited in us a playful desire of imitation  So, people were stuck inside and bored. Mary Shelley decided to write a book becuase it was so awful outside. I can totally see her point, you know? I guess I would write a novel if there was nothing else to do.\"\n",
        "# Let's tokenize  the text\n",
        "\n",
        "def get_ttr_stats(str1):\n",
        "  tok = ld.tokenize(str1)\n",
        "  #print(tok[:10])\n",
        "  # Let's lemmatize the text\n",
        "  flt = ld.flemmatize(str1)\n",
        "  #print(flt[:10])\n",
        "\n",
        "  print(f'ttr = {ld.ttr(flt)}')\n",
        "  print(f'root_ttr = {ld.root_ttr(flt)}')\n",
        "  print(f'log_ttr = {ld.log_ttr(flt)}')\n",
        "  print(f'maas_ttr = {ld.maas_ttr(flt)}')\n",
        "  print(f'mtld = {ld.mtld(flt)}')"
      ],
      "metadata": {
        "id": "mFTt4B0b6DXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str1  = '''\n",
        "some people dont like chocolate and i think theyre stupid they dont have any good taste i mean seriously how can you not just love it?!! its the most delicious thing on the entire universe. everytime i hear someone say they dont like chocolate i just want to curl up in a ball and sob. its a real problem, they are. oh, haha, i sound like yoda.\n",
        "anyways there are so many things that are made out of chocolate that are so wonderful. they even made a movie about it. it was called charlie and the chocolate factory. i loved that movie! do you like movies?? one of my favorite movies it the avengers. hulk is so adorable. tony stark is super sarcastic. \n",
        "ugh, im getting so off topic!!! so sorry about that, you must be so annoyed with me. CHOCOLATE IS SO AMAZING, IM LIKE THAT FISH FROM SPONGEBOB. OMG THAT WAS SUCH A FUNNY EPISODE UGH STOP IT YOU NEED TO GET BACK ON TRACK. oh no not you reader i was talking to myself through text which is really weird.\n",
        "lets start a new paragraph for new stuff. there are many different types of chocolate including white chocolate. alot of people who dont like brown chocolate like white chocolate. is that racist? can you be racist with chocolate or would that be something else like chocolist? i ask the real questions. \n",
        "what i dont approve of is putting a whole bunch of peanut butter and only a little chocolate together. thats just grody and wrong. its like trying to swallow a brick which ive never done btw, but ya know its just a figure of speech. the whole point is that not liking chocolate makes me feel sad because you are missing out on a whole world of wonderfulness and happiness and amazingness and CHOCOLATE!!\n",
        "'''\n",
        "get_ttr_stats(str1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FywGGhS_875G",
        "outputId": "ad38ded6-8564-4692-b221-dfbe025047f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ttr = 0.5258064516129032\n",
            "root_ttr = 9.257777898227156\n",
            "log_ttr = 0.8879431717517264\n",
            "maas_ttr = 0.04497814529524016\n",
            "mtld = 70.9322033898305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = '''\n",
        "For me, the strength of a person’s character is defined by their ability to act on their values and stand up for what they believe in. Having strong moral values only becomes a powerful agent of change when one is willing to follow through on them with action. Situations, such as this one, where I feel a sinking sensation deep in my gut, help to cue me to conflicts with my own values, prompting me to gather more information, thus taking the first step towards informed action.\n",
        "'''\n",
        "get_ttr_stats(str1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEbGwHcY9fM2",
        "outputId": "f214cd86-f3e5-4fd6-d247-0dd505476a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ttr = 0.7528089887640449\n",
            "root_ttr = 7.101985796042612\n",
            "log_ttr = 0.9367416455795197\n",
            "maas_ttr = 0.032450332773252495\n",
            "mtld = 100.81272727272726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = '''\n",
        "The children now love luxury; they have bad manners, contempt for authority; they show disrespect for elders and love chatter in place of exercise. They contradict their parents, chatter before company, gobble up dainties at the table, cross their legs, and tyrannize their teachers.\" These words seem like something my parents and any of my friends' parents would say. They express the disapproval of older and wiser generations towards the actions of college students. But these words came from Socrates. The problem of \"corrupted\" youth is not a problem of this generation only. It's a problem as old as the civilization itself. The problem is that when they were young, our parents and professors saw the world with different eyes. When they were at college, they were rebels. Now, I am part of the rebellious generation. The most important lesson that college taught me is that I should embrace the rebellious spirit and fight against the conformity my parents and teachers push me to accept.\n",
        "\n",
        "People tend to idealize the times of their youth. When they were young, they felt powerful. They believed they could change the world and they were happy. Today, when they are no longer young, they believe they resonate more realistically. They see young college students and shake their heads in disapproval: \"Our time was better. The way we lived, the music we listened to, the movies we watched, the friendships we made... you name it, everything was better. Today's young people don't know anything.\" That's what my father says, and I cannot do anything about it. It's how the human brain works, and it's probably how I will feel when I'm older. It took me a long time to realize the truth: there always were (and will be) good and bad young people. Each generation has its positive and negative aspects. The behavior of college students is a reflection of the time in which they live.\n",
        "\n",
        "If our parents and professors truly believe that students today are a disaster, then they should point the finger at themselves and seek part of the blame within them. If the youth was much better before our generation, they did something very wrong to grow an entire generation of broken children. My parents were always trying to convince me I was doing something wrong. When I came to college, the professors were saying the same things. They said we lacked focus, discipline, and will to learn. We only cared about parties, alcohol, friendships, and relationships. But from the first day at college, I realized that I was not the problem. Every other student was going through the same struggles. We all want to learn and achieve good academic results, but we also need to live as much as possible while we're still young. We learn a lot of theory at class, but none of it works without real life experience.\n",
        "\n",
        "Older generations push us to conform. They push us to learn what they tell us to learn, write the papers they tell us to write, and take exams to prove the knowledge we gained. They measure knowledge and intelligence through tests based on theory. They want us to be theoretically advanced, but no one cares to push us to live and learn from experience. The glorification of the higher education system is not justified. College produces instant graduates, many of which are semi-literate when they enter the job market. They hold degrees that give them foundation to consider themselves genius. They will never accept a reality check suggesting that college is tailored for mediocre individuals. Conformity makes us mediocre, and young people choose to rebel against that pattern. They always have and they always will.\n",
        "\n",
        "The education system is not built in accordance with the needs of the students and the job market. Universities use false advertising to make students believe that they will gain the ultimate experience and knowledge if they just give their money away. Education is being sold as something that it's not. When students face college, they face huge disappointment and shock. If they conform to those expectations, they will face an even greater shock later on, when they graduate and start searching for jobs. Fortunately, most of them choose to rebel. They see the reality and they believe they have the power to change it, just like our parents and professors thought when they were young. Young people are the driving force of society - that's the greatest lesson that college teaches us. Socrates had it wrong. Young people are not corrupted. They are the progressive force that begs to be considered. Ezra Taft Benson said it well: \"Youth is the spirit of adventure and awakening. It is a time of physical emerging when the body attains the vigor and good health that may ignore the caution of temperance. Youth is a period of timelessness when the horizons of age seem too distant to be noticed.\n",
        "'''\n",
        "get_ttr_stats(str1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmz6RKKH93SO",
        "outputId": "316341dc-5473-4b80-c50a-695b9b0424c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ttr = 0.3863912515188335\n",
            "root_ttr = 11.084783172574422\n",
            "log_ttr = 0.8583478292617216\n",
            "maas_ttr = 0.04858756216811159\n",
            "mtld = 65.00789889415482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk as nlp \n",
        "nltk.download('punkt')\n",
        "document= re.sub(r'[^\\w]', ' ', str1)\n",
        "document = document.lower()\n",
        "tokens = nlp.word_tokenize(document)\n",
        "types=nlp.Counter(tokens)\n",
        "TTR = (len(types)/len(tokens))\n",
        "print(TTR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ip4RVCA_qW8",
        "outputId": "2f1264d9-b2b4-4e61-a6a3-cc71b48abe0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "0.42016806722689076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bEk_wQEAqXD",
        "outputId": "3e95b9e6-45d6-4fa1-c30a-263474d9ee27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rakeshadk7/LexicalChains.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhylQT8SAo5X",
        "outputId": "902cd1d5-ebf0-43c5-e522-fcc26310097b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LexicalChains'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 24 (delta 5), reused 24 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/LexicalChains"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d1Xsr70AwSn",
        "outputId": "f24f3371-ba46-4627-814a-e591387d2d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/LexicalChains\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet_ic')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvePi9k1B9Ym",
        "outputId": "3e57e3e3-e77b-4795-a0b3-5ab7a595516b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-5dMl6GCEOD",
        "outputId": "d2b09b0c-f27f-468c-f277-03772ebb7685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpUF2cIQCJRu",
        "outputId": "9cfded2f-976a-4d57-8a07-de673b615468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python Chains.py\n",
        "!python2.7 Chains.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTR_02iWA1yT",
        "outputId": "dee7c4ea-6975-4012-eb0f-67d5297a339d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter file path + name, if file name is 'nlp.txt', type 'nlp' \n",
            " \n",
            "text\n",
            "\n",
            "\n",
            "\n",
            "Youth(2), genius(1), students(7), age(1), authority(1), graduates(1), youth(3), brain(1), individuals(1), student(1), friends(1), children(2)\n",
            "luxury(1)\n",
            "body(1), vigor(1), behavior(1), horizons(1), focus(1), manners(1), times(1), degrees(1), way(1), time(4), spirit(2), contempt(1), reflection(1)\n",
            "needs(1), theory(2), elders(1), system(2), expectations(1), part(2), teachers(2), things(1)\n",
            "place(1), chatter(2), words(2)\n",
            "discipline(1), tests(1), education(2), pattern(1), actions(1), market(2), Education(1), music(1), exams(1), lesson(2), works(1), exercise(1), adventure(1)\n",
            "father(1), parents(8)\n",
            "relationships(1), foundation(1), force(2), College(1), company(1), society(1), awakening(1), civilization(1), college(10), lot(1), parties(1), table(1), friendships(2), Universities(1)\n",
            "dainties(1), alcohol(1)\n",
            "legs(1), teaches(1), finger(1)\n",
            "something(1)\n",
            "knowledge(3), power(1), intelligence(1), results(1), disapproval(2), reality(2), blame(1), truth(1), problem(5), check(1)\n",
            "life(1), people(5), generation(5), People(1), period(1), experience(3), world(2), class(1), generations(2)\n",
            "Socrates(2)\n",
            "professors(4), heads(1)\n",
            "eyes(1), caution(1)\n",
            "rebels(1)\n",
            "conformity(1), shock(2), struggles(1), fight(1), advertising(1), Conformity(1)\n",
            "today(1), Today(2), day(1)\n",
            "movies(1), job(2), jobs(1), papers(1)\n",
            "everything(1)\n",
            "anything(1)\n",
            "anything(1)\n",
            "aspects(1)\n",
            "disaster(1)\n",
            "something(1)\n",
            "something(1)\n",
            "none(1)\n",
            "glorification(1)\n",
            "accordance(1)\n",
            "money(1)\n",
            "something(1)\n",
            "disappointment(1)\n",
            "Ezra(1)\n",
            "Taft(1)\n",
            "Benson(1)\n",
            "health(1)\n",
            "temperance(1)\n",
            "timelessness(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2to3 Chains.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "BK_Oy1enBd5-",
        "outputId": "f2df5d6d-acaf-4b0d-967e-92b21e59170f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-62-c695e97c1ba8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    2to3 Chains.py\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CEFR Predictor"
      ],
      "metadata": {
        "id": "NfAuHP7xDajl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AMontgomerie/CEFR-English-Level-Predictor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFOUS-_3BpsS",
        "outputId": "48e62d07-bb44-48c4-da70-41c054f0c42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CEFR-English-Level-Predictor'...\n",
            "remote: Enumerating objects: 1643, done.\u001b[K\n",
            "remote: Counting objects: 100% (1643/1643), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1608/1608), done.\u001b[K\n",
            "remote: Total 1643 (delta 66), reused 1604 (delta 33), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1643/1643), 14.82 MiB | 8.41 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "Checking out files: 100% (1522/1522), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CEFR-English-Level-Predictor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFaA3focDcjn",
        "outputId": "e0dad022-be64-42ae-983e-e732c3c794a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/LexicalChains/CEFR-English-Level-Predictor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7qm75bJ4DhHR",
        "outputId": "f102578e-804b-4512-bec9-6d8b72075196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/gdrive/MyDrive/LexicalChains/CEFR-English-Level-Predictor\n",
            "Collecting en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting numpy==1.20.1\n",
            "  Downloading numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 2.7 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.2\n",
            "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 21.3 MB/s \n",
            "\u001b[?25hCollecting textstat==0.7.0\n",
            "  Downloading textstat-0.7.0-py3-none-any.whl (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting xgboost==1.3.3\n",
            "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 157.5 MB 60 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.24.1\n",
            "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting scikit-optimize==0.8.1\n",
            "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting streamlit==0.77.0\n",
            "  Downloading streamlit-0.77.0-py2.py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 45.6 MB/s \n",
            "\u001b[?25hCollecting spacy<2.4.0,>=2.3.0\n",
            "  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 573 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->EnglishCEFRPredictor==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->EnglishCEFRPredictor==1.0.0) (2018.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->EnglishCEFRPredictor==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->EnglishCEFRPredictor==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->EnglishCEFRPredictor==1.0.0) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.17.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.8.1)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.27.1)\n",
            "Collecting validators\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting watchdog\n",
            "  Downloading watchdog-2.1.6-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.2.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (6.0.1)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.2.4)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (21.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (7.1.2)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 49.5 MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pyphen\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.11.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.18.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.11.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.7.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize==0.8.1->EnglishCEFRPredictor==1.0.0) (3.13)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.1.1)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (7.6.5)\n",
            "Collecting ipykernel>=5.1.2\n",
            "  Downloading ipykernel-6.9.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.5.4)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.3.5)\n",
            "Collecting ipython>=7.23.1\n",
            "  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (57.4.0)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[K     |████████████████████████████████| 380 kB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.5.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.0.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (22.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.9.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.2.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.0.6)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (4.63.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.10)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.8.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.0.7)\n",
            "Building wheels for collected packages: en-core-web-sm, blinker\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047105 sha256=b80096978466907813b0212acd8bdf2b2c98b58f3ad96aae90dc17c2e4266418\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=9b0224c5b356c4ab881a0d6cf22c9d0a3a810c0c49dd0461a49b648652c22957\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "Successfully built en-core-web-sm blinker\n",
            "Installing collected packages: prompt-toolkit, ipython, ipykernel, numpy, smmap, thinc, pandas, gitdb, watchdog, validators, toml, spacy, scikit-learn, pyphen, pydeck, pyaml, gitpython, blinker, base58, xgboost, textstat, streamlit, scikit-optimize, en-core-web-sm, EnglishCEFRPredictor\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "  Running setup.py develop for EnglishCEFRPredictor\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.28 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.9.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed EnglishCEFRPredictor-1.0.0 base58-2.1.1 blinker-1.4 en-core-web-sm-2.3.1 gitdb-4.0.9 gitpython-3.1.27 ipykernel-6.9.1 ipython-7.32.0 numpy-1.20.1 pandas-1.2.2 prompt-toolkit-3.0.28 pyaml-21.10.1 pydeck-0.7.1 pyphen-0.12.0 scikit-learn-0.24.1 scikit-optimize-0.8.1 smmap-5.0.0 spacy-2.3.7 streamlit-0.77.0 textstat-0.7.0 thinc-7.4.5 toml-0.10.2 validators-0.18.2 watchdog-2.1.6 xgboost-1.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "en_core_web_sm",
                  "ipykernel",
                  "numpy",
                  "pandas",
                  "prompt_toolkit",
                  "sklearn",
                  "spacy",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/LexicalChains/CEFR-English-Level-Predictor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MSdAB_HDjAP",
        "outputId": "c107f1a0-913f-4748-c65b-758e6c20f620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/LexicalChains/CEFR-English-Level-Predictor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z64Cfzqyi1TB",
        "outputId": "62ec2446-811a-4b12-8c19-4788a1739f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/gdrive/MyDrive/LexicalChains/CEFR-English-Level-Predictor\n",
            "Collecting en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.5 MB/s \n",
            "\u001b[?25hCollecting numpy==1.20.1\n",
            "  Downloading numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.2\n",
            "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting textstat==0.7.0\n",
            "  Downloading textstat-0.7.0-py3-none-any.whl (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting xgboost==1.3.3\n",
            "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 157.5 MB 64 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.24.1\n",
            "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting scikit-optimize==0.8.1\n",
            "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting streamlit==0.77.0\n",
            "  Downloading streamlit-0.77.0-py2.py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 46.3 MB/s \n",
            "\u001b[?25hCollecting spacy<2.4.0,>=2.3.0\n",
            "  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 26.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->EnglishCEFRPredictor==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->EnglishCEFRPredictor==1.0.0) (2018.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->EnglishCEFRPredictor==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->EnglishCEFRPredictor==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->EnglishCEFRPredictor==1.0.0) (1.4.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.4)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.1.27)\n",
            "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.17.3)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.1.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.10.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.5.1)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.18.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.2.4)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.23.0)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.1.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (21.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.7/dist-packages (from textstat==0.7.0->EnglishCEFRPredictor==1.0.0) (0.12.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.11.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.3.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (21.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.7.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize==0.8.1->EnglishCEFRPredictor==1.0.0) (3.13)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.1.1)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (7.6.5)\n",
            "Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (6.9.1)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (7.32.0)\n",
            "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.3.5)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.1.3)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.5.4)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.0.28)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.18.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.9.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.2.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (4.63.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (0.9.0)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz->EnglishCEFRPredictor==1.0.0) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (2.10)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.3.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.13.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.8.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (5.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit==0.77.0->EnglishCEFRPredictor==1.0.0) (3.0.7)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047105 sha256=813655c269518fbce558e3bed58ea86e1635381ffe2c1bb65e02d160ade008a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: numpy, thinc, pandas, spacy, scikit-learn, pyaml, xgboost, textstat, streamlit, scikit-optimize, en-core-web-sm, EnglishCEFRPredictor\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: textstat\n",
            "    Found existing installation: textstat 0.7.2\n",
            "    Uninstalling textstat-0.7.2:\n",
            "      Successfully uninstalled textstat-0.7.2\n",
            "  Attempting uninstall: streamlit\n",
            "    Found existing installation: streamlit 1.7.0\n",
            "    Uninstalling streamlit-1.7.0:\n",
            "      Successfully uninstalled streamlit-1.7.0\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "  Running setup.py develop for EnglishCEFRPredictor\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.9.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed EnglishCEFRPredictor-1.0.0 en-core-web-sm-2.3.1 numpy-1.20.1 pandas-1.2.2 pyaml-21.10.1 scikit-learn-0.24.1 scikit-optimize-0.8.1 spacy-2.3.7 streamlit-0.77.0 textstat-0.7.0 thinc-7.4.5 xgboost-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run CEFR_Predictor.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLaCOlzOiTly",
        "outputId": "7cafa290-ef09-4e2f-f891-a8cd384a4bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.192.11.168:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "assyLaCaivQZ",
        "outputId": "e52f78a8-db84-4fe1-b678-5b47e165b2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: uvicorn: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbsEXqe7gxeB",
        "outputId": "5b40c251-2123-497e-bd18-b4ff0a5c7e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textstat\n",
            "  Downloading textstat-0.7.2-py3-none-any.whl (101 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 20 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 101 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting pyphen\n",
            "  Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 39.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
            "Successfully installed pyphen-0.12.0 textstat-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPEC7lZnhpzq",
        "outputId": "abfa614a-b655-4e47-8529-30e9131b0f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "api.py             \u001b[0m\u001b[01;34mdata\u001b[0m/                           README.md\n",
            "app.yaml           Dockerfile                      requirements.txt\n",
            "\u001b[01;34mcefr_predictor\u001b[0m/    \u001b[01;34mEnglishCEFRPredictor.egg-info\u001b[0m/  setup.py\n",
            "CEFR_Predictor.py  LICENSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run api.py "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fffgkVonEMKF",
        "outputId": "e0915e78-b1ca-4903-c7a6-3bdbd1206e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-10 11:11:27.596 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.192.11.168:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "QOcqx8v2EV9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13436b52-d681-4ab8-a67e-cf2477798519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.7.0-py2.py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.21.5)\n",
            "Collecting pympler>=0.9\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[K     |████████████████████████████████| 164 kB 76.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.3.5)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.13.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.11.2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
            "Collecting gitpython!=3.1.19\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.4.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.4.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.10.0.2)\n",
            "Collecting watchdog\n",
            "  Downloading watchdog-2.1.6-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting validators\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.3)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (5.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
            "Collecting ipykernel>=5.1.2\n",
            "  Downloading ipykernel-6.9.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.5)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.1.1)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.3)\n",
            "Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
            "Collecting ipython>=7.23.1\n",
            "  Downloading ipython-7.32.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.5.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[K     |████████████████████████████████| 380 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.9.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (3.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=b865afced2a523c6b613d32dd62920dd481109366e4d8f947a09b33a9bdd9c20\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n",
            "Successfully built blinker\n",
            "Installing collected packages: prompt-toolkit, ipython, ipykernel, smmap, gitdb, watchdog, validators, toml, pympler, pydeck, gitpython, blinker, base58, streamlit\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.28 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.9.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\u001b[0m\n",
            "Successfully installed base58-2.1.1 blinker-1.4 gitdb-4.0.9 gitpython-3.1.27 ipykernel-6.9.1 ipython-7.32.0 prompt-toolkit-3.0.28 pydeck-0.7.1 pympler-1.0.1 smmap-5.0.0 streamlit-1.7.0 toml-0.10.2 validators-0.18.2 watchdog-2.1.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "ipykernel",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 745 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=f6aab42ff8df9dac55e945e232dc6deae07093de1a2422fbed8d0a35d0b98c64\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awlify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJyzQhfHfuFO",
        "outputId": "36a95345-7da7-4c47-bfbd-02e85ae49675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awlify\n",
            "  Downloading awlify-1.1.2-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: spacy>=2.0.16 in /usr/local/lib/python3.7/dist-packages (from awlify) (2.3.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (1.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (4.63.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (57.4.0)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (7.4.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (1.20.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.16->awlify) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.16->awlify) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.16->awlify) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.16->awlify) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.16->awlify) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.16->awlify) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.16->awlify) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.16->awlify) (3.0.4)\n",
            "Installing collected packages: awlify\n",
            "Successfully installed awlify-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA5BYfrtjtB4",
        "outputId": "a88e687a-7339-4cb9-8f42-7be19817a8cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.3.1\n",
            "  Using cached en_core_web_sm-2.3.1-py3-none-any.whl\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.20.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.63.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str1 = '''\n",
        "The children now love luxury; they have bad manners, contempt for authority; they show disrespect for elders and love chatter in place of exercise. They contradict their parents, chatter before company, gobble up dainties at the table, cross their legs, and tyrannize their teachers.\" These words seem like something my parents and any of my friends' parents would say. They express the disapproval of older and wiser generations towards the actions of college students. But these words came from Socrates. The problem of \"corrupted\" youth is not a problem of this generation only. It's a problem as old as the civilization itself. The problem is that when they were young, our parents and professors saw the world with different eyes. When they were at college, they were rebels. Now, I am part of the rebellious generation. The most important lesson that college taught me is that I should embrace the rebellious spirit and fight against the conformity my parents and teachers push me to accept.\n",
        "\n",
        "People tend to idealize the times of their youth. When they were young, they felt powerful. They believed they could change the world and they were happy. Today, when they are no longer young, they believe they resonate more realistically. They see young college students and shake their heads in disapproval: \"Our time was better. The way we lived, the music we listened to, the movies we watched, the friendships we made... you name it, everything was better. Today's young people don't know anything.\" That's what my father says, and I cannot do anything about it. It's how the human brain works, and it's probably how I will feel when I'm older. It took me a long time to realize the truth: there always were (and will be) good and bad young people. Each generation has its positive and negative aspects. The behavior of college students is a reflection of the time in which they live.\n",
        "\n",
        "If our parents and professors truly believe that students today are a disaster, then they should point the finger at themselves and seek part of the blame within them. If the youth was much better before our generation, they did something very wrong to grow an entire generation of broken children. My parents were always trying to convince me I was doing something wrong. When I came to college, the professors were saying the same things. They said we lacked focus, discipline, and will to learn. We only cared about parties, alcohol, friendships, and relationships. But from the first day at college, I realized that I was not the problem. Every other student was going through the same struggles. We all want to learn and achieve good academic results, but we also need to live as much as possible while we're still young. We learn a lot of theory at class, but none of it works without real life experience.\n",
        "\n",
        "Older generations push us to conform. They push us to learn what they tell us to learn, write the papers they tell us to write, and take exams to prove the knowledge we gained. They measure knowledge and intelligence through tests based on theory. They want us to be theoretically advanced, but no one cares to push us to live and learn from experience. The glorification of the higher education system is not justified. College produces instant graduates, many of which are semi-literate when they enter the job market. They hold degrees that give them foundation to consider themselves genius. They will never accept a reality check suggesting that college is tailored for mediocre individuals. Conformity makes us mediocre, and young people choose to rebel against that pattern. They always have and they always will.\n",
        "\n",
        "The education system is not built in accordance with the needs of the students and the job market. Universities use false advertising to make students believe that they will gain the ultimate experience and knowledge if they just give their money away. Education is being sold as something that it's not. When students face college, they face huge disappointment and shock. If they conform to those expectations, they will face an even greater shock later on, when they graduate and start searching for jobs. Fortunately, most of them choose to rebel. They see the reality and they believe they have the power to change it, just like our parents and professors thought when they were young. Young people are the driving force of society - that's the greatest lesson that college teaches us. Socrates had it wrong. Young people are not corrupted. They are the progressive force that begs to be considered. Ezra Taft Benson said it well: \"Youth is the spirit of adventure and awakening. It is a time of physical emerging when the body attains the vigor and good health that may ignore the caution of temperance. Youth is a period of timelessness when the horizons of age seem too distant to be noticed.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "kmiXJwc5kGSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from awlify import awlify\n",
        "import json\n",
        "global awl_list\n",
        "awl_list = []\n",
        "def iterate_nested(d):\n",
        "  for k, v in d.items():\n",
        "      if isinstance(v, dict):\n",
        "          iterate_nested(v)\n",
        "      else:\n",
        "          if k == 'awl_words':\n",
        "            if v:\n",
        "              for val in v:\n",
        "                if isinstance(val, dict):\n",
        "                  iterate_nested(val)\n",
        "          elif k == 'word':\n",
        "            if v not in awl_list:\n",
        "              #print(v)\n",
        "              awl_list.append(v)\n",
        "  return len(awl_list)\n",
        "\n",
        "\n",
        "def get_count_AWL(essay):\n",
        "  result = awlify(essay)\n",
        "  res = json.loads(result)\n",
        "  awl_count  = iterate_nested(res)\n",
        "  word_count = count_non_stop_words(essay)\n",
        "  #print(f'Essay has {awl_count} academic words and {word_count} total words !')\n",
        "  return awl_count/word_count\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "word_tokens = word_tokenize(df_essays.iloc[729].values[0])\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def count_non_stop_words(essay):\n",
        "  word_tokens = word_tokenize(essay)\n",
        "  filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "  return len(filtered_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5_gL5tfqFmb",
        "outputId": "b657638a-4bee-4542-fdbf-074158783f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_count_AWL(str1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8GcDD2ztmUY",
        "outputId": "87d186ec-fad6-4abe-dfe0-0586373dc3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03546099290780142"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays['AWLCount'] = df_essays['Essay Text'].apply(get_count_AWL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wu7xdIit_SW",
        "outputId": "884bb2c7-1dcd-4c37-b17e-78297492abda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_essays.head()"
      ],
      "metadata": {
        "id": "ApAAfcAKutmz",
        "outputId": "469d4ed5-ba59-4721-d259-ae07313642e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-97f3b2b6-63a6-4d80-b986-9098b79fe624\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay Text</th>\n",
              "      <th>Essay Grading</th>\n",
              "      <th>SentenceCount</th>\n",
              "      <th>AWLCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE ALARM CLOCK IS, TO MANY high school studen...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>34</td>\n",
              "      <td>0.060606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>30</td>\n",
              "      <td>0.158576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHEN I WAS FOUR YEARS OLD, I fell in love. It ...</td>\n",
              "      <td>Excellent (A+)</td>\n",
              "      <td>40</td>\n",
              "      <td>0.125940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THIS SUMMER, I WENT TO THE governor’s Honors P...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>20</td>\n",
              "      <td>0.269481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>THIS PAST SUMMER I HAD THE opportunity to part...</td>\n",
              "      <td>Average (B-C)</td>\n",
              "      <td>22</td>\n",
              "      <td>0.312500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97f3b2b6-63a6-4d80-b986-9098b79fe624')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97f3b2b6-63a6-4d80-b986-9098b79fe624 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97f3b2b6-63a6-4d80-b986-9098b79fe624');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          Essay Text   Essay Grading  \\\n",
              "0  THE ALARM CLOCK IS, TO MANY high school studen...   Average (B-C)   \n",
              "1  I HAVE ALWAYS BEEN A MATH-SCIENCE girl. I sigh...   Average (B-C)   \n",
              "2  WHEN I WAS FOUR YEARS OLD, I fell in love. It ...  Excellent (A+)   \n",
              "3  THIS SUMMER, I WENT TO THE governor’s Honors P...   Average (B-C)   \n",
              "4  THIS PAST SUMMER I HAD THE opportunity to part...   Average (B-C)   \n",
              "\n",
              "   SentenceCount  AWLCount  \n",
              "0             34  0.060606  \n",
              "1             30  0.158576  \n",
              "2             40  0.125940  \n",
              "3             20  0.269481  \n",
              "4             22  0.312500  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_count_AWL(str1)\n",
        "#get_count_AWL('the economic recovery is ongoing and potentially problematic')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgb8Txq4qxw7",
        "outputId": "5bdd9d30-08bb-4c2f-839f-03716f64e1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "authority\n",
            "contradict\n",
            "generations\n",
            "generation\n",
            "conformity\n",
            "positive\n",
            "negative\n",
            "aspects\n",
            "seek\n",
            "convince\n",
            "focus\n",
            "achieve\n",
            "academic\n",
            "theory\n",
            "conform\n",
            "intelligence\n",
            "theoretically\n",
            "justified\n",
            "job\n",
            "foundation\n",
            "individuals\n",
            "ultimate\n",
            "jobs\n",
            "physical\n",
            "emerging\n",
            "attains\n",
            "ignore\n",
            "period\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from awlify import awlify\n",
        "result = awlify('the economic recovery is ongoing and potentially problematic')\n",
        "print(type(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH23V2d4lc9g",
        "outputId": "56cca4c1-f936-4b0a-de8c-15b067011a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using json.loads()\n",
        "# convert dictionary string to dictionary\n",
        "import json\n",
        "res = json.loads(result)"
      ],
      "metadata": {
        "id": "036vcSW8mmZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXas2FNfmwG3",
        "outputId": "a45362ab-53b6-4328-ae67-45871c1939b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': {'awl_words': [{'index': 1,\n",
            "                         'meta': {'head': 'economy', 'sublist': 1},\n",
            "                         'word': 'economic'},\n",
            "                        {'index': 2,\n",
            "                         'meta': {'head': 'recover', 'sublist': 6},\n",
            "                         'word': 'recovery'},\n",
            "                        {'index': 4,\n",
            "                         'meta': {'head': 'ongoing', 'sublist': 10},\n",
            "                         'word': 'ongoing'},\n",
            "                        {'index': 6,\n",
            "                         'meta': {'head': 'potential', 'sublist': 2},\n",
            "                         'word': 'potentially'}],\n",
            "          'sentence': 'the economic recovery is ongoing and potentially '\n",
            "                      'problematic'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def myprint(d):\n",
        "    for k, v in d.items():\n",
        "        if isinstance(v, dict):\n",
        "            myprint(v)\n",
        "        else:\n",
        "            if k == 'awl_words':\n",
        "              if v:\n",
        "                #print(\"{0} : {1}\".format(k, v))\n",
        "                for val in v:\n",
        "                  if isinstance(val, dict):\n",
        "                    myprint(val)\n",
        "                  else:\n",
        "                    print(\"{0} : {1}\".format(k, v))\n",
        "            elif k == 'word':\n",
        "              print(v)\n",
        "\n",
        "\n",
        "myprint(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDSqUza5mQdY",
        "outputId": "784afc0d-1121-4817-c4b6-2885a3c44b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "economic\n",
            "recovery\n",
            "ongoing\n",
            "potentially\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2H0Ob684j38-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AutomatedEssayScoring.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}